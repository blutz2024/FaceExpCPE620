{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73db0601",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10b8bb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from itertools import cycle\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torchinfo import summary\n",
    "from tqdm import tqdm\n",
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a374da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb69d7f8",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d415bfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f070573d",
   "metadata": {},
   "source": [
    "## Data Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5689ad0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean = [0.485, 0.456, 0.406]\n",
    "#std = [0.229, 0.224, 0.225]\n",
    "\n",
    "# train_transforms = T.Compose([\n",
    "#     T.Resize((48, 48)),\n",
    "#     T.ToTensor(),\n",
    "#     T.RandomHorizontalFlip(p=0.5),\n",
    "#     T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "#     T.Normalize(mean, std),\n",
    "#     T.RandomAffine(degrees=0, shear=0.2, scale=(0.8, 1.2))\n",
    "# ])\n",
    "\n",
    "mean = [0.485]  # Single channel\n",
    "std = [0.229]\n",
    "\n",
    "train_transforms = T.Compose([\n",
    "    T.Grayscale(num_output_channels=3),  # Keep 3 channels but use grayscale\n",
    "    T.RandomApply([T.RandomRotation(15)], p=0.5),\n",
    "    T.RandomPerspective(distortion_scale=0.3, p=0.3),\n",
    "    T.RandomResizedCrop(48, scale=(0.8, 1.2)),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean, std),\n",
    "    T.RandomErasing(p=0.2)  # Helps with occlusion\n",
    "])\n",
    "\n",
    "val_transforms = T.Compose([\n",
    "    T.Resize((48, 48)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean, std)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369f49a1",
   "metadata": {},
   "source": [
    "## DataSet and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04df5c89",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "fer_2013_dir = Path(os.getcwd(), 'datasets', 'fer2013')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97db57d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = ImageFolder(root=fer_2013_dir / 'train', transform=train_transforms)\n",
    "training_loader = DataLoader(training_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_set = ImageFolder(root=fer_2013_dir / 'test', transform=val_transforms)\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40020c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 28709 images\n",
      "Testing set: 7178 images\n",
      "One image batch shape : torch.Size([128, 3, 48, 48])\n",
      "One label batch shape : torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "# Print shape of training and testing images\n",
    "print(f\"Training set: {len(training_set)} images\")\n",
    "print(f\"Testing set: {len(test_set)} images\")\n",
    "\n",
    "for images, labels in training_loader:\n",
    "  break\n",
    "\n",
    "print(f\"One image batch shape : {images.shape}\")\n",
    "print(f\"One label batch shape : {labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17391128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'angry': 0, 'disgust': 1, 'fear': 2, 'happy': 3, 'neutral': 4, 'sad': 5, 'surprise': 6}\n"
     ]
    }
   ],
   "source": [
    "print(training_set.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c08b7dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    0: 'angry', 1: 'disgust', 2: 'fear', 3: 'happy', \n",
    "    4: 'neutral', 5: 'sad', 6: 'surprise'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3867fc1",
   "metadata": {},
   "source": [
    "#### Show sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc0b98a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAFBCAYAAACmUBx4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABfhUlEQVR4nO3de5RfVX3//x0g5H6bSSYzuSeTG+F+C4J+lUutFqlFpXhZbUXqKvVSXLV2qasqYrGrS623IlKsRZeIVVuLaO2yiEpFQYkgQgiQkEyuTJJJyBXCrZ/fH/7IMp33M5n3cD5nMsPzsZZ/9N3j+eyzz977nDkr7tewRqPRKJIkSZIkSVKNjhjoBkiSJEmSJOmFx49SkiRJkiRJqp0fpSRJkiRJklQ7P0pJkiRJkiSpdn6UkiRJkiRJUu38KCVJkiRJkqTa+VFKkiRJkiRJtfOjlCRJkiRJkmrnRylJkiRJkiTVzo9Sh5kvfelLZdiwYWXZsmWVnG/YsGHlne98ZyXn+u1zfvjDH670nJIGtxfC2nXrrbeW0047rYwZM6YMGzas3HTTTZW1TVLzvRDWqWZ7rg+7uroGuinSkPFCWJt8h9LBHDXQDZAk6XDXaDTKxRdfXBYuXFhuvvnmMmbMmLJo0aKBbpYkSdJhzXcoHYofpfSC9uyzz5ZnnnmmjBgxYqCbIukwtmnTprJ9+/bymte8ppx33nm1/naj0Sj79u0ro0aNqvV3JUmSni/foXQo/s/3BqF9+/aVv/qrvyonnXRSmTBhQmlpaSlnnnlm+fa3v43/nX/6p38qCxcuLCNGjChLliwp//qv/9rrmO7u7nLZZZeVGTNmlKOPPrrMnTu3XHnlleWZZ56prO1bt24tb3/728uSJUvK2LFjS1tbWzn33HPLT37ykwOO6+rqKsOGDSuf+MQnyic/+ckyd+7cMnbs2HLmmWeWO++8s9d5v/CFLxxwfTfeeGO55JJLypw5c3qd82Mf+1i56qqryty5c8uIESPKLbfcUiZOnFguu+yyXuft6uoqRx55ZPn4xz9eWR9IL1SDde368Ic/XGbMmFFKKeW9731vGTZs2AFry8qVK8ub3vSm0tbWVkaMGFGOOeaY8rnPfa7f1/7cP7u/9tpryzHHHFNGjBhRvvzlL1dyLZIObrCuU6WU8vjjj5f3vOc9Ze7cuWXkyJGlpaWlnHbaaeVrX/va/mOWLVtW3vCGN5Q5c+aUUaNGlTlz5pQ3vvGNZe3atb3Od+edd5YXv/jFZeTIkWXatGnl/e9/f3n66acra6+kvhusa5PvUOoL/6XUIPTkk0+W7du3l/e85z1l+vTp5amnnio/+MEPymtf+9py/fXXlz/5kz854Pibb765/OhHPyof+chHypgxY8o111xT3vjGN5ajjjqqXHTRRaWU3yxIS5cuLUcccUT50Ic+VDo7O8sdd9xRrrrqqtLV1VWuv/76g7bpucXlUHsMbN++vZRSyhVXXFHa29vLnj17yn/8x3+Us88+u9x6663l7LPPPuD4z33uc2Xx4sXl05/+dCmllA9+8IPl/PPPL2vWrCkTJkwopZRy3XXXlcsuu6y87nWvK5/61KfKzp07y5VXXlmefPLJsA2f/exny8KFC8snPvGJMn78+LJgwYJy6aWXluuuu6587GMf23/eUkq55pprytFHH10uvfTSg16XpEMbrGvXW9/61nLiiSeW1772teUv/uIvypve9Kb9/7rygQceKGeddVaZNWtW+Yd/+IfS3t5evv/975fLL7+89PT0lCuuuKJf137TTTeVn/zkJ+VDH/pQaW9vL21tbZmultRPg3WdKqWUd7/73eUrX/lKueqqq8rJJ59c9u7dW+6///6ybdu2/cd0dXWVRYsWlTe84Q2lpaWlPProo+Xzn/98Of3008sDDzxQJk+eXEr5zdp23nnnlTlz5pQvfelLZfTo0eWaa64pN954Y7JHJVVhsK5NvkOpTxo6rFx//fWNUkrjrrvu6vN/55lnnmk8/fTTjT/90z9tnHzyyQf8/0opjVGjRjW6u7sPOH7x4sWN+fPn769ddtlljbFjxzbWrl17wH//E5/4RKOU0li+fPkB57ziiisOOK6zs7PR2dnZ5zb/37afd955jde85jX762vWrGmUUhrHH39845lnntlf/8UvftEopTS+9rWvNRqNRuPZZ59ttLe3N84444wDzrt27drG8OHDG7Nnz+51zs7OzsZTTz11wPGPPPJI44gjjmh86lOf2l974oknGq2trY23vOUt6euSXmiG+tr13Prx8Y9//ID6K17xisaMGTMaO3fuPKD+zne+szFy5MjG9u3b+3XtEyZMwP+upP4Z6uvUcccd17jwwgv7fG3PtXfPnj2NMWPGND7zmc/sr7/+9a/HayulNNasWZP6HUlsqK9NvkPpUPyf7w1S3/zmN8uLX/ziMnbs2HLUUUeV4cOHly9+8YtlxYoVvY4977zzytSpU/f/30ceeWR5/etfX1atWlU2bNhQSinlu9/9bjnnnHPKtGnTyjPPPLP/P7/3e79XSinltttuO2h7Vq1aVVatWtWntl977bXllFNOKSNHjtzf9ltvvTVs+6te9apy5JFH7v+/TzjhhFJK2f/PzB966KHS3d1dLr744gP+e7NmzSovfvGLw99/9atfXYYPH35Abd68eeWCCy4o11xzTWk0GqWUUm688caybdu2ytMrpBeywbx2/V/79u0rt956a3nNa15TRo8efcDvn3/++WXfvn0H/M+NM9d+7rnnlkmTJvWrXZKen8G6Ti1durT813/9V3nf+95XfvzjH5cnnnii1zF79uwp733ve8v8+fPLUUcdVY466qgyduzYsnfv3gOu70c/+hFem6SBMVjXpojvUPptfpQahL71rW+Viy++uEyfPr3ccMMN5Y477ih33XVXufTSS8u+fft6Hd/e3o615/5J9+bNm8t3vvOdMnz48AP+c+yxx5ZSSunp6amk7Z/85CfL2972tnLGGWeUf//3fy933nlnueuuu8orX/nK8OWptbX1gP/7uX/u+dyxz7X/txfd50S1Ukrp6OgI6+9617vKypUryy233FJK+c3/dPDMM88sp5xySh+vTtLBDOa1K7Jt27byzDPPlH/8x3/s9fvnn3/+Ab+fvXZapyQ112Bepz772c+W9773veWmm24q55xzTmlpaSkXXnhhWbly5f5j3vSmN5Wrr766vPWtby3f//73yy9+8Yty1113lSlTphzwHrZt27aDXpukeg3mtSniO5R+m3tKDUI33HBDmTt3bvn6179ehg0btr9Oeyh1d3dj7bmPPpMnTy4nnHBC+ehHPxqeY9q0ac+32aWU37T97LPPLp///OcPqO/evbtf53uu/Zs3b+71/4uuu5RyQJ/9tnPPPbccd9xx5eqrry5jx44td999d7nhhhv61S5JvQ3mtSsyadKkcuSRR5Y//uM/Lu94xzvCY+bOnVtKyV87rVOSmmswr1NjxowpV155ZbnyyivL5s2b9/+rqd///d8vDz74YNm5c2f57ne/W6644oryvve9b/9/77n9Wn5ba2vrQa9NUr0G89oU8R1Kv82PUoPQsGHDytFHH33AhOvu7sb0hVtvvbVs3rx5/78cevbZZ8vXv/710tnZuT8N4YILLijf+973SmdnZ1P/ueOwYcP2/2un5/z6178ud9xxR5k5c2b6fIsWLSrt7e3lG9/4Rnn3u9+9v75u3brys5/9LL2YXn755eXP//zPy86dO8vUqVPLH/7hH6bbJCk2mNeuyOjRo8s555xT7rnnnnLCCSeUo48+Go/NXrukgTFU1qmpU6eWSy65pNx7773l05/+dHn88cfLsGHDSqPR6PUe9s///M/l2WefPaB2zjnnlJtvvjm8Nkn1Gypr03N8h9Jv86PUYeqHP/xhmGRw/vnnlwsuuKB861vfKm9/+9vLRRddVNavX1/+9m//tnR0dBzwT7SfM3ny5HLuueeWD37wg/vTFx588MEDYkE/8pGPlFtuuaWcddZZ5fLLLy+LFi0q+/btK11dXeV73/teufbaa/cvYJH58+eXUsoh/3fFF1xwQfnbv/3bcsUVV5SXvexl5aGHHiof+chHyty5c/sVPXrEEUeUK6+8slx22WXloosuKpdeemnZsWNHufLKK0tHR0c54ojc/0L1j/7oj8r73//+8j//8z/lAx/4wEEXSEm9DdW1i3zmM58pL3nJS8r/+3//r7ztbW8rc+bMKbt37y6rVq0q3/nOd8oPf/jDUkpJX7uk5hmq69QZZ5xRLrjggnLCCSeUSZMmlRUrVpSvfOUr5cwzzyyjR48upZTy0pe+tHz84x8vkydPLnPmzCm33XZb+eIXv1gmTpx4wLk+8IEPlJtvvrmce+655UMf+lAZPXp0+dznPlf27t170DZI6r+hujYR36G030DvtK4DPZe+QP95Lu3k7//+7xtz5sxpjBgxonHMMcc0vvCFLzSuuOKKxv+9paWUxjve8Y7GNddc0+js7GwMHz68sXjx4sZXv/rVXr+9devWxuWXX96YO3duY/jw4Y2WlpbGqaee2vibv/mbxp49ew445/9NX5g9e/YBSXfkySefbLznPe9pTJ8+vTFy5MjGKaec0rjpppsab37zm8OkvP+b0kC/f9111zXmz5/fOProoxsLFy5s/Mu//EvjD/7gDw5IZDjYOX/bJZdc0jjqqKMaGzZsOOT1SPqNob52HWz9WLNmTePSSy9tTJ8+vTF8+PDGlClTGmeddVbjqquuOuC47LVLqtZQX6fe9773NU477bTGpEmTGiNGjGjMmzev8Zd/+ZeNnp6e/cds2LCh8brXva4xadKkxrhx4xqvfOUrG/fff39j9uzZjTe/+c0HnO+nP/1p40UvelFjxIgRjfb29sZf//VfN6677jrT96SKDfW1yXcoHcqwRuP/jxqThpAdO3aUhQsXlgsvvLBcd911ff7vPfXUU2XOnDnlJS95SfnGN77RxBZKkiRJkvTC5v98T4Ned3d3+ehHP1rOOeec0traWtauXVs+9alPld27d5d3vetdfTrH1q1by0MPPVSuv/76snnz5gM2AJUkSZIkSdXzo5QGvREjRpSurq7y9re/vWzfvr2MHj26vOhFLyrXXnvt/kjTQ/nP//zP8pa3vKV0dHSUa665ppxyyilNbrUkSZIkSS9s/s/3JEmSJEmSVLtcNJkkSZIkSZJUAT9KSZIkSZIkqXZ+lJIkSZIkSVLt/CglSZIkSZKk2vU5fe/KK69MnbiZ+6cfcUT8LS1bHzZsWOp3o2v63//939Q5BoNm732f7ffs8RG6T9lrpbZU0WdV9QtdK80Dant0/tGjR4fHTp8+PawvXLgwdXxbW1tYP5QqxogkHczzWeeH4hpF1zRy5MiwHj2bsn2afY5Rnc5Dnn322T6fO/u+Qf141FHxKzrVM31AbaQ6/Sbd6+HDh6fOM27cuLCe+c3x48eH9S1btoT1xx9/PKzT2KC2Z8bSk08+GdZ37NgR1nfv3t3nc5fS/zXq05/+dFjftWtXWKdxsn379l61I488MjyW7jn10RNPPBHW6b739PSEdbpfLS0tvWpLliwJj+3q6grre/fuDevz5s0L6zSWH3300bBO/f7zn/+8V+3cc88Nj6X37zFjxoT1e++9N6z/5Cc/Ces0lqntt99+e1jX0HOo9cl/KSVJkiRJkqTa+VFKkiRJkiRJtfOjlCRJkiRJkmrnRylJkiRJkiTVrs8bndMGfySz4SJt8pitk2aeP7tZ5mCQvaaqNkbPblSaOZY2WswaiA3NCbWFNhjNboweoU0cH3744bC+YcOGsD5z5sywfvHFF/e5LYPNpEmTwnq0uWYppXR3d4f1qVOnhvVos8+jjz46PDbajLSUUh577LGwTptx0saYNN8yG8uOHTs2PHbatGlhvbW1Nax3dHT0+TdLKWX9+vVhncZ4tKknzbWnn346rEebKJfCbaT7MWrUqNT5o3GQ2QS2FL7XNJb27NnT57aU0vzgjcPVhAkTwnrU33QP6FlAaJzQM+KZZ54J65l5nv1Nutbs+0NV9QjNoWwICdVpHSFR2+nZUMUG8KXwGph9NkThKvQM2Lx5c1inDbLpftCzmo7funVrWI/6htbo7N9YVaO1gtpLz6CNGzf2qtGzgDYRp3ecX/3qV2Gd1sr58+eHddo8PhpXdJ2TJ08O6/v27QvrtNk+vZ/QuxXNk2g+04bjFFhEaxxtJE+bt9Pv0loRvetOmTIlPPYVr3hFWM++X9Mm+DfddFNYv+2228K6qjX0vqhIkiRJkiTpsOdHKUmSJEmSJNXOj1KSJEmSJEmqnR+lJEmSJEmSVDs/SkmSJEmSJKl2fY57yCaGUYJH5jzZtLBsvYoUv6qS1A4nVaTPVPm7z/fYUvL3ic5fRZJjs9P3Mml6Bzs+SsqghBhK1KEkktWrV/exdUMHpR1R340YMSKs0/iJjp87d27qHNRGuo/Z8UD1KMWL2kKpfJQEQ8dT2ykpiJ5p0fkppTKbVEXJR5Q0SKk6dE1RYk02wZR+kxKvqA+GuuOPPz6sUxohjaFormSfS5k1n37zYMdnE/Ui1Pbscy/7Lprtg8y5s/fjqaeeCuu0dtEzI/Ob1L/ZhECq0zqSuU+0tlCd+p3W0c7OzrD+5JNPhnUSpZDRPa0qIbq/aExRXzzyyCNhPXrWzJ49Ozx2zpw5YZ2Sh+l+0XsOjQdKf47mD90XSqSj1Lxdu3aFdUqqozRESg6MniP0m9RfdG7qR0ombG9vD+v0LnbPPff0uS0rV64M66eddlpYp/eTWbNmhfWlS5eG9XHjxoX1KPkxOzYo2ZnWLUoCpLE0mPgvpSRJkiRJklQ7P0pJkiRJkiSpdn6UkiRJkiRJUu38KCVJkiRJkqTa+VFKkiRJkiRJtWta+l4mwS2bskKyiSdZL5T0vWx620AYiHtdlWamQZbCqR3Z1Jeonp2rVKc0t6GM7gslpDz99NNhPZPgRmk1lCRC6UKUhEL3kcY4pYNEiT10nZTKN3ny5NTxdP5sulc0r7LzgcYGJR9RmhGl22zZsiWsR/1Ox9L6QW0n2XS/TOrZ4YzGfjaRLfMeQuegtYXuMd2D7LtCNOcodY3mLbUlm16WTQiM+jg7z+k+UR9QW6hvqB6pKmWZUtuonk2hjY6nuZRdQygljBIx6XkXpZjS8T09PeGxNAbqQn1E6/vixYvD+oYNG3rVqN9oPtCzfNOmTWG9o6MjrNO7FT0no/Xv0UcfDY/t6uoK6zR/KJGN2kjvXFH/lhKnxlG64c6dO8M6pfRSndqYfe8///zze9Xuu+++1DnovYUSAqdNmxbWs38/Re2h5NyWlpawTu/plHr4yle+MqxTG+k5Ev0dEKUJlsJJ0NTGq6++Oqwfiv9SSpIkSZIkSbXzo5QkSZIkSZJq50cpSZIkSZIk1c6PUpIkSZIkSapd0zY6HwgD0cbsppDKq+K+VrWpZ1Ub/jcTbWJLm4BmNtjMbg5NmwZmN6UdCkaPHh3WadNW2iiW7ldbW1uvGm0ASveF7iNtZpi9jzQ2o80+aTNO2uR71qxZYZ02xqQNZ2lTSNowk64pQhvrzp07N6wfe+yxYZ3uK42Nxx9/PKxHm9v+4Ac/CI/duHFjWKdxOmbMmLD+Qgw5KIU3zKV1geZW1N/Zjc5pU+NsuEJW1HZqY1XP5uwzq5nPQ0Jtzz4DqC8zY4bq2c3V6RkzYsSIsE5tj+q0OTSNa+ovOg+tURQQMnPmzLAebQZOYSLUFtrc+6677grr/UXPFHpO0vHHH398r9qDDz4YHkvXRhtCZ9fK7DMouge0yXf2PZveoagttIbQ/JkxY0avGs3l7DpPm1xn3zeo7dE7Ha0ftCZm0djbtm1bWM88Xygogc5B6wpdK80D6ncae9H9oNAG+k26p3/2Z38W1g/FfyklSZIkSZKk2vlRSpIkSZIkSbXzo5QkSZIkSZJq50cpSZIkSZIk1c6PUpIkSZIkSapdn7expySAZibeDcRvauBUlZAXoTGTSdqpSjOvsxRO/6DzU2JNJNuPzb7WwWTs2LFhndI+KHlj/PjxYX3OnDl9PpaSTeg+Tp48OaxTmlw2TSoas3v37g2PpUSdCRMmhHVKD6KkEkr3o/SRKCWQ+pcSAqdPnx7WW1tbwzpdKyVYUapOlCi4ffv28NjNmzeHdUqaoXtNaV0DsRbXKXtvMnM0u7ZnU+Oy71x0fHR+GieZNDY698Fkn5PR71aRaFsK9xedn+YQnSea59nkVLqmbMoenYfW9UxfZlNi6dlLaz0l5K1cuTKsR+s6pdZNmzYtVa8rfW/37t1hPZPGSu8PlDxHdWoj3XdKzqMExOhZRsdmk/3ofYZSfWkun3rqqWE9mm/UFpoPNJez73M09+n46Pwnn3xyeOxTTz0V1un9JJumR89MWnOjdzEaGzRO161bF9bnzZuXOk827TxK/aO/Gej6afzOnz8/rB/K0H4LlCRJkiRJ0mHJj1KSJEmSJEmqnR+lJEmSJEmSVDs/SkmSJEmSJKl2fpSSJEmSJElS7fqcvkeamaJ1uKXsRe15IaaINctA3O+BuH/Nvs5sahGl29DxmXMQSn8ayiZOnBjWV61aFdajZIxSSpkxY0ZYjxJusukoVKe2UxpONk0qSiuhY+ncTz/9dOo36TxtbW1hnRJPonQiSjBpaWlJtSWbvkXzihJlouSUpUuXhscuW7YsrFNyDLU9mzY0VGSSJw9Wj/opm7KXTd+rSiZ9L/uMoONpXGWPj+4H9RelII0aNSqsZxL/SuF1JJOkS23JJrMS6kf6XRL1O6Vb0T2lpFVSVUJodD927NgRHhuluNZpypQpYZ3SaylxMOq7TBrnweqUOrthw4awvmnTprBO7zlRshsl+FEKHL230XvFpEmTwjqNwUySZDaplMZ3ti00D6nPonc3ukc09+laae7TOkdJkZl5S/eaUj3p3ZXamH2vp3eu6DlC7/o0Nqh/M38/HvA7/fpvSZIkSZIkSc+DH6UkSZIkSZJUOz9KSZIkSZIkqXZ+lJIkSZIkSVLt/CglSZIkSZKk2vU5fS+bnpA5nnZpp3PQLvB0fDaBgGSOpzYOVFpf1DeUkJBNGHkhyY7353tsf1Q1xqJkjew60N8EhqGIEpOo7zKJGaVwEkqEUj0oNa61tTWsUxspHYTWlqjtdD10DvpNqlOiDN0PSraKklPGjh0bHkv27t0b1rPPNEpxIVHfzJo1Kzx23rx5YZ3S9+g+Ud+8UJ879Bx+8sknw3o0bqnvMvOtlHxyK8k842jM0rzNzgla60g2mSqSTUGitSibYEfnj2TTByk5in4z+35J4z261myqJI13uk80Buj8NPb27dvXq0bXHx1bSind3d1hvWqUAkfPg61bt4b1KPGOErqoP7Npb11dXWGdxhTd9+g+UtsppWz+/PlhferUqWGdUFIdjbXoWmku05ylZDtaQ7NzP0oqpt+l50I2IZpS8/bs2RPWp02bFtbpvSVKz6akZupf+k06nt5Fad5Q2ykpMrJ9+/Y+H1tK//8OfWG+BUqSJEmSJGlA+VFKkiRJkiRJtfOjlCRJkiRJkmrnRylJkiRJkiTVzo9SkiRJkiRJql2f0/cGIqkum1KWTYhpZtoPXX8V6W0HO09GJq3rYKpKe8ucJ9tfVSXeZdPnIs1OpMumVlI9amd2/B5uKZR1aG9vD+uUdEFpIpS8QfUo8YTuCyVbUZoKtZHOTykg9LvReMg+F6hOyTETJkzoc1tKyaVVUT9Syh4l7WRTpiiVJZNyREkt06dPD+v0HKE+oBSvoS6bGpepVzVXBiIZtpnvlqXk051pPEd16nca+5SaR2tUdu2iuRW1ndKtKAWO1hA6ntDxmWcJJdDSNVHSFj2nKLUt2/YohYvG77Zt28L62rVrw3rVenp6wvqGDRtSx0dpddkxRfeREv/ouUf14447Lqx3dHT0qlEb6Z2I3vPo3YfQ2pJ5X8y+h2Xf86hOfUbzMDpP9j2MrolSDzPptqWUsnDhwrAerenLli0Lj924cWNYnzJlSlina6X3SJqTdP5oHaW5R+sTjXdaow/FfyklSZIkSZKk2vlRSpIkSZIkSbXzo5QkSZIkSZJq50cpSZIkSZIk1c6PUpIkSZIkSapdLg6gSapK2asq2a6Zsmlk2aSZKtLhBkoz71M28a6q1KKo35udfFRVmlEVY4bGe1XJj4ejpUuXhnVK9Zg4cWJYnz17dqoe9XU2GYOOp7ZnEx0pTSpKyakiLfJgx1PSTBXPl2waGh1PSSjZ1C9Kvdm9e3evWmtra3jspEmTUnXqL5r7zU4lHWjZ9TSzdmbHbFVzK5soGJ0/OycokYhQAld2jYrq2eTJbOpVNuEr81zNppVmEz+pf2m9yIzhKOGtlFImT54c1rNpqNlEQbpPURpiNoUte3x/PfLII2F99erVYb2rqyusR+OKnj/Uz+PHjw/r1M80puhd6cQTTwzr0btYVanuVaXJ0btYVK9qbaU5nr2mzDsX/WaUaEnnKIUTSWmM0TsX9fsxxxzTq0bJfrfffntY37JlS1hva2sL63T/Nm3aFNZp/kXjnZL6smnKNCcPxX8pJUmSJEmSpNr5UUqSJEmSJEm186OUJEmSJEmSaudHKUmSJEmSJNXOj1KSJEmSJEmqXdNiHTJJYlWlf2UTj7JpZ1F7qI2UBEDpKM1sI8km51SVDtfMayI0Ng4nzU5IrCLdKtuP2VSooWDFihVhnZJgKJFk/vz5YZ2S86IUDEpByaasUCLJ2LFjwzqtc3Tfo2ST7HildBSSTSCrItmUEkyo3+maKDWK0HmiPn7qqafCY2fNmhXWJ0yYENZ37NgR1rOJgkNFdrxl3xUy56Zz0L1vZqIrrSHURko2yr5X0LqbSc7LpubRuceMGZM6DyXkZdao7D2l3xw1alRYp2uiOq0LUXLUrl27Uueg36RUKjqexirVozFDzzVK2qI0rB/84Adhvb/uu+++sL5q1aqw3t3dHdajvsuObzJz5sywvmDBgrDe2dmZ+t3oOUwpeLQ+Z9dcGrN0PL0rRPMw+/6dTcyl90g6nvoy0++U2JhNMKbzZxMLo7FECca0VtL7HLWd3rno/DRX169f36tGaXq0/mfmUl8M7bdASZIkSZIkHZb8KCVJkiRJkqTa+VFKkiRJkiRJtfOjlCRJkiRJkmrnRylJkiRJkiTVrmnpe1XIJtJlk/Do+CpS5min/qrSyLJJPpn0lWwKUlXJPM00UG2sKrFwIETjIDO+Sml+kuPhaM2aNWE9SroopZT29vawvmjRorA+ffr0sH777bf3qlGiDt2XE044Iay/7GUvC+uUskIJgSQaV9k5SNdEdUoTIZkxTsdS4su4cePC+vbt28M6JZBRysq2bdvC+uTJk3vVKDlm7ty5YZ3SoXbu3BnWH3/88bDe37SWwSKbMpd5DtM5MmlHpeTnUPYdLWoPJThl38+yzybqm8y6QG2hlL3x48enfpPWV5r/lJwUpW9mxwxdE7WR6pTERgmhmzdv7lWj66d1jlL2aN3Nvl9Tn0X3g+51dr186UtfGtb7i9YESrxbsmRJWI+eH9FzppRSHnvssbC+devW1G/OmzcvrFNf7969O6xH44oSzWj+0HpGayglrFGd0ueifs8m+FHb6TzZVL7M8yibPErrB10rJXjSWkH16PzURnqn//Wvfx3WaX7QNdFaQf0e3Seae9kE7v6mvfsvpSRJkiRJklQ7P0pJkiRJkiSpdn6UkiRJkiRJUu38KCVJkiRJkqTa9Xmj82ZuFJ3dLLOqjc6raE92A9CqNtCm82TOT21v9kbnWVFfVrVRdjM3uycDNTZoU0IStTM77rJzeCigTQiXL18e1mnzQ9osvKenJ6zfddddfWjdb0yaNCmsL1u2LKzThumvfe1rw/rJJ58c1mnD00h2TNF6RuOeNm7MbmCaQWvr3r17w/qGDRvCOt3raLP7UnjDzLa2tl61Cy+8MDz2oosuCutz5swJ69RG2kiT+p02MH3qqafC+uGKNqGmcU7rSDRuaVNYqtN4yz6DaE7QnIvaQxv3Zt9Pss8UaiOdP7oftOE2XRNtFk512jA3uzZG7aHrp/lGGz5nN2On+0q/O3Xq1D63hZ6ZtLH1jh07wjqtLXRf6fjMmKT5TmMjWrufj5e//OVhfeLEial6tPExXRs9C+h+UVBAVWMwmlfUlieeeCKs02bT9L5BaExRPVq3aP2nNY7OnT1P9lqjeZINoqDjaV2ZMGFCWKe2032NnoE0To8//viwTuOR/magTdqpjZkQEApcoLVv1qxZYb2joyOsH4r/UkqSJEmSJEm186OUJEmSJEmSaudHKUmSJEmSJNXOj1KSJEmSJEmqnR+lJEmSJEmSVLs+p++RbLJdJJv2lk30ol356XczKWW0Uz/1SzZ5JJMEc7B6dE3UL3QOkk29OZyS16pqeyaVLpsSmU3aoTGTSWAgpu/1HyUGUSIdpYNs27YtrJ9xxhm9alOmTAmPnTZtWlinuf/9738/rH/1q18N61u2bAnrURtLiZM6KHWI1spsal52vlH6SOb5RWlA69evD+v/9m//FtZXrlwZ1mfMmBHWZ8+eHdb37NnTq/bwww+Hx9L101jKJmE1O8X1cFXFWkjpSNmxnE2wJPS70VzMvuOQ7LO5itQ/Wovo3JQ2Fs3DUnj9HjduXOo827dv71Wjfmlvbw/r2XQruh+U8EUJodHYpmcpJXPRMzbql1J4jdq0aVNYf/TRR8N6lGSVTRml9wC61v6ixNwqUme7u7vDOvUzXTPNKxr3VKfncPT3XJQmWAqPY0o2pd+kFD9KWCPRuKKEROrfbCInrZU0ZjJ/o2eT7WlsEFpDaM2lZLtINsH0lFNOCeu//vWvwzqNPUrVzqSP0rMlO95pjB2K/1JKkiRJkiRJtfOjlCRJkiRJkmrnRylJkiRJkiTVzo9SkiRJkiRJqp0fpSRJkiRJklS7PqfvZVO0qkiUoXQQSmXJtoUSAqpIm6BkDDo37WxPqG8yiYLZ5MSqxkA2JSdqJ/VjNh2OUAoF9W/mmrJtaXb/ZpLzqjr3UPbOd74zrHd1dYX1bIoOJWkcd9xxvWrZhEZKTLv44ovD+g033BDWv/nNb4Z1Gg/HHHNMr1pbW1t4LLWRUnKof2mO07pIz51o7abUH0rZ+973vhfW161bF9Zf/epXh/W5c+eGdbqmqO2Z5LRSShk9enTqN3/nd34nrN97771h/Y477gjrgw2l1GTTy6L7Q8lDlMpHv0kJUdmk4sw7Wna8UQocyc5zSsOK1hHqR6rTWkT9Timm2XTnKFWMxhddPyXVUcrS+PHjwzrdVzo+Qgm0lDZGdUrDomuldZ3mWYTmKo2BbFphf9HvZ8ZUKaVs3LixV42eYzT3aQxSAtrmzZvDOiXY0fmjdYueqTTuKQGN1iG6vzTGo8S0UuK1Ivv+TddE56G20xynPsj8nUTPomzKMrWF3iMplS46P80N6i9ahxYsWBDWs+sQPUeitYjOTesWzW1KJD0U/6WUJEmSJEmSaudHKUmSJEmSJNXOj1KSJEmSJEmqnR+lJEmSJEmSVDs/SkmSJEmSJKl2fY4xoZ3wabd32k0+kzRFO9hnd4enJBTaxT+DUmYoaYd29qc6Jc1kE2ui9lDaBqWyUIpBFYl0Bzt/lO40ZsyY8FgaX9QWGjM0xig9ge5TJsGuivF4sPNkUyUziRiZBL+DHT8UTJ06Naz39PSEdUqUoYQY6tNozd26dWt47M6dO8N6Nhnp5JNPDuvU9ttvvz2sR2tRZ2dneCz1Fz1zqJ5N8aLUmygFidKb7r///rBOz4tXvepVYX3+/Plhne4frfVR39DzktKACL0bzJ49O6xTit+aNWvCen/TXQYKvStQClA22S5zDrrHNFdoXFFbMsm+dI6q2kjznNpIcyU6P72j0rmp7fQ8pKTV7Fo3cuTIXjVaoymxjNAYo3e07LvbrFmzetUWL14cHkvPBkrOoj6gsUSJsLR+R/ePxjuNAbqmqt4Xn0MJXZMnTw7rdB2rVq3qVaP+6ejoCOs0Bzdt2hTWKdmY5iGlzEX3Pbqeg52bnnvTpk0L6wsXLgzrlPpH73T33XdfrxrNzWwiPd0/Wv+yz67od6l/aZ7QOl9VUjvd16gvaW5m/07KjgHqA2p79DcJ/W1A95r+rqE5eSj+SylJkiRJkiTVzo9SkiRJkiRJqp0fpSRJkiRJklQ7P0pJkiRJkiSpdn6UkiRJkiRJUu36HD9EaQWURkGpClHKHO2yTwlolBKxcePGsJ5NDiCZJDVK06Pd9CmZgZJKqM9o5/woqYj6kdI+CLWFUg+ozyh9KUprovFF/UVojHV3d4f17BiL+oaSKUhVKYbNTLyjNpKhnL5HyWt032nc0/yhJI0o2YTSmyhRhtKbHn744bBO95GuldIrV69e3atG/UIpTZQ8QmtxNjmVEoGi+01rK6U90XOBEsjo/lH/Zp5TLS0t4bE0rinZis5D94/eJaL0rVIGX/peNtU2k7BLx9I7TvaZQmM/u45Hx9NaQfOZjs+my1JCEtWj9tCx9A6VTVPOpinRe3qUEErrH40ZGgOZd59SSmlvbw/rtDZGz4GlS5eGx1JKLK05lKhK94OeSdSXUQJVdC9KqS41ub+WLVsW1inpdfr06WE9+luGEh1pHaLj6e8bGpvURkpIvvvuu3vVaHxn37/pvtPYOfbYY8M6zZ/obxnqX3pmUz/S/ci+/9Ecj343m1ZLayLVSTaZMFqjswnr1C+0/tP9o/s0adKksB6tZ2vXrg2PpftBfzPQNR2K/1JKkiRJkiRJtfOjlCRJkiRJkmrnRylJkiRJkiTVzo9SkiRJkiRJqp0fpSRJkiRJklS7PqfvTZkyJazPmTMnrE+ePDmsRzvh0w7+EydODOuUgEGpIevXrw/rlDRAu/tH7aSkBeqXzs7OsE6pIZS+RLv703miVDrq902bNoV1Sh/IJjCMHDkyrNMYi9L3Wltbw2MprYDuEyVzUaIAJRDQGMskPFIbs+h+ZJOSojFG6RHZNKehjPqI1i1KHaOxlvldSuPYunVrWD/++OPDOqXe9PT0hHVqO6UgrVu3rleNUmbouUCJJNn0IkospHqUtEdJO7Se0zoRpRIe7HgaY7SeReeh9ZmS/SjxixJf6Px0TdlE1cMVrQvZ9Tpaa2mMU53aQvegqmQ7mv+RbFJd9promZVJ98y8K5bCSV60dtF7NKU10zyP1m9ai2jtpqRiSrDLHk/rSLReRM+LUko58cQTwzo9S+h9OZuGRcmk0f2g8Uhjid4Labz31wMPPBDWN2zYENbPO++8sB4l29F79rZt28J69n2d5smMGTPCeialnMYx/Sa1cd++fWH9oYceCuu05tLflgsWLOhVyya70jOe1i06ntJHKTE3Oj+Nb/rbj+YPvYfQ+anPMum52YR1eh+nsUdrCK2ttG5FCcm0VtL1UzoyjdND8V9KSZIkSZIkqXZ+lJIkSZIkSVLt/CglSZIkSZKk2vlRSpIkSZIkSbXzo5QkSZIkSZJq1+f0PdrBnpKQKMEkShTIprdRSge1hXb8p+QA2mU+Qm2kNBVKZsgmzVCdzhO1h9pIqSyUqJBJCSol18ZS4nSybHICoSQouiZKt6JxECXZDFRSXfZ3o3q2jdmxMRRE6TOlcIIJJQBRWgvVM8mmHR0dYX3evHlhPUrpKIUT6Sg1ZOPGjWE9SpmjBCRKTaX1n54XtM7R+SlRL1oXKQWL6vSbdDyNpWwiUzQ+smsrPeupf2nNJfS8GGyyz3J6pkRrZ/YeZNtCSVDZBLuoTuegejYJkNLkqH8zbaexTG2n36QkL0owovWb1oUowZLWV1rT6XhaL+j9mhJbqd+j9ZUSoun9LDvHsn97LFy4MKxH6XL0/KaUO1JVWvNzuru7wzolet11111h/ZRTTulVo2czzc3s+zf9XUXnoeOj+/jzn/88PJbmCaXFRu9npfA10Xygd6vo7yf6TUJjit5PaO5TGzN/t2bffSjBjvqA5jIdn0lapWPp3PQcoZRISvukOo336L2ekl3pWXTSSSeF9dNPPz2sH4r/UkqSJEmSJEm186OUJEmSJEmSaudHKUmSJEmSJNXOj1KSJEmSJEmqnR+lJEmSJEmSVLs+x9pkU31oF/9Melc26YvaSHXaIT+TPpRNKqJUlux5suev4jerSlLLXhPdp0xbsv1e1ViKfjebmlJVUl0VqX9VjYFmJw0OJEqvuOeee8I6jamnn346rGfm/owZM8JjZ86cGdYpBYrSngglNS1fvjysRylhlNiTHWutra1hneYstZ3S96KEFOp3Sl+hhDlKoKH0KUq8ojEW9SWlAVHqGf0mjV+6f9lkmsEmm7BLovlPKXs0xilNKfsMpjpda5QolU38o3GVfWZn30OiPqa5QveDEoanT58e1un8USLxwUT3g5KaKK163bp1YZ3S2Sg5iu43rbtRWh+txdQWOjc9G2jM0P2jeRAlVlHq19q1a8M6zSV6PvYXXTMl5K1YsSKsR8+spUuXhsdS/9MYoechzRNa56hPTzvttF416hcaU9lEThoPU6ZMCeu0Lu7atatXjcYrJQdSwjqtZ9R2+t3Zs2eH9TVr1vSqrVy5Mjz2kUceCeuUHrl48eKwTonSdK00xqJrpX6hsTFr1qywTutZJmW1lNzfGJTUR++09LdBf//G819KSZIkSZIkqXZ+lJIkSZIkSVLt/CglSZIkSZKk2vlRSpIkSZIkSbXr80bn27ZtC+u0KRZtYBdt9EUbYtEGqrRJG9Vpo76sqJ20KSZtIkmbP9KmhdHGoKXwxorUZ9EmeLSJWnaDWrp/1DeZNpYSb3Q5fvz48FjaLJfaTtdKfUNtpDGW2dS8qg3NsxvMZX63qjYOZbQmbt26NaxnNzSn80c6OzvDOq2VNDez6xBtJEobOk6dOrVXLbuuZDeopE096Xhqe7Tx6MKFC8Nj6V7TBq7UB7Te0Pnp/kXHZzeYp7FEG8HSRq20SSet6YMN3QMaz9RP0X3IbCx+sN+kOUTnzwaLROOWxjitLXQ8jf3seTJ1Wi+z/UL9TpvIUlAF3afovXvLli3hsfR8oTY+/PDDYZ3OT5vu0qbU0XOT5gZtFk6bt59++ulhfd68eWGd1mkaB5n3P+pf+s0lS5b0+dx9Eb1nl8L3iwJdontD95Y2fqZ1qyo0D6P7dcwxx4TH0hgkdDytT/Tco3o0fvbt2xceS8/mPXv2hHW6H7Te0N9Jd955Z1iP1go6B9Vprt17771hPbt5O4VLRBvST5o0KTyW1lZ6X6R1nr7H0N+tmzdvDutRX9I4zb7nUf8eiv9SSpIkSZIkSbXzo5QkSZIkSZJq50cpSZIkSZIk1c6PUpIkSZIkSaqdH6UkSZIkSZJUuz6n71F6BSWV0K7/meQo2tWdku0o7YNSWbKixAba8Z92u6ckjWgH/1I4CYr6nRKlogQTStvIphVmU2zo/I899lhYX7VqVa9alNZVSinjxo0L65S2sXfv3rBOY4n6jNJFoj7IJvNkZVMSM+3JJvu9EFE6CCVmZNO3aA2JklAoNYVSb7JJgNkEGpq30TVt2rQpde6WlpawTtdESTM0xilNJEqro3WFnmn0vKS1ks5DaMxE6yWl4BF61lFaC62VkydPDuvNTmIaaLT+UupV1B80D2ne0nig36Q5lH3/o3qErqmq1KsqZNP06P1k9uzZYf2ss84K6/SeR0le0Xs3vUfT/Kf0Kbqn2XWkvb09rEfvwJRKSOlTtF5SWh+lh1OqFs2DaK2jsUHPRkpDXbx4cVjvL1orKO3tpJNOCusnnnhirxqlZdPcpFQ3Sjkk1Ne0zkX17HszzcHsGp1536Dfpf6iuUn9TvOH0uQpaZrOE7WH/taiNZTeu+n+Zd8rMumutE7Q3/PR37il8NybMWNGWKfUUBp70Tsw/e1L9WwC7aH4L6UkSZIkSZJUOz9KSZIkSZIkqXZ+lJIkSZIkSVLt/CglSZIkSZKk2vlRSpIkSZIkSbXrc/oeJenQru60K3+U+kS7tFPyECUbUZoSod+lNITMOaiN69atC+uUPEcJDISSjaK0FkpwyabpEUq4oD6j9qxfv75XjVJWsmkblBxA94/qmQQl6kcad9mUD5IZ11lVjY2hIBqvpfB9pCS8adOmhfXu7u6wHq25lKZC6SDUxmwSFtUpIS9a/ygdhRJcaXxnEzOp7bRWRGOZkq1ozlKCFR1PdRpLmbSh7DMnu55Rv9M1DfXEz2z6XtRP1NfZRC269zT2s3Mlag+Nh0za0cHq9B5J60smsXTWrFnhsVSfM2dOWH/pS18a1o855piwftttt4X1TEpqdn2l+zFhwoSwTveDxhj9bvSsWrBgQXhsZ2dnWKcxQH+nUFuyYywyffr0sJ5N7KKEwP4644wzwjolr1OCW9QX9Hyj5xWNERrf1P/07KAUuGhO0HVmE0np3YfS5OjvIWpP9PcvPUOov+jv/OzfbPR3EiUHRu/MNL7pmUPXRO/LixYtCuu0RpPo/DSuFy5cGNYpeXTlypVhnfqX+ob6PVrnaMzQNVHb+2vo/mUoSZIkSZKkw5YfpSRJkiRJklQ7P0pJkiRJkiSpdn6UkiRJkiRJUu38KCVJkiRJkqTa9Tl9j3ZkpxQDSlTJpG5lU+Conk0po/NECQTZ5BxKK6B0Cjo/ySQhZdPxCB1fVdujvqH+onPQtWaTo+h4SrLJyKZMZcd7FSlWzRyPgw0lxFACBh1PfUppPI888khYj1JcKH2P0reoTm2kcU/rf2ZeZVNZaY5Tug21nX6XkmmiVJ1NmzaFx1KiIs0Tun+UNEv9S2loUXJWNn2F0oBOOeWUsE73g9o+ZcqUsD7YZJ+T2feWCM1nuseUKEVrGs3zTBoWHZtdR2mu0NyivqG0s2g9prS3JUuWhPWTTz45rJ9wwgmptsyePTusr1ixIqxH7+m0/lE/0vyn8bt69eqwTmOP1pHo/lH6FFm8eHGqLdlUMUpbjcb2zJkzw2OzibXZPjiUCy+8MKzT+0ZbW1tYj9IFqT+p32gMZscOrWf0DIpSvWkdHj9+fOrcNE8oeZ2SITPtoX6nNZfOTfeJ3iuob2jtjtYWun66p7SG0jil9xNKk6MUv+h+0/pMzxyay9n3a5JJYaS5R++u9H6W/VvxOf5LKUmSJEmSJNXOj1KSJEmSJEmqnR+lJEmSJEmSVDs/SkmSJEmSJKl2fpSSJEmSJElS7fqcvke7wNMu/rTzepSwk006o53kM8l+Bzt/FcdTigFdKyVvVCW6H9lEuma2pRTe9T/qM+ov6l+qZxORsmMsk0BQ1filvsmkSjbbUEjf+/KXvxzWe3p6wnpra2vq/JQwSYlMUbIJpa8QSrGJUtpK4XWO2kgpI1GayKpVq8JjFyxYENYp2YWeXaNGjQrrlO5Cx0dtp/QVSiqh+zR58uSw/uCDD4Z1Sneh80d9M3bs2NS5Ozo6wjrNA7p/W7duDeuLFi0K64NNNlEqk9ZJ56B7Rs8CSvWhtYjGFaUyRb9Lbc+mD9LalU3ZpHkepThRIhHV582bF9YprYrux8SJE8M6Pfuj+5FNX6ZnAD3XKIWMxsyxxx4b1qO207pI7xW7du0K63RNNG8effTRsL5+/fqwHs0bSt+jcUf39M477wzr/UXtomujdkWpabSW0fMwk8R9sLbQeSi9Nprj1HZa46hOv0kpc1OnTg3r9G6Vkf17PkrvLIXXaErqpPsXXSu9h9A9nT9/fljftm1bWKc1lJ7TdHy0jtJ6Q/1OiX/0XKA1l+ZB5m8Jeo5mk3z7y38pJUmSJEmSpNr5UUqSJEmSJEm186OUJEmSJEmSaudHKUmSJEmSJNXOj1KSJEmSJEmqXZ/T97JJeJTgEZ0nmwqW/c1suh+Jzl9VUl02Ba6ZiWmZe3ewelW/G9WbnY6XHWMk0zfZfm/muG62gfjNqlHKCqV0UBoRJWZQagilr0T3nZLkKNWJUlOyyWH0u3Tf16xZE9Yz58gm8ND9o/NQ0syWLVt61Sh9i1JsKJVl9+7dYT2b5JhJM8omtlFiD/VXNgmL0o8GG0oTon6iORcdT3OCxhXNT6pTeg+N50yaMKWO0fONxgOtiy0tLWGdxjP1WTQ+qe3URuoXqtM6TfeJxkzmnSA7z2nennDCCWGd2kiJpRF6xmZTlrP9TnXqm+j5SG2n66fEP5qT/UXJuDSvaOxH7eru7g6PpfcHmrN0vzZt2hTWOzs7wzqNk6jt9B6WSRg92PE0l2ltpbUlGps0XumZQ2OA1kRC/Utpi9E7FI07eo4SWp+y94/ejaMxSf3+2GOPhXVKE6X3POpfuq+05kRJewPxzeG3+S+lJEmSJEmSVDs/SkmSJEmSJKl2fpSSJEmSJElS7fwoJUmSJEmSpNr5UUqSJEmSJEm163P6XiZNpZTmpu9VpYrzN7vtVe2EH7UzmzJVVSpftu3R8ZTaUVVCYDOPb2aCXyl8/6q4pmaOx8Fm69atYX3BggVhPZOaUkopO3fuDOuUhBKlktCxlJxDdUIpIJRGtHr16rC+ffv2XjXqRxo7lBpHa8Xjjz+eOg8l4UUpMRs2bAiPnTVrVljPpvJR2yndJUpZKSV+BuzYsSM8dtKkSWGd+otSb2h9opSjBx98MKwPNpQ8RKif9uzZ06uWfT+j5C5KX6I6zf9Mei2ti3T9NN6oTmlvdDytgdE10VzZuHFjWCfR+lcKpzJR/fjjjw/ra9eu7VXr6uoKj6V0zGzSIo13SoIi0Tig5CwaM1TPpk3S71IiWDT2KIWX1miq0zX11/r168P6/PnzwzrN256enl61bD/Ts5aeKdRHmzdvDus0f6J3Ono/ozWOUuPo+ZlNSKa+idYzWp/p/YHeOWms0XsenaejoyOsR2nFUSJfKfyeQGMj+7dG9p02qtMzh9pIa2I2VZcSAmmuRmM421/Z7wiH4r+UkiRJkiRJUu38KCVJkiRJkqTa+VFKkiRJkiRJtfOjlCRJkiRJkmrnRylJkiRJkiTVrs/pe9kktcwO7pRikG1LVclrVbRloK4pcz8oZSCr2cl20TVl096yaX2kmWMsm2xXVT1zTdlxV1Va3+HozjvvDOuUskJpKpRAQ8dTskcmpTKTjlUKpw5RCgilwP3qV7/q83koSSS7blGaFJ2HUqYo9SbqM0oyomuifqdkExobVKdrilDKDJ2D0spWrVoV1in1jFKpVqxYEdaXLFnSq/bAAw+Exx4OWlpawnp2LYySdCgdj9LhaM0hNG7peUDrQjSGaIxTohmdm9pC45aOp9SgaP6vW7cuPJbWv4ceeiisU1LdSSedFNZPP/30sE7pe1HqEyWEUqoszVtaR+m+UtpY5l2axiM91yh9itY6Siej5C96Jh977LG9anPmzAmPpWfssmXLwvq9994b1vuLnm+//OUvw3qUmFZKfH/p3HQfqU6JbNT/NK+iBNNScolhlLJH61Z2jabz0PM26oPs3yU0N+kZRXOf0veoPa2trb1q2UQ6mj+0DtFaQddEfRONmdmzZ4fHUkokrUPUX5TiR+tcRrO/XRzqfcd/KSVJkiRJkqTa+VFKkiRJkiRJtfOjlCRJkiRJkmrnRylJkiRJkiTVrs8bnWc3LM5sRtvMc/fn/JmNu5q9kXNVm7RnzlNV/2Y1c7PwrKo2gc+0p6p+p/NUsRl5FZvUDxW00Tlt2EybP9Lm1JmNFUuJ7zuNheym69nND1evXh3We3p6wnq0IenGjRvDY2nDXdrslNA10aas1PboftA5aANkGjPZjcurmPs07qh/s/1IY4zuN21K29bW1qt2OG90Tv2U3bg7Giu0wSmNH9rIOftMobWI6lF7qI3ZDVSzG91SPYPmIY1Zuk/bt28P67SxNm2afOqpp4b16FqpjY8++mhYpzWKNl6mMZYN2YjWHQoNyL5D0fHUduozanu0YTeto/Rs2LRpU1inTZP764477gjrdM3z5s0L69Hm7tFaXQrPZbovtFZOnjw5rNM8IVGf0v2iOv0mPfcoGIfWCnoPidpDG8bTs5bW7Wz4SfZvjWhNoGPpeUEbw9NG8nSt48ePD+u0/kVrK7WR+pHGNW2mPxB/V/V34/Is/6WUJEmSJEmSaudHKUmSJEmSJNXOj1KSJEmSJEmqnR+lJEmSJEmSVDs/SkmSJEmSJKl2ubiiAKUkZFK6sil4WVWkjpUSX2tVaWRV7WyfOb6qtlSRYngwVY2DZp47k042EImKBzt+IFIPm3lP60LJSD/72c/Cemtra1invqAxRfUo2YMSqQglvlA6CCXNrFixIqxTGkyU4tLV1ZU6B/VjNqlp165dYZ3aE6W1UH/RmKEEK5pX2USxTOIVHUtpQ/Sb1HbqA0pszCY/Hq4o1TCbmBiNLUqkpIQuShfLPvsp8YjSh6LEo2y/0HijPqD1IpuqFfU7pSNRndpCtmzZEtaXLVsW1mmti/qdUqlo/aN+nzhxYljPpqFSMlX0TMqmhNEYo/FOzzVauyhpNGoPzb2tW7eG9c7OzrBedfoePbPpvlNfRO1asGBBeCy9b9DYmTBhQlinFDi677RuRWgdyq5PhPqA1hDq9+hdL5vsmn3foLFM/U7JdlGiIM2HqVOnhnWagzRPqG+yz8ZoTc88/0rh9Eh6plH/ZtP9qD6QhsbbniRJkiRJkgYVP0pJkiRJkiSpdn6UkiRJkiRJUu38KCVJkiRJkqTa+VFKkiRJkiRJtXve6Xskk5iTTe7KambqWPY3s5rZN81M9jvY8dn7kfndqpIDSRX3o6q2VJWgQTLJXAPRjwON+n/jxo1hnZKRKGWFEmgowSO6v5TSkTnHwc6zdu3asE59sHDhwrC+c+fOXjVKQKKUFRpT2YQYOn93d3dYj+7TtGnTwmOjlJlSOJmR0ldoHmaT8KIxTGOD7Nu3L6xTAg2NjcceeyysZ8fq4YqScaj/KN0puvc0rujcNH6yKT00PmnOReOQ7iOtf+PGjQvr1MZsEh5dUzRHOzo6wmOpjVOmTEm1hebtpEmTwjolU61atapXjdZXmrc0HqO1+2AoaZTGaqSqlD0aM5RaS8ln1GfRfaWxQevf/Pnzw/rs2bPDen/RWKP1l9acqN7W1hYeS8lz9Ju0btF5suePxgn1C61P1MbMb5bCYznz7kzju4p+Odjx2WTTPXv29Pk3M+c4GHruUJIj/W6U7kdrJa199IzK/g3dzBR0Ove6devC+lvf+taw/t///d8H/R3/pZQkSZIkSZJq50cpSZIkSZIk1c6PUpIkSZIkSaqdH6UkSZIkSZJUOz9KSZIkSZIkqXZ9Tt+jndcpaSCzq3s2qS67wzzthJ9VRWJYVUmAVSXbVdGWrGbf7yo0M8Wgqt+sKpmh2fc7QkkWgwmtK5TcQ0klEydODOt0Xyh5KEpUyabp0bkpTWv58uVhnfogSiopJU68o+QYSjqiNCBKmcr2DR0ftZOuk9pIyTHZFBtCc5/ud4T6hdpOaVqUbkj9S+8YmYTfw8GWLVvCejYxLLpnlIBGqW7ZxE9Ka6J7RmtjdE10DlpDTjjhhLBO44HmP/Uvpe+NHz++V43W7unTp4f1E088May3t7eH9Wy6Fc2tqC9pHaV+p/uUTb2i89NYjeYHJWSR6N6VwuOUxvvYsWPD+rx588L6WWed1atGzzVKd6VUvqrXv2ziHa0527dv71WjNY7uCz2vqO+yfZH5u5XmGj07aV3JJgRSH9CaEz1v6b0tm+xM15pNEqfzR2su9Qsl2NFcpnWrqr9DozGZef6VwnOcrpXWyoFAY+yWW27p1/kG11udJEmSJEmShgQ/SkmSJEmSJKl2fpSSJEmSJElS7fwoJUmSJEmSpNr5UUqSJEmSJEm163OET1WpcVU4nNLbqko0a3baW+b8zU67G4hku6zsbw5EG0l2rlaRzJidB4MtOSuSTfWkFChKoKFEjl27doX11tbWPreFEjMoeYp+c+XKlWGdUkNIdDy1hVLdduzYEdYpJYgSaCiZLJOeQ+Oe+oXSpMaNGxfWaf5QOlEm2Y7mMiUo0Viia6Lz0DXRPBtsawil79FYyaQJUToSzSFC6UjZ9MZMkhedm+YzzaFZs2aF9ZaWlrBO43PdunVhPbommm8bN24M61OmTAnrkyZNCuu0pmfXwCgRjdbF7D2lFD+6r5S+R9cUnYfmBo0NajuNAbomOj89w6Pz0FpMz5fo3pXCz6n+oj6iZ38mNZPGQjbVM5u+l02Ny/wmjVdaPygZc9q0aWGdEjnp+RnVqV+yCXb0rkTPLuobmvtRe6pK9qN6Nt2Z+iA6D10/rROZc5eSf2fI/I2X/Vuu6r99B9dbnSRJkiRJkoYEP0pJkiRJkiSpdn6UkiRJkiRJUu38KCVJkiRJkqTa+VFKkiRJkiRJtetz+h7JpnFVcW4NTc1M/Wt2GmKzEwszsqkVlNgQHU9pHtnrpwSRwYSSXQilb2XTXSjBJEr2oHQbuud0bmp7T09PWD/55JPDOo2fKJWKUlMoxYZQOhwloUyYMCGs05iNxj6lOtE10bmzKUTZlLRINsGFxgwlgdHxQz3Bk+4l9TeNiag/qnq+0fikdCAaV5nxSfeR0sV++tOfhnVKN7344ovD+vTp08N6V1dXWI/uEyX73X///WH97rvvDuuUhDd16tSwPnLkyLBO94kSpSJ07wjNZxqTNGZofkycOLFXjcYp/Satx/RcW7NmTVin1LLNmzeH9cjLX/7ysE7XRGlu9OztL+p/ul9jxowJ6zNmzOjzsbTGUV8QamMV6Xt0jj179oR1mg+E5ib9Lp0/Op7WA7Jt27awTu+RtA5lU1+jcUDrEK3zNJboPJnnayncl9H7Jc3Zjo6OsJ59N6jq3aeKd4mqDa63OkmSJEmSJA0JfpSSJEmSJElS7fwoJUmSJEmSpNr5UUqSJEmSJEm186OUJEmSJEmSatfnrfmziV6ZHdybmeCnwaOZ42Cg0vQy58mmHlTVX5TkENWz56b0CEqbGMoojWzDhg1hndJdKAEoSnEZO3Zs6hw0FrZv3x7WaQy2tbWF9ShJqZQ4xSU7RigdhdJqxo0blzoPpSFGfUDHZlKwSuE+yKbbZBLesnOcUoJovGcTkSiJia7pcEVzK5N+Wko83rLJqtlnB52H5gqdP0pxonNQUhGtXWvXrg3r3/zmN8P6zJkzw/q8efPCepTitHz58vBYSvajFDJKvfrWt74V1mkd/d3f/d2wHq0XtEbv2rUrrFPqKc1nWqOoTs+qqM8omZHGHaXjUUoiJXPRs4QSvqLfve+++8JjKSWW0iBbW1vDen/RNdP9or6I5if1Dz3fsmmfmWTcUnLvpdmEUZpX1EZqS3YeRmOf7hGlUdIYpLlJ6Xu0RpMqnmkkm8xISYM0JqP393vuuSc8lpKds8+6bPoevY9G10rXX9f3GP+llCRJkiRJkmrnRylJkiRJkiTVzo9SkiRJkiRJqp0fpSRJkiRJklQ7P0pJkiRJkiSpdn1O38uiFIxswtjhbigmBA7UPcqMmWan6Q1EImSzr6mKtCo6R/bclNoxFNB92bt3b1in5KXsGIwSNihNhRJ1KFGG0vfoPJTg0d3dHdZXrlzZq0YJU5TGRolMlHhFySZ0HkqgiVJcKO2EUm8omYfqNDYolYVSjqK20znoNyklklKCqlrnBluCJ80J6u9M+hDdG5r/NIcmTZqUagslEtE1tbS09KpRQtSiRYvCOrWd1pZ169aF9VWrVoX1W265JaxH85/WkOzYpFSmnTt3hvV77703rNP9jpLaHnvssfBYajulldKYya67dHzU79TG1atXh/UHHnggrFNCKLWF3lsoVTUae5kU11JK2bJlS1in9aS/6PdpjlPfReOK+of6M/O8KiWXLlZKNcmm9O5D6xO1keYszU963kbtpP6ie01znOYsXSuNGerLqJ30Lkq/Sf1I71A0Nuj81O/R+adNmxYe+/DDD4d1WkNpzNB9zf59Fs0/GgP0TKe29Jf/UkqSJEmSJEm186OUJEmSJEmSaudHKUmSJEmSJNXOj1KSJEmSJEmqXZ83Oq9ik+Ssgdhs+mCi3x2KG51nDebN67Ntr+Jaq+ovGnuZTRz7U4/QpoS0aTRt7DoUZO8vbdA7c+bMsE4bpkebiWY2xSyFN++kTSRpg0banJU2F47GycKFC8NjaeNK2qBy06ZNYX3Xrl1hncZytFlwKaWMHz++V43GN210TpvG0vG0QSz1QWYjddrQkjYvpX6kDaxp09ShHo5C9yZbj+4ZbQxM9zK7ySvJvhdG6w6NK5q3S5cuDes0b7du3RrWaTNrak805+gcNG9p7aY2rl27Nqxv3rw5rNP6vWTJkl412qCW5icFT1Cd+pHuE7U9GjNr1qwJj/35z38e1mnDYEJrF6FritpOazFtBt7W1hbWaSz1F90vai+tLdH7DG3a3dHREdZpPaM6PT9pfWpvbw/rUR/Q8ye7GTuhdzHqdzo+uh80p+heZwNwss8L6svoPtH4orbQ/aB5VdW1RkEMM2bMCI+lIAYKhaE2Ut9QG+n4aIzR2kfP4y9/+cthvb/8l1KSJEmSJEmqnR+lJEmSJEmSVDs/SkmSJEmSJKl2fpSSJEmSJElS7fwoJUmSJEmSpNr1OX0vm+hFu71XkVZ3OKX0DJVkoOejqgTCTJpc9jcPp/tU1dxo9pyMjqfUJkrZo3S2lpaWsD6YZPufUCIdpb1RykiUMERJIlFiSCmcVkPXRPexp6cnrFMK0vz583vVKH1w3LhxYZ2SRygJhVJGKA2RErWipMFp06aFx9L9oH6nBB4aA9mkoOj4bHoQJTzStWZR27PJPwON1k7q78zzkO47rctRYmQp+QSubOpf1E4aJzTf6DcprZOulRK7aFxFfUNtnzJlSlinflm3bl1Y37lzZ1invqG0pmiO0r2m5w7VaVzT+bPvIVHyK6W7ZlJGD9YWmk/0zKDn6eLFi/v8mw899FBYp/Vh+vTpYb2/6H5Rehkdv2HDhl41Su6ieUJzkPqC0v1ojlPCZLRe0riktmRT+bLPW5pvUZ3OTeOb3s/o+OzzgtoTzYns3KS1kmTTgWmORygZk5I0aY5RG7N/42XelShN+Z577gnrV199dZ/P3Rf+SylJkiRJkiTVzo9SkiRJkiRJqp0fpSRJkiRJklQ7P0pJkiRJkiSpdn6UkiRJkiRJUu36nL5HKQnZJLyonj0HJRVlk6OqSGQ7nFLdmm0gUvZKiRMFqjhHf86TPX8mVYISEqpK68um4UTHU/IHJVZUkWRxuKpq7lPa2/bt28M6JWpFiR/Nng90H7dt2xbW165dG9YffvjhXjVKAaFUvvb29rBOaX00Nuk5QukuXV1dvWqUmkKpfDT3KZWFEn6yKWmZc1AyD/VLNp2S+p3OQ8cfrmjOkexcjNBaQSltNN4yz7dSeDxHdZqflJr3yCOPhHVKAj3zzDPDOs0JWnejcU7psmeffXZYHzlyZFi/5ZZbUm2hPps9e3ZYj9pObaFrorGUTcHMPjejZwmtUTQ3aI2iZwC952STv1avXt3n34yeI6VwYhk97/qL5kM26TVKwqPnPj0Pp06dGtZpzc+2cevWrWF9zJgxvWqUsElrH41NSsykOqFrisYJPbOpTmON1grqm2yibHQeOpb6d/fu3WE9+55H94Pe6aJ20vXTObLJvHQeGpN0n6K2U7/Qu0HV/JdSkiRJkiRJqp0fpSRJkiRJklQ7P0pJkiRJkiSpdn6UkiRJkiRJUu38KCVJkiRJkqTa9Tl9b/HixakTZ9IQmp2+l03lI5m2D0VVpAGVUk3yV7PT9JqZykfHUopNtn+ruk9Re5rdxhciStjYsmVLWKfkpShRpaOjIzw2SpkphddKSsOh1BBK36N6lIazfPny8FhKK8wmPVIfUBujdMNSStmxY0evGs2TiRMnhnVaz2hsUAINHZ9B546usxROvck+v7PpdIMtfS+TSHcw0bsVpetQyh7dG0oeovQlumeZpB5aWyhdjFLgKAFt8+bNYf3YY48N60uXLg3r0TOLnmOtra1hndZ0Os9xxx0X1mntosTSxx9/vFeN0gqpf2ltyc5nembQmInWTEoIpP6ltlAK2bx588L6/PnzwzpZtWpVr9qePXvCY6kfKfk8Sqx9PijRi+5LJmGNUiQpBY/mD7WRxiw9b+kZF52fjqUxRX/7ZtP36HfpfkTPALpHjz76aFivKpEz+zyK1oRsOl72PkUpkaVwGzNtp2c6tZGOp3dOen5nkyLpmiI096rmv5SSJEmSJElS7fwoJUmSJEmSpNr5UUqSJEmSJEm186OUJEmSJEmSaudHKUmSJEmSJNWuz+l7lABBsol6VZy7quObfZ7D3UAlo1H/ZlJvDrdUt8E8ZqpIyqQ6pVAMZUcdFS+3lHiSTemJEpboN9va2sI6HU/pINnUOLqm6DyUYkPnoHQ4WhMoqYR+l64pSnCK7sXB6tnkOWpLJvW2lHgsUboNJVtRglUmkfSFoKpnVnTPKNGM0nVonNC6TClL2YTFCK0tlNhF10T9SOe5++67wzqtI1ESHvX7Aw88ENZpradUN1qjaB2htkf3j+4poTUnmwRF94nW9eiZdNJJJ4XHZucBpb9R0hStdZk1c8KECeGxlBRHf3vNnTs3rPdXNkWR5m2UDEnrTU9PT1inRFf6TRrLlFRMoj6o4plaCidmUpoepYZm3iOpv7L9S+l7NDZp7pNojNFco/6iOU5t2bBhQ1in+zpr1qywPnny5LAeofWf0DqUTdXNjGEaX5mkvufjhfl2KEmSJEmSpAHlRylJkiRJkiTVzo9SkiRJkiRJqp0fpSRJkiRJklQ7P0pJkiRJkiSpdn1O36PkDZJJ48qmz2RTbKpKvami7WpuAmMzUx+b7XBrYzPT94YCmvt0zZRiQ6kWdHwmYWnnzp3hsbt27Qrr06ZNC+uUAjJq1KiwTmkflJwSpZJQcg71F52bUlwoaSybHJM5NyXzUGoUoTGWSQgklMxD6XtVJWlmEtsGI5oT2SS8qJ8o1YfmCiWd0W9WlXgUtZ0S0KhfaC2iBDRKiKJrXb58eVhfuXJlrxr1C43l6dOnh3U6Dz1jaN1tb28P61GfZZ9fdD8osYvOQ4lrtEZF94+eU93d3WGd7sfUqVPDOp2fUg/Xr18f1qMxSWs03Y/FixeH9U2bNoX1/qL7SO2ilK5o7lMC5j333NPnc5TCqYv0rpBNhoyuicZO9t2W7jslB1LiHYnuH907et+gxD/qL3ruZJM3M+eg/qJz0/OF5iytQ+PHjw/rM2fO7FXLjhkaG9QHtP5nfzda02leZ9Na+8t/KSVJkiRJkqTa+VFKkiRJkiRJtfOjlCRJkiRJkmrnRylJkiRJkiTVzo9SkiRJkiRJql3t6XuRZqfvVfW7mTSywYxSOJqtmQlu2XNXlaoYnafZY6aq8zeznS/E1MoxY8aE9WyCFSXZRGs0JWZQ+h4lLFGqByV1ULoL3feobyh9hpJH9u7dm/rNTFtKySUK0vOS+oXudTapiZLJKIUxSnikZDY6B/VLVXM8s0ZHSTilcNJOneg6aG7RczgaK3RvKHmOUtpoDlGqGZ2/tbU1rEfJRrRGUT27LlJqJPUvtT26Vrp3NIeoLZQC19bWFtYpBY7GQXRNNG/p2ZBNx6R0Q6pTklfUN694xSvCYyk566GHHgrrs2bNCusTJkwI66tXrw7rY8eO7XOd1mha6x977LGw3tXVFdb7i9br7PoUofcEGmuUyke/edppp6WOp3sQyaZRUn9RPZvKSvUI3VOaa/RuRYm89D5Da2gm9ZBkE083btwY1ikFlK6J1txoDNN6kB1LdJ8y/VUK9000Pug5umrVqtRv9pf/UkqSJEmSJEm186OUJEmSJEmSaudHKUmSJEmSJNXOj1KSJEmSJEmqnR+lJEmSJEmSVLs+b+EepfQMFs1MdRuKsolPA2GgEhubqarxWEWqZPbYoTzHqD/p2mitpEQSSjyhpBJK69uxY0efz00pRTT3Ke2D+oDSiyiVJEq8o/4aP358WKeEGLp/1L8TJ04M65S+EvU7pf7Q/cgm9lC/U6oQpYFF56d0rGxbsmlOVbxjdHZ2hvXDIX0ve92ZxBxC85bOQfOf2vLEE0+EdRqH0Tync9B8o3TMjo6OsE7rBSUNUkJelIK2aNGi8NiLLrqoz+cohdcuqlMCFSUWRuvR5s2bw2Oj9awUXi/pfhBai+iZMWPGjF41WqO2bt0a1pcsWRLWaa2fM2dOWH/pS18a1n/5y1+G9YcffrhXjcYppenRtVadkp1dn6gevZ/QuWlM0bi/6667wjo9gyiVL7suRiiljfqFfpOS12gs03iI+iCbDkrrNiWyUZ3W1mnTpoX1qC+zqY80lxcvXhzWqR8pYXP58uVhPbrfp59+engsjdNs8ibJpvVFfXn77beHx/7d3/1dqi39NXi/NEmSJEmSJGnQ8qOUJEmSJEmSaudHKUmSJEmSJNXOj1KSJEmSJEmqXZ83Os9uZlrFBtJVbZ5c1WbLQ2HT5r7IbuzcbFWMpWZvaJ4Zq3QsbeyX/c2sgbjfg2kuZdc+QhvC0ua0tAkobQDe09PTq0ab1tLmwrQBOm3qSZtF0obm06dPD+tRX7a0tITH0oaW1L+0MSYdT7+7adOmsD5u3LhetUmTJqXaQpud0ppA/U4blWY2pKaN9GkTzV27doX17PzIbmw6mNaQUqoLiYjqtFZQ39E8p83Fs88s2kg32nCVxhv9Jm3+SpvF0tinDacXLFjQ5+Nprdi5c2eqXsW8LYXvX7Re0Dmi9awUXi9p/nd3d4d12tCcNo2P7seNN94YHksbZNNGv7ROH3/88WG9vb09rNP6HdWzISD33XdfWM++L/YXreP0PIjq1D90btosnJ57t912W1inOU4b2Ueyz5nss5zWbpqHNG+j8ANqC73P0Tyh42m+rVmzJqxT26MN0DPjqxR+jtAYo2ulYIxVq1aF9ei9kPol+y5DG8ZTP2bDlKL20Jipi/9SSpIkSZIkSbXzo5QkSZIkSZJq50cpSZIkSZIk1c6PUpIkSZIkSaqdH6UkSZIkSZJUuz6n72V3ZG922tnhYiheZ7NTjZp5/sFwP6pKlcyeP9s3lIBSRVuGMrpmSo6h9D3qf0rwiNJEKL2JUqAorY/SV+i5QG0/8cQTw/r27dt71ahfKL2Ijqe0FjqeUqaoz2bOnNmrRgku2cQk6t8oaac/9SixLNu/lL6VTWyrImWvijXrcBf1ByUPUV9Tqg+lt1FaH61pJFqjKDGIzk2pSTQOM2O/FE7Dmjx5cp9/c926danfpPuxcePGsE7XROM/qlOKKa31XV1dYZ2Stmi9oEQ0anvUxz/+8Y9T56a2UJ369/777w/rv/jFL8L6zTff3OdzDDRKDGtrawvr9JyI7iOtH7Tm07sqrXM0dug8tM5F56dz0BihZDQ6D6032YTN6F2Bzk1toftBawK9K9HvZub4li1bwmNnzZoV1um5QKL1vBROPaR5EK31lJjZ2dkZ1jOpqaVw39D6R6nX0fpHz6i6DP03OEmSJEmSJB12/CglSZIkSZKk2vlRSpIkSZIkSbXzo5QkSZIkSZJq50cpSZIkSZIk1a7P29VnU22amTBWVcJa9jxR27NpSoPBQCWmNfN3qzo3jZnMWKriHAc7PptEkpmr2Xnd7KTBgUTXQP1PSWqUDrdnz56wTgk0UZrStm3bwmMpZY/S+lpaWsI6pepQmsiCBQvCepQ+RckjlBBD/U6pLNSP9LujRo0K61GiCt1rStShtBpCbcympEWpOtQWStqhZ2BV7wzUl9F6RmPjcEBtyyYbR2gNodQkSo7KpinRPKd1JDMmKAWInmM0z2ns0xoYJYGWEice0XxeuXJlWH/sscdSv0n3g9DxY8eO7VXbunVreCw9M6iNdE9pTPb09IT1n/3sZ2H99ttv71W75ZZbwmMHOjlqMMuuv3Tfo/cWSq6luZxJ9iuFkwNpzaXUzOh3s3OQxiCtFdS/2ffL6Frp2Ux1ajvVs+ehlNENGzb0qlGC6etf//qwTv1FzwWq0zNz/vz5YT0aH3fffXd47EMPPRTWKYGWnqPr168P69Rnp556aliP3scH+puG/1JKkiRJkiRJtfOjlCRJkiRJkmrnRylJkiRJkiTVzo9SkiRJkiRJqp0fpSRJkiRJklS7PqfvVZEQU5WhkNw1lFSVhthMh1Mbqxq/2bQUVYvGFKVX0H2hVDdKlKHUuCjBg5KUKJEq2/bRo0eHdUpqokSmKN1v7dq1qXNTSg7dJ0ogi1K2Dnb+qO10DupfSoLJJjlS+h71QTSWqI00TrNpn1WJ2plN/KsT3WNKKso8J+je0D2gNL05c+aEdVpzKO2H5mg0PuncdC8pkYiStuhaaQ5t2rQprEfjjRK1fvWrX4V1uiZaR6mNdK2UhhiNpfvuuy88NkrC0tD37W9/O3X8JZdcEtaj5yHN8WwiHSWjtbe3h3Uay7QmPPzww71qlIw2fvz4sE5znNbzbJpwJgmVnuVV9Tu1kd47V6xYEdajZyOdm9pCY4yegdTvdJ/oPNHYe9nLXhYem1mfS+H3OXqXoGRTOk+UQEtjoy6H7xucJEmSJEmShiw/SkmSJEmSJKl2fpSSJEmSJElS7fwoJUmSJEmSpNr5UUqSJEmSJEm1G9Ywyk6SJEmSJEk1819KSZIkSZIkqXZ+lJIkSZIkSVLt/CglSZIkSZKk2vlRSpIkSZIkSbXzo5QkSZIkSZJq50cpSZIkSZIk1c6PUpIkSZIkSaqdH6UkSZIkSZJUOz9KSZIkSZIkqXb/H7OQ9+Z3c2d3AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x400 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get a batch\n",
    "images, labels = next(iter(training_loader))\n",
    "\n",
    "# Unnormalize a few images from the batch\n",
    "def unnormalize(img):\n",
    "    # Use values matching your actual normalization\n",
    "    mean = torch.tensor([0.485, 0.485, 0.485]).to(img.device)\n",
    "    std = torch.tensor([0.229, 0.229, 0.229]).to(img.device)\n",
    "    return img * std.view(1, 3, 1, 1) + mean.view(1, 3, 1, 1)\n",
    "\n",
    "# Display with proper channel handling\n",
    "fig, axes = plt.subplots(1, 4, figsize=(12, 4))\n",
    "for i in range(4):\n",
    "    img = unnormalize(images[i].unsqueeze(0)).squeeze(0)\n",
    "    img = img.permute(1, 2, 0).cpu().numpy()\n",
    "    axes[i].imshow(img, cmap='gray')  # Force grayscale display\n",
    "    axes[i].set_title(f\"Label: {label_map[int(labels[i])]}\")\n",
    "    axes[i].axis(\"off\")\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e253eda5",
   "metadata": {},
   "source": [
    "# Base Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60da6d19",
   "metadata": {},
   "source": [
    "### Define Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e811ba57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseFERModel(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super(BaseFERModel, self).__init__()\n",
    "        num_classes = params['num_classes']\n",
    "\n",
    "        # First convolutional layer\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2) # Output: 32x24x24\n",
    "        )\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            #nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            #nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.layer6 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, 3, 48, 48)\n",
    "            out = self.layer1(dummy_input)\n",
    "            out = self.layer2(out)\n",
    "            out = self.layer3(out)\n",
    "            out = self.layer4(out)\n",
    "            out = self.layer5(out)\n",
    "            out = self.layer6(out)\n",
    "            flattened_size = out.view(1, -1).size(1)\n",
    "\n",
    "\n",
    "        # Fully connected (dense) layers\n",
    "        #self.fc1 = nn.Linear(in_features=1024*1*1, out_features=1024)\n",
    "        self.fc1 = nn.Linear(in_features=flattened_size, out_features=1024)\n",
    "        self.dropout = nn.Dropout(params['dropout_rate'])\n",
    "        self.fc2 = nn.Linear(in_features=1024, out_features=256)\n",
    "        self.fc3 = nn.Linear(in_features=256, out_features=num_classes)\n",
    "       \n",
    "        #self.log_softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, x, return_embeddings=False):\n",
    "        output = self.layer1(x)  #  first layer\n",
    "        output = self.layer2(output)  # second layer\n",
    "        output = self.layer3(output)  # third layer\n",
    "        output = self.layer4(output)  # fourth layer\n",
    "        output = self.layer5(output)  # fifth layer\n",
    "        output = self.layer6(output)  # sixth layer        \n",
    "        output = output.view(output.size(0), -1)  # Flatten for the fully connected layers\n",
    "        \n",
    "        # Embedding extraction (no dropout)\n",
    "        embeddings = F.relu(self.fc1(output))\n",
    "        embeddings = self.fc2(embeddings)\n",
    "        embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "        \n",
    "        # Classification head (with dropout)\n",
    "        #logits = self.dropout(F.relu(embeddings))  # Reintroduce dropout here\n",
    "        logits = self.dropout(embeddings)\n",
    "        logits = self.fc3(logits)\n",
    "        \n",
    "        return (logits, embeddings) if return_embeddings else logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcf315ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseFERModel_V2(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # Stem\n",
    "            nn.Conv2d(3, 64, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            # FER-Specialized Blocks\n",
    "            DepthwiseSeparableConv(64, 128),\n",
    "            DepthwiseSeparableConv(128, 256),\n",
    "            DepthwiseSeparableConv(256, 512),\n",
    "            \n",
    "            nn.AdaptiveAvgPool2d((1,1))\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, params['num_classes'])\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, return_embeddings=False):\n",
    "        # Feature extraction\n",
    "        x = self.features(x)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        if return_embeddings:\n",
    "            # Return embeddings before final classifier\n",
    "            embeddings = self.classifier[:-1](x)\n",
    "            logits = self.classifier[-1:](embeddings)\n",
    "            return logits, embeddings\n",
    "        \n",
    "        # Full classification\n",
    "        return self.classifier(x) # logits\n",
    "\n",
    "def DepthwiseSeparableConv(in_c, out_c):\n",
    "    return nn.Sequential(\n",
    "        # Depthwise\n",
    "        nn.Conv2d(in_c, in_c, 3, padding=1, groups=in_c, bias=False),\n",
    "        nn.BatchNorm2d(in_c),\n",
    "        nn.LeakyReLU(0.1),\n",
    "        # Pointwise\n",
    "        nn.Conv2d(in_c, out_c, 1, bias=False),\n",
    "        nn.BatchNorm2d(out_c),\n",
    "        nn.LeakyReLU(0.1),\n",
    "        nn.MaxPool2d(2)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41261683",
   "metadata": {},
   "source": [
    "### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a2f5287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "BaseFERModel_V2                          [128, 7]                  --\n",
      "├─Sequential: 1-1                        [128, 512, 1, 1]          --\n",
      "│    └─Conv2d: 2-1                       [128, 64, 48, 48]         1,728\n",
      "│    └─BatchNorm2d: 2-2                  [128, 64, 48, 48]         128\n",
      "│    └─LeakyReLU: 2-3                    [128, 64, 48, 48]         --\n",
      "│    └─MaxPool2d: 2-4                    [128, 64, 24, 24]         --\n",
      "│    └─Sequential: 2-5                   [128, 128, 12, 12]        --\n",
      "│    │    └─Conv2d: 3-1                  [128, 64, 24, 24]         576\n",
      "│    │    └─BatchNorm2d: 3-2             [128, 64, 24, 24]         128\n",
      "│    │    └─LeakyReLU: 3-3               [128, 64, 24, 24]         --\n",
      "│    │    └─Conv2d: 3-4                  [128, 128, 24, 24]        8,192\n",
      "│    │    └─BatchNorm2d: 3-5             [128, 128, 24, 24]        256\n",
      "│    │    └─LeakyReLU: 3-6               [128, 128, 24, 24]        --\n",
      "│    │    └─MaxPool2d: 3-7               [128, 128, 12, 12]        --\n",
      "│    └─Sequential: 2-6                   [128, 256, 6, 6]          --\n",
      "│    │    └─Conv2d: 3-8                  [128, 128, 12, 12]        1,152\n",
      "│    │    └─BatchNorm2d: 3-9             [128, 128, 12, 12]        256\n",
      "│    │    └─LeakyReLU: 3-10              [128, 128, 12, 12]        --\n",
      "│    │    └─Conv2d: 3-11                 [128, 256, 12, 12]        32,768\n",
      "│    │    └─BatchNorm2d: 3-12            [128, 256, 12, 12]        512\n",
      "│    │    └─LeakyReLU: 3-13              [128, 256, 12, 12]        --\n",
      "│    │    └─MaxPool2d: 3-14              [128, 256, 6, 6]          --\n",
      "│    └─Sequential: 2-7                   [128, 512, 3, 3]          --\n",
      "│    │    └─Conv2d: 3-15                 [128, 256, 6, 6]          2,304\n",
      "│    │    └─BatchNorm2d: 3-16            [128, 256, 6, 6]          512\n",
      "│    │    └─LeakyReLU: 3-17              [128, 256, 6, 6]          --\n",
      "│    │    └─Conv2d: 3-18                 [128, 512, 6, 6]          131,072\n",
      "│    │    └─BatchNorm2d: 3-19            [128, 512, 6, 6]          1,024\n",
      "│    │    └─LeakyReLU: 3-20              [128, 512, 6, 6]          --\n",
      "│    │    └─MaxPool2d: 3-21              [128, 512, 3, 3]          --\n",
      "│    └─AdaptiveAvgPool2d: 2-8            [128, 512, 1, 1]          --\n",
      "├─Sequential: 1-2                        [128, 7]                  --\n",
      "│    └─Linear: 2-9                       [128, 256]                131,328\n",
      "│    └─BatchNorm1d: 2-10                 [128, 256]                512\n",
      "│    └─LeakyReLU: 2-11                   [128, 256]                --\n",
      "│    └─Dropout: 2-12                     [128, 256]                --\n",
      "│    └─Linear: 2-13                      [128, 7]                  1,799\n",
      "==========================================================================================\n",
      "Total params: 314,247\n",
      "Trainable params: 314,247\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 2.41\n",
      "==========================================================================================\n",
      "Input size (MB): 3.54\n",
      "Forward/backward pass size (MB): 698.88\n",
      "Params size (MB): 1.26\n",
      "Estimated Total Size (MB): 703.68\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "params={\n",
    "        \"initial_filters\": 8,    \n",
    "        \"dropout_rate\": 0.2,\n",
    "        \"num_classes\": 7}\n",
    "\n",
    "#base_fer_model = BaseFERModel(params).to(device)\n",
    "base_fer_model = BaseFERModel_V2(params).to(device)\n",
    "print(summary(base_fer_model, input_size=(BATCH_SIZE, 3, 48, 48), device=device.type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d81fda9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oreda\\AppData\\Local\\Temp\\ipykernel_47144\\970727120.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if return_embeddings:\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "base_fer_model = BaseFERModel_V2(params).to('cpu')\n",
    "base_fer_model.eval()\n",
    "\n",
    "input = torch.rand(1,3,48,48)\n",
    "torch.onnx.export(base_fer_model, input, \"ourbasemodel.onnx\", verbose=False, \n",
    "                 input_names=[\"input_names\"], output_names=[\"output_names\"],\n",
    "                 export_params=True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dc8a14",
   "metadata": {},
   "source": [
    "# Create Train and Test functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf63633",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cee4304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_pred,y_true):\n",
    "    top_p,top_class = y_pred.topk(1, dim = 1)\n",
    "    equals = top_class == y_true.view(*top_class.shape)\n",
    "    return torch.mean(equals.type(torch.cuda.FloatTensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e3b04bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, criterion, optimizer, device, current_epoch, epochs):\n",
    "    \"\"\"\n",
    "    Train one epoch of the model.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The  model.\n",
    "        dataloader (DataLoader): DataLoader for training data.\n",
    "        device (torch.device): Device to train the model on (CPU/GPU).\n",
    "\n",
    "    Returns:\n",
    "        training_loss (float): Returns epoch_loss / len(dataloader)\n",
    "    \"\"\"\n",
    "    model.train()  # Set model to training mode\n",
    "    epoch_loss = 0.0\n",
    "    epoch_accuracy = 0.0\n",
    "    tk = tqdm(dataloader, desc=\"EPOCH\" + \"[TRAIN]\" + str(current_epoch + 1) + \"/\" + str(epochs))\n",
    "\n",
    "    for t, data in enumerate(tk):\n",
    "        images, labels = data\n",
    "\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Compute log probabilities from model\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "\n",
    "        # Update model parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate loss for logging; Total loss\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        epoch_accuracy += calculate_accuracy(logits, labels)\n",
    "\n",
    "        # Print/log training loss and accuracy for this epoch\n",
    "        tk.set_postfix({\n",
    "            'loss': '%6f' % float(epoch_loss / (t + 1)), \n",
    "            'acc': '%6f' % float(epoch_accuracy / (t + 1))\n",
    "        })\n",
    "\n",
    "    return epoch_loss / len(dataloader), epoch_accuracy / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7824849d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_one_epoch(model, dataloader, criterion, device, current_epoch, epochs):\n",
    "    \"\"\"\n",
    "    Test one epoch of the model\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model.\n",
    "        dataloader (DataLoader): DataLoader for training data.\n",
    "        learning_rate (float): Learning rate for optimizer.\n",
    "        device (torch.device): Device to train the model on (CPU/GPU).\n",
    "\n",
    "    Returns:\n",
    "        training_loss (float): Returns epoch_loss / len(dataloader)\n",
    "        \n",
    "        running_acc (float): Returns epoch accuracy\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    epoch_loss = 0.0\n",
    "    epoch_accuracy = 0.0\n",
    "    tk = tqdm(dataloader, desc=\"EPOCH\" + \"[VALID]\" + str(current_epoch + 1) + \"/\" + str(epochs))\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():  # Disable gradient calculation for testing\n",
    "        for t, data in enumerate(tk):          \n",
    "            images, labels = data\n",
    "\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Compute log probabilities from model\n",
    "            logits = model(images)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += images.size(0)            \n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            # Accumulate loss for logging; Total loss\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            epoch_accuracy += calculate_accuracy(logits, labels)\n",
    "            \n",
    "\n",
    "            tk.set_postfix({\n",
    "                'loss': '%6f' % float(epoch_loss / (t + 1)), \n",
    "                'acc': '%6f' % float(epoch_accuracy / (t + 1))\n",
    "            })\n",
    "\n",
    "    return epoch_loss / len(dataloader), epoch_accuracy / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81b39d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate_model(model, training_dataloader, testing_dataloader, epochs, learning_rate, device):\n",
    "    \"\"\"\n",
    "    Train and Test the speech recognition model using CTC loss.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model.\n",
    "        training_dataloader (DataLoader): DataLoader for training data.\n",
    "        testing_dataloader (DataLoader): DataLoader for testing data.\n",
    "        epochs (int): Number of training epochs.\n",
    "        learning_rate (float): Learning rate for optimizer.\n",
    "        device (torch.device): Device to train the model on (CPU/GPU).\n",
    "    \"\"\"\n",
    "    # Define Loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    #optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    #scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.1)\n",
    "    \n",
    "    optimizer = optim.AdamW(model.parameters(), lr=2e-3, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50)\n",
    "\n",
    "    # Move model to device\n",
    "    model.to(device)\n",
    "\n",
    "    best_valid_loss = np.inf\n",
    "    patience_counter = 0   # Tracks the number of epochs without improvement\n",
    "    early_stop = False # Flag to indicate whether to stop training\n",
    "    save_weights_patience = 5\n",
    "\n",
    "    # Dictionary to store loss and accuracy values over epochs\n",
    "    history_metrics = {\n",
    "        'training_loss': [],\n",
    "        'training_accuracy': [],\n",
    "        'validation_loss': [],\n",
    "        'validation_accuracy': []\n",
    "    }\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        if early_stop:\n",
    "            print(\"Early stopping triggered. Stopping training.\")\n",
    "            break\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}, LR: {scheduler.optimizer.param_groups[0]['lr']}\")\n",
    "\n",
    "        # Training step\n",
    "        train_loss, train_accuracy = train_one_epoch(model, training_dataloader, criterion, optimizer, device, epoch, epochs)\n",
    "        \n",
    "        # Testing step\n",
    "        valid_loss, valid_accuracy = test_one_epoch(model, testing_dataloader, criterion, device, epoch, epochs) \n",
    "\n",
    "        history_metrics['training_loss'].append(train_loss)\n",
    "        history_metrics['validation_loss'].append(valid_loss)\n",
    "        history_metrics['training_accuracy'].append(train_accuracy)\n",
    "        history_metrics['validation_accuracy'].append(valid_accuracy)\n",
    "\n",
    "        # Update the learning rate based on validation loss and print\n",
    "        #scheduler.step(valid_loss)\n",
    "\n",
    "        if valid_loss < best_valid_loss:\n",
    "            torch.save(model.state_dict(), 'weights/base_model_with_fer2013_weights.pt')\n",
    "            print(\"SAVED-BEST-WEIGHTS!\")\n",
    "            best_valid_loss = valid_loss\n",
    "            patience_counter = 0 # Reset early stopping\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"No improvement in validation loss for {patience_counter} epoch(s).\")\n",
    "\n",
    "        if patience_counter >= save_weights_patience:\n",
    "            print(\"Patience exceeded. Early stopping at epoch \" +str(epoch + 1))\n",
    "            early_stop = True\n",
    "            \n",
    "        \n",
    "    print(\"\")\n",
    "    return history_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cf1b19",
   "metadata": {},
   "source": [
    "### Run train functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e53dfa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "time1 = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e820802d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, LR: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]1/50: 100%|██████████| 225/225 [03:27<00:00,  1.09it/s, loss=1.719857, acc=0.312969]\n",
      "EPOCH[VALID]1/50: 100%|██████████| 57/57 [00:20<00:00,  2.84it/s, loss=1.531349, acc=0.407237]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 2, LR: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]2/50: 100%|██████████| 225/225 [00:31<00:00,  7.24it/s, loss=1.512696, acc=0.410191]\n",
      "EPOCH[VALID]2/50: 100%|██████████| 57/57 [00:03<00:00, 16.56it/s, loss=1.385648, acc=0.476261]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 3, LR: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]3/50: 100%|██████████| 225/225 [00:31<00:00,  7.10it/s, loss=1.425704, acc=0.450536]\n",
      "EPOCH[VALID]3/50: 100%|██████████| 57/57 [00:03<00:00, 16.37it/s, loss=1.378405, acc=0.476206]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 4, LR: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]4/50: 100%|██████████| 225/225 [00:31<00:00,  7.13it/s, loss=1.367784, acc=0.478639]\n",
      "EPOCH[VALID]4/50: 100%|██████████| 57/57 [00:03<00:00, 16.53it/s, loss=1.331536, acc=0.478262]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 5, LR: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]5/50: 100%|██████████| 225/225 [00:31<00:00,  7.05it/s, loss=1.324140, acc=0.492825]\n",
      "EPOCH[VALID]5/50: 100%|██████████| 57/57 [00:03<00:00, 16.46it/s, loss=1.326619, acc=0.483553]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 6, LR: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]6/50: 100%|██████████| 225/225 [00:31<00:00,  7.12it/s, loss=1.294140, acc=0.503447]\n",
      "EPOCH[VALID]6/50: 100%|██████████| 57/57 [00:03<00:00, 15.75it/s, loss=1.311136, acc=0.509814]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 7, LR: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]7/50: 100%|██████████| 225/225 [00:31<00:00,  7.04it/s, loss=1.266059, acc=0.516350]\n",
      "EPOCH[VALID]7/50: 100%|██████████| 57/57 [00:04<00:00, 13.20it/s, loss=1.276729, acc=0.534814]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 8, LR: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]8/50: 100%|██████████| 225/225 [03:00<00:00,  1.25it/s, loss=1.255420, acc=0.522109]\n",
      "EPOCH[VALID]8/50: 100%|██████████| 57/57 [00:13<00:00,  4.08it/s, loss=1.191492, acc=0.538569]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 9, LR: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]9/50: 100%|██████████| 225/225 [00:33<00:00,  6.63it/s, loss=1.235479, acc=0.528836]\n",
      "EPOCH[VALID]9/50: 100%|██████████| 57/57 [00:04<00:00, 13.79it/s, loss=1.186137, acc=0.539693]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 10, LR: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]10/50: 100%|██████████| 225/225 [00:31<00:00,  7.11it/s, loss=1.221586, acc=0.534170]\n",
      "EPOCH[VALID]10/50: 100%|██████████| 57/57 [00:03<00:00, 16.67it/s, loss=1.184348, acc=0.554879]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 11, LR: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]11/50: 100%|██████████| 225/225 [00:30<00:00,  7.32it/s, loss=1.201565, acc=0.537974]\n",
      "EPOCH[VALID]11/50: 100%|██████████| 57/57 [00:03<00:00, 16.74it/s, loss=1.163231, acc=0.564501]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 12, LR: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]12/50: 100%|██████████| 225/225 [00:30<00:00,  7.29it/s, loss=1.193982, acc=0.543421]\n",
      "EPOCH[VALID]12/50: 100%|██████████| 57/57 [00:03<00:00, 16.79it/s, loss=1.259271, acc=0.534759]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in validation loss for 1 epoch(s).\n",
      "Epoch 13, LR: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]13/50: 100%|██████████| 225/225 [00:30<00:00,  7.31it/s, loss=1.184729, acc=0.549726]\n",
      "EPOCH[VALID]13/50: 100%|██████████| 57/57 [00:03<00:00, 16.90it/s, loss=1.227506, acc=0.535636]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in validation loss for 2 epoch(s).\n",
      "Epoch 14, LR: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]14/50: 100%|██████████| 225/225 [00:30<00:00,  7.27it/s, loss=1.178353, acc=0.550747]\n",
      "EPOCH[VALID]14/50: 100%|██████████| 57/57 [00:03<00:00, 16.84it/s, loss=1.128949, acc=0.581908]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 15, LR: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]15/50: 100%|██████████| 225/225 [00:30<00:00,  7.28it/s, loss=1.162799, acc=0.555698]\n",
      "EPOCH[VALID]15/50: 100%|██████████| 57/57 [00:03<00:00, 16.75it/s, loss=1.099521, acc=0.584923]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 16, LR: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]16/50: 100%|██████████| 225/225 [00:31<00:00,  7.25it/s, loss=1.146796, acc=0.565177]\n",
      "EPOCH[VALID]16/50: 100%|██████████| 57/57 [00:03<00:00, 16.45it/s, loss=1.129549, acc=0.570285]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in validation loss for 1 epoch(s).\n",
      "Epoch 17, LR: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]17/50: 100%|██████████| 225/225 [00:30<00:00,  7.30it/s, loss=1.143695, acc=0.567731]\n",
      "EPOCH[VALID]17/50: 100%|██████████| 57/57 [00:03<00:00, 16.80it/s, loss=1.138717, acc=0.571382]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in validation loss for 2 epoch(s).\n",
      "Epoch 18, LR: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]18/50: 100%|██████████| 225/225 [00:30<00:00,  7.31it/s, loss=1.133258, acc=0.566663]\n",
      "EPOCH[VALID]18/50: 100%|██████████| 57/57 [00:03<00:00, 16.86it/s, loss=1.098197, acc=0.594764]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 19, LR: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]19/50: 100%|██████████| 225/225 [00:30<00:00,  7.30it/s, loss=1.122501, acc=0.573823]\n",
      "EPOCH[VALID]19/50: 100%|██████████| 57/57 [00:03<00:00, 17.02it/s, loss=1.068383, acc=0.595669]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 20, LR: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]20/50: 100%|██████████| 225/225 [00:30<00:00,  7.31it/s, loss=1.118500, acc=0.575322]\n",
      "EPOCH[VALID]20/50: 100%|██████████| 57/57 [00:03<00:00, 16.73it/s, loss=1.073513, acc=0.594846]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in validation loss for 1 epoch(s).\n",
      "Epoch 21, LR: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]21/50: 100%|██████████| 225/225 [00:30<00:00,  7.29it/s, loss=1.118624, acc=0.575423]\n",
      "EPOCH[VALID]21/50: 100%|██████████| 57/57 [00:03<00:00, 16.93it/s, loss=1.065407, acc=0.600603]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 22, LR: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]22/50: 100%|██████████| 225/225 [00:30<00:00,  7.31it/s, loss=1.107053, acc=0.580354]\n",
      "EPOCH[VALID]22/50: 100%|██████████| 57/57 [00:03<00:00, 16.51it/s, loss=1.045485, acc=0.609540]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 23, LR: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]23/50: 100%|██████████| 225/225 [00:30<00:00,  7.26it/s, loss=1.102030, acc=0.583987]\n",
      "EPOCH[VALID]23/50: 100%|██████████| 57/57 [00:03<00:00, 16.86it/s, loss=1.099391, acc=0.581689]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in validation loss for 1 epoch(s).\n",
      "Epoch 24, LR: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]24/50: 100%|██████████| 225/225 [00:30<00:00,  7.29it/s, loss=1.101820, acc=0.583757]\n",
      "EPOCH[VALID]24/50: 100%|██████████| 57/57 [00:03<00:00, 16.66it/s, loss=1.098343, acc=0.588816]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in validation loss for 2 epoch(s).\n",
      "Epoch 25, LR: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]25/50: 100%|██████████| 225/225 [00:30<00:00,  7.36it/s, loss=1.094220, acc=0.586636]\n",
      "EPOCH[VALID]25/50: 100%|██████████| 57/57 [00:03<00:00, 16.87it/s, loss=1.056245, acc=0.605428]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in validation loss for 3 epoch(s).\n",
      "Epoch 26, LR: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]26/50: 100%|██████████| 225/225 [00:30<00:00,  7.32it/s, loss=1.088748, acc=0.587766]\n",
      "EPOCH[VALID]26/50: 100%|██████████| 57/57 [00:03<00:00, 16.65it/s, loss=1.024856, acc=0.611815]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 27, LR: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]27/50: 100%|██████████| 225/225 [00:30<00:00,  7.33it/s, loss=1.083257, acc=0.590322]\n",
      "EPOCH[VALID]27/50: 100%|██████████| 57/57 [00:03<00:00, 16.30it/s, loss=1.041537, acc=0.611349]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in validation loss for 1 epoch(s).\n",
      "Epoch 28, LR: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]28/50: 100%|██████████| 225/225 [00:31<00:00,  7.08it/s, loss=1.078721, acc=0.590941]\n",
      "EPOCH[VALID]28/50: 100%|██████████| 57/57 [00:03<00:00, 16.41it/s, loss=1.085880, acc=0.592489]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in validation loss for 2 epoch(s).\n",
      "Epoch 29, LR: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]29/50: 100%|██████████| 225/225 [00:31<00:00,  7.22it/s, loss=1.069691, acc=0.593236]\n",
      "EPOCH[VALID]29/50: 100%|██████████| 57/57 [00:03<00:00, 16.37it/s, loss=1.032211, acc=0.611952]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in validation loss for 3 epoch(s).\n",
      "Epoch 30, LR: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]30/50: 100%|██████████| 225/225 [00:33<00:00,  6.75it/s, loss=1.067263, acc=0.595023]\n",
      "EPOCH[VALID]30/50: 100%|██████████| 57/57 [00:04<00:00, 12.42it/s, loss=1.023720, acc=0.621656]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 31, LR: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]31/50: 100%|██████████| 225/225 [00:33<00:00,  6.68it/s, loss=1.059680, acc=0.596235]\n",
      "EPOCH[VALID]31/50: 100%|██████████| 57/57 [00:03<00:00, 16.07it/s, loss=1.025796, acc=0.619956]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in validation loss for 1 epoch(s).\n",
      "Epoch 32, LR: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]32/50: 100%|██████████| 225/225 [00:32<00:00,  6.90it/s, loss=1.061905, acc=0.599221]\n",
      "EPOCH[VALID]32/50: 100%|██████████| 57/57 [00:03<00:00, 16.44it/s, loss=1.066914, acc=0.605784]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in validation loss for 2 epoch(s).\n",
      "Epoch 33, LR: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]33/50: 100%|██████████| 225/225 [00:31<00:00,  7.22it/s, loss=1.047255, acc=0.601716]\n",
      "EPOCH[VALID]33/50: 100%|██████████| 57/57 [00:03<00:00, 16.57it/s, loss=1.102563, acc=0.601179]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in validation loss for 3 epoch(s).\n",
      "Epoch 34, LR: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]34/50: 100%|██████████| 225/225 [00:31<00:00,  7.22it/s, loss=1.047151, acc=0.603284]\n",
      "EPOCH[VALID]34/50: 100%|██████████| 57/57 [00:03<00:00, 16.53it/s, loss=1.017571, acc=0.622368]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 35, LR: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]35/50: 100%|██████████| 225/225 [00:31<00:00,  7.21it/s, loss=1.053003, acc=0.599082]\n",
      "EPOCH[VALID]35/50: 100%|██████████| 57/57 [00:03<00:00, 16.61it/s, loss=1.015704, acc=0.619079]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 36, LR: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]36/50: 100%|██████████| 225/225 [00:31<00:00,  7.16it/s, loss=1.042825, acc=0.605404]\n",
      "EPOCH[VALID]36/50: 100%|██████████| 57/57 [00:03<00:00, 16.14it/s, loss=1.011261, acc=0.628810]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 37, LR: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]37/50: 100%|██████████| 225/225 [00:31<00:00,  7.21it/s, loss=1.034214, acc=0.610487]\n",
      "EPOCH[VALID]37/50: 100%|██████████| 57/57 [00:03<00:00, 16.82it/s, loss=1.016836, acc=0.625822]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in validation loss for 1 epoch(s).\n",
      "Epoch 38, LR: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]38/50: 100%|██████████| 225/225 [00:31<00:00,  7.25it/s, loss=1.036051, acc=0.608297]\n",
      "EPOCH[VALID]38/50: 100%|██████████| 57/57 [00:03<00:00, 16.28it/s, loss=1.010894, acc=0.622780]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 39, LR: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]39/50: 100%|██████████| 225/225 [00:31<00:00,  7.20it/s, loss=1.031930, acc=0.610834]\n",
      "EPOCH[VALID]39/50: 100%|██████████| 57/57 [00:03<00:00, 16.70it/s, loss=1.005712, acc=0.624534]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 40, LR: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]40/50: 100%|██████████| 225/225 [00:31<00:00,  7.22it/s, loss=1.030999, acc=0.609659]\n",
      "EPOCH[VALID]40/50: 100%|██████████| 57/57 [00:03<00:00, 16.72it/s, loss=0.993722, acc=0.628481]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 41, LR: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]41/50: 100%|██████████| 225/225 [00:31<00:00,  7.23it/s, loss=1.025725, acc=0.613011]\n",
      "EPOCH[VALID]41/50: 100%|██████████| 57/57 [00:03<00:00, 16.49it/s, loss=1.041648, acc=0.608690]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in validation loss for 1 epoch(s).\n",
      "Epoch 42, LR: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]42/50: 100%|██████████| 225/225 [00:31<00:00,  7.20it/s, loss=1.015697, acc=0.614240]\n",
      "EPOCH[VALID]42/50: 100%|██████████| 57/57 [00:03<00:00, 16.41it/s, loss=1.019615, acc=0.622259]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in validation loss for 2 epoch(s).\n",
      "Epoch 43, LR: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]43/50: 100%|██████████| 225/225 [00:31<00:00,  7.21it/s, loss=1.015720, acc=0.613436]\n",
      "EPOCH[VALID]43/50: 100%|██████████| 57/57 [00:03<00:00, 16.43it/s, loss=1.033311, acc=0.622423]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in validation loss for 3 epoch(s).\n",
      "Epoch 44, LR: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]44/50: 100%|██████████| 225/225 [00:31<00:00,  7.20it/s, loss=1.012528, acc=0.615688]\n",
      "EPOCH[VALID]44/50: 100%|██████████| 57/57 [00:03<00:00, 16.50it/s, loss=1.060455, acc=0.608443]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in validation loss for 4 epoch(s).\n",
      "Epoch 45, LR: 0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]45/50: 100%|██████████| 225/225 [00:30<00:00,  7.28it/s, loss=1.009415, acc=0.617122]\n",
      "EPOCH[VALID]45/50: 100%|██████████| 57/57 [00:03<00:00, 16.34it/s, loss=1.049177, acc=0.615488]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in validation loss for 5 epoch(s).\n",
      "Patience exceeded. Early stopping at epoch 45\n",
      "Early stopping triggered. Stopping training.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model:\n",
    "base_model_losses = train_and_validate_model(base_fer_model, training_loader, test_loader, epochs=50, learning_rate=0.001, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "971550d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training time:  0:32:00.443535\n"
     ]
    }
   ],
   "source": [
    "time2 = datetime.now()\n",
    "print(\"Total training time: \", time2 - time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6722ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses and accuracy saved\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data\n",
    "data = {\n",
    "    \"Epoch\": list(range(1, len(base_model_losses['training_loss']) + 1)),\n",
    "    \"Training Loss\": base_model_losses['training_loss'],\n",
    "    \"Validation Loss\": base_model_losses['validation_loss'],\n",
    "    \"Training Accuracy\": [acc.cpu().item() for acc in base_model_losses['training_accuracy']],\n",
    "    \"Validation Accuracy\": [acc.cpu().item() for acc in base_model_losses['validation_accuracy']]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"stats/base_model_stats_001_50_epochs.csv\", index=False)\n",
    "print(\"Losses and accuracy saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2143882d",
   "metadata": {},
   "source": [
    "# Test Model Accuracy on Out of Distribution Data set (Manga Faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "846e5189",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_out_of_distribution(model, testing_dataloader, epochs, device):\n",
    "    \"\"\"\n",
    "    Train and Test the speech recognition model using CTC loss.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model.\n",
    "        training_dataloader (DataLoader): DataLoader for training data.\n",
    "        testing_dataloader (DataLoader): DataLoader for testing data.\n",
    "        epochs (int): Number of training epochs.\n",
    "        learning_rate (float): Learning rate for optimizer.\n",
    "        device (torch.device): Device to train the model on (CPU/GPU).\n",
    "        \n",
    "    Returns:\n",
    "        history_metrics (dict): Dictionary containing validation loss and accuracy over epochs.\n",
    "    \"\"\"\n",
    "    # Define Loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Move model to device\n",
    "    model.to(device)\n",
    "\n",
    "    # Dictionary to store loss and accuracy values over epochs\n",
    "    history_metrics = {\n",
    "        'validation_loss': [],\n",
    "        'validation_accuracy': []\n",
    "    }\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}\")\n",
    "        \n",
    "        # Testing step\n",
    "        valid_loss, valid_accuracy = test_one_epoch(model, testing_dataloader, criterion, device, epoch, epochs) \n",
    "        \n",
    "        history_metrics['validation_loss'].append(valid_loss)\n",
    "        history_metrics['validation_accuracy'].append(valid_accuracy)\n",
    "                \n",
    "    print(\"\")\n",
    "    return history_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0084c040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_fer_model_2 = BaseFERModel_V2(params).to(device)\n",
    "base_fer_model_2 = base_fer_model_2.to(device)\n",
    "base_fer_model_2.load_state_dict(torch.load('weights/base_model_with_fer2013_weights.pt', weights_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e436afd",
   "metadata": {},
   "source": [
    "## Import MangaFaces Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c985db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train set\n",
    "manga_faces_train_dir = Path(os.getcwd(), 'datasets', 'manga', 'train')\n",
    "manga_faces_train_images = ImageFolder(root=manga_faces_train_dir, transform=train_transforms)\n",
    "manga_faces_train_images_loader = DataLoader(manga_faces_train_images, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Test Set\n",
    "manga_faces_test_dir = Path(os.getcwd(), 'datasets', 'manga', 'test')\n",
    "manga_faces_test_images = ImageFolder(root=manga_faces_test_dir, transform=val_transforms)\n",
    "manga_faces_test_images_loader = DataLoader(manga_faces_test_images, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735db254",
   "metadata": {},
   "source": [
    "## Run 'test_out_of_distribution' function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "ce41c5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/5: 100%|██████████| 7/7 [00:00<00:00, 10.75it/s, loss=2.583786, acc=0.216071]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]2/5: 100%|██████████| 7/7 [00:00<00:00, 12.12it/s, loss=2.531525, acc=0.193750]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]3/5: 100%|██████████| 7/7 [00:00<00:00, 14.98it/s, loss=2.458348, acc=0.272321]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]4/5: 100%|██████████| 7/7 [00:00<00:00, 14.17it/s, loss=2.452406, acc=0.199107]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]5/5: 100%|██████████| 7/7 [00:00<00:00, 14.96it/s, loss=2.546078, acc=0.234821]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model:\n",
    "test_out_of_distribution_metrics = test_out_of_distribution(base_fer_model_2, manga_faces_train_images_loader, epochs=5, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e9e9fc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses and accuracy saved\n"
     ]
    }
   ],
   "source": [
    "# Store the metrics from when the model was tested on the out-of-distribution dataset\n",
    "data = {\n",
    "    \"Epoch\": list(range(1, len(test_out_of_distribution_metrics['validation_loss']) + 1)),\n",
    "    \"Validation Loss\": test_out_of_distribution_metrics['validation_loss'],\n",
    "    \"Validation Accuracy\": [acc.cpu().item() for acc in test_out_of_distribution_metrics['validation_accuracy']]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"stats/test_model_out_of_distribution_stats_001_5_epochs.csv\", index=False)\n",
    "print(\"Losses and accuracy saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "82398d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/5: 100%|██████████| 5/5 [00:00<00:00, 10.98it/s, loss=3.377855, acc=0.156250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]2/5: 100%|██████████| 5/5 [00:00<00:00, 23.95it/s, loss=2.565618, acc=0.156250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]3/5: 100%|██████████| 5/5 [00:00<00:00, 27.50it/s, loss=2.638279, acc=0.200000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]4/5: 100%|██████████| 5/5 [00:00<00:00, 27.55it/s, loss=2.533443, acc=0.287500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]5/5: 100%|██████████| 5/5 [00:00<00:00, 28.39it/s, loss=2.684730, acc=0.156250]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model:\n",
    "test_out_of_distribution_metrics = test_out_of_distribution(base_fer_model_2, manga_faces_test_images_loader, epochs=5, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c183a06",
   "metadata": {},
   "source": [
    "# FSL DA Prototypical Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a556c60f",
   "metadata": {},
   "source": [
    "### Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15233c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FewShotFERDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for few-shot FER, where images are organized by class in folders.\n",
    "    This dataset generates episodes (tasks) on-the-fly.\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir, n_way=5, k_shot=1, k_query=5, transform=None):\n",
    "        \"\"\"\n",
    "        root_dir: Root folder containing one folder per class.\n",
    "        n_way: number of classes per episode.\n",
    "        k_shot: number of support examples per class.\n",
    "        k_query: number of query examples per class.\n",
    "        transform: transformation to apply to images.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.n_way = n_way\n",
    "        self.k_shot = k_shot\n",
    "        self.k_query = k_query\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Build a mapping: class -> list of image paths.\n",
    "        self.class_to_imgs = {}\n",
    "        for cls_name in os.listdir(root_dir):\n",
    "            cls_folder = Path.joinpath(root_dir, cls_name)\n",
    "            if Path.is_dir(cls_folder):\n",
    "                self.class_to_imgs[cls_name] = [Path.joinpath(cls_folder, img)                                                 \n",
    "                                                 for img in Path(cls_folder).rglob('*')\n",
    "                                                 if str(img).endswith('.jpg') or str(img).endswith('.png')]        \n",
    "        self.classes = list(self.class_to_imgs.keys())\n",
    "    \n",
    "    def __len__(self):\n",
    "        # Define the number of episodes arbitrarily.\n",
    "        return 1000  # or any number representing episodes\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Randomly sample n_way classes for this episode.\n",
    "        sampled_classes = random.sample(self.classes, self.n_way)\n",
    "        support_imgs, support_labels = [], []\n",
    "        query_imgs, query_labels = [], []\n",
    "        \n",
    "        label_map = {cls_name: i for i, cls_name in enumerate(sampled_classes)}\n",
    "        \n",
    "        for cls_name in sampled_classes:\n",
    "            imgs = self.class_to_imgs[cls_name]\n",
    "            # Ensure there are enough examples in this class.\n",
    "            selected_imgs = random.sample(imgs, self.k_shot + self.k_query)\n",
    "            support_paths = selected_imgs[:self.k_shot]\n",
    "            query_paths = selected_imgs[self.k_shot:]\n",
    "            \n",
    "            for sp in support_paths:\n",
    "                img = Image.open(sp).convert('RGB')\n",
    "                if self.transform:\n",
    "                    img = self.transform(img)\n",
    "                support_imgs.append(img)\n",
    "                support_labels.append(label_map[cls_name])\n",
    "            \n",
    "            for qp in query_paths:\n",
    "                img = Image.open(qp).convert('RGB')\n",
    "                if self.transform:\n",
    "                    img = self.transform(img)\n",
    "                query_imgs.append(img)\n",
    "                query_labels.append(label_map[cls_name])\n",
    "        \n",
    "        # Convert lists to tensors.\n",
    "        support_imgs = torch.stack(support_imgs)  # shape: [n_way*k_shot, C, H, W]\n",
    "        support_labels = torch.tensor(support_labels, dtype=torch.long)\n",
    "        query_imgs = torch.stack(query_imgs)      # shape: [n_way*k_query, C, H, W]\n",
    "        query_labels = torch.tensor(query_labels, dtype=torch.long)\n",
    "        \n",
    "        return (support_imgs, support_labels), (query_imgs, query_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58adc3d5",
   "metadata": {},
   "source": [
    "### Instantiate Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b699e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms \n",
    "#mean = [0.485]  # Single channel\n",
    "#std = [0.229]\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.Resize((48, 48)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485],\n",
    "                std=[0.229])\n",
    "])\n",
    "\n",
    "# Root folder with classes as subfolders.\n",
    "few_shot_dataset = FewShotFERDataset(root_dir=manga_faces_train_dir, n_way=4, k_shot=10, k_query=22, transform=transform)\n",
    "few_shot_loader = DataLoader(few_shot_dataset, batch_size=1, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc3e480",
   "metadata": {},
   "source": [
    "### Prototypical Network Inference function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "584fdf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_episode(feature_extractor, support_imgs, support_labels, query_imgs, query_labels, device):\n",
    "    \"\"\"\n",
    "    feature_extractor: model that outputs embeddings [B, embedding_dim]\n",
    "    support_imgs: tensor of shape [n_way * k_shot, C, H, W]\n",
    "    support_labels: tensor of shape [n_way * k_shot]\n",
    "    query_imgs: tensor of shape [n_way * k_query, C, H, W]\n",
    "    query_labels: tensor of shape [n_way * k_query]\n",
    "    \"\"\"\n",
    "    feature_extractor.eval()\n",
    "    with torch.no_grad():\n",
    "        # Move data to device.\n",
    "        support_imgs = support_imgs.to(device)\n",
    "        query_imgs = query_imgs.to(device)\n",
    "        \n",
    "        # Compute the embeddings.\n",
    "        support_embeddings = feature_extractor(support_imgs)  # [n_way*k_shot, D]\n",
    "        query_embeddings = feature_extractor(query_imgs)      # [n_way*k_query, D]\n",
    "    \n",
    "        # Compute prototypes: mean of support embeddings per class.\n",
    "        prototypes = []\n",
    "        unique_labels = torch.unique(support_labels)\n",
    "        for cls in unique_labels:\n",
    "            cls_indices = (support_labels == cls).nonzero(as_tuple=True)[0]\n",
    "            cls_embeddings = support_embeddings[cls_indices]\n",
    "            prototype = cls_embeddings.mean(dim=0)\n",
    "            prototypes.append(prototype)\n",
    "        prototypes = torch.stack(prototypes)  # shape: [n_way, D]\n",
    "        \n",
    "        # Compute distances between query embeddings and prototypes.\n",
    "        # We use Euclidean distance here.\n",
    "        # query_embeddings: [Q, D], prototypes: [n_way, D]\n",
    "        distances = torch.cdist(query_embeddings, prototypes, p=2)  # shape: [Q, n_way]\n",
    "        \n",
    "        # Convert distances to probabilities (smaller distance -> higher probability).\n",
    "        probs = F.softmax(-distances, dim=1)\n",
    "        preds = torch.argmax(probs, dim=1)\n",
    "        correct = (preds.cpu() == query_labels).sum().item()\n",
    "        total = query_labels.size(0)\n",
    "    \n",
    "    return correct, total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f71a500",
   "metadata": {},
   "source": [
    "### Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "242bc81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Few-Shot Episode Accuracy: 36.14%\n"
     ]
    }
   ],
   "source": [
    "total_correct = 0\n",
    "total_samples = 0\n",
    "num_episodes = 50  # Evaluate on 50 episodes.\n",
    "\n",
    "for i, episode in enumerate(few_shot_loader):\n",
    "    if i >= num_episodes:\n",
    "        break\n",
    "    # Remove the extra batch dimension since batch_size=1.\n",
    "    (support_imgs, support_labels), (query_imgs, query_labels) = episode\n",
    "    support_imgs = support_imgs.squeeze(0)\n",
    "    support_labels = support_labels.squeeze(0)\n",
    "    query_imgs = query_imgs.squeeze(0)\n",
    "    query_labels = query_labels.squeeze(0)\n",
    "    \n",
    "    correct, total = evaluate_episode(base_fer_model_2, support_imgs, support_labels, query_imgs, query_labels, device)\n",
    "    total_correct += correct\n",
    "    total_samples += total\n",
    "\n",
    "episode_accuracy = 100.0 * total_correct / total_samples\n",
    "print(\"Few-Shot Episode Accuracy: {:.2f}%\".format(episode_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bad0b2",
   "metadata": {},
   "source": [
    "# Contrastive Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38835e02",
   "metadata": {},
   "source": [
    "### Align Label spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1286eb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    \"angry\": 0,\n",
    "    \"disgust\": 1,\n",
    "    \"fear\": 2,\n",
    "    \"happy\": 3,\n",
    "    \"neutral\": 4,\n",
    "    \"sad\": 5,\n",
    "    \"surprise\": 6\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "017fa156",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MappedImageFolder(ImageFolder):\n",
    "    def __init__(self, root, label_map, transform=None):\n",
    "        super().__init__(root, transform=transform)\n",
    "        self.samples = [\n",
    "            (path, label_map[self.classes[label]])\n",
    "            for path, label in self.samples\n",
    "            if self.classes[label] in label_map\n",
    "        ]\n",
    "        self.targets = [s[1] for s in self.samples]\n",
    "        \n",
    "        inverse_label_map = {v: k for k, v in label_map.items()}\n",
    "        self.classes = [inverse_label_map[i] for i in sorted(inverse_label_map)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4c8e7725",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean=[0.485]\n",
    "std=[0.229]\n",
    "\n",
    "manga_transforms = T.Compose([\n",
    "    T.Grayscale(num_output_channels=3),  # Keep 3 channels but use grayscale\n",
    "    T.RandomApply([T.GaussianBlur(3), T.RandomSolarize(0.5)], p=0.5),\n",
    "    T.RandomPerspective(distortion_scale=0.4, p=0.3),\n",
    "    T.RandomApply([T.RandomRotation(15)], p=0.5),\n",
    "    T.RandomPerspective(distortion_scale=0.3, p=0.3),\n",
    "    T.RandomResizedCrop(48, scale=(0.8, 1.2)),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean, std),\n",
    "    T.RandomErasing(p=0.2)  # Helps with occlusion\n",
    "])\n",
    "\n",
    "\n",
    "manga_faces_train_dir = Path(os.getcwd(), 'datasets', 'manga', 'train')\n",
    "manga_faces_train_images = MappedImageFolder(root=manga_faces_train_dir, label_map=label_map  , transform=manga_transforms)\n",
    "manga_faces_train_images_loader = DataLoader(manga_faces_train_images, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "# Test Set\n",
    "test_transforms = T.Compose([\n",
    "    T.Grayscale(num_output_channels=3),\n",
    "    T.Resize((48, 48)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485], std=[0.229])\n",
    "])\n",
    "manga_faces_test_dir = Path(os.getcwd(), 'datasets', 'manga', 'test')\n",
    "manga_faces_test_images = MappedImageFolder(root=manga_faces_test_dir, label_map=label_map  , transform=test_transforms)\n",
    "manga_faces_test_images_loader = DataLoader(manga_faces_test_images, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c5504b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 3, 5, 6}\n"
     ]
    }
   ],
   "source": [
    "print(set(manga_faces_test_images.targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4cf8ef",
   "metadata": {},
   "source": [
    "### Contrastive Loss Class Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ea01118c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self, temperature=0.5):  # Increased temperature\n",
    "        super().__init__()\n",
    "        self.tau = temperature # hyperparameter for scaling the similarity scores\n",
    "        \n",
    "    def forward(self, source_emb, source_labels, target_emb, target_labels):\n",
    "        device = source_emb.device\n",
    "        \n",
    "        # Normalize embeddings\n",
    "        source_emb = F.normalize(source_emb, p=2, dim=1)\n",
    "        target_emb = F.normalize(target_emb, p=2, dim=1)\n",
    "        \n",
    "        embeddings = torch.cat([source_emb, target_emb], dim=0)\n",
    "        labels = torch.cat([source_labels, target_labels], dim=0)\n",
    "        \n",
    "        # Similarity matrix\n",
    "        sim_matrix = torch.mm(target_emb, embeddings.T) / self.tau\n",
    "        \n",
    "        # Masks\n",
    "        pos_mask = torch.zeros_like(sim_matrix, dtype=torch.bool)\n",
    "        for i, label in enumerate(target_labels):\n",
    "            pos_mask[i, :len(source_labels)] = (source_labels == label)\n",
    "            \n",
    "        neg_mask = (labels != target_labels.unsqueeze(1))\n",
    "        neg_mask[:, len(source_labels):] &= ~torch.eye(\n",
    "            len(target_labels), dtype=torch.bool, device=device\n",
    "        )\n",
    "        \n",
    "        # Compute terms with stability\n",
    "        pos_term = (sim_matrix.exp() * pos_mask.float()).sum(dim=1) + 1e-8\n",
    "        neg_term = (sim_matrix.exp() * neg_mask.float()).sum(dim=1) + 1e-8\n",
    "        \n",
    "        loss = -torch.log(pos_term / (pos_term + neg_term))\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8dcecc",
   "metadata": {},
   "source": [
    "### Few-shot sampling function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c38636a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few-shot sampling function\n",
    "def get_few_shot_indices(dataset, shots_per_class=5):\n",
    "    \"\"\"\n",
    "    Returns a balanced list of indices for few-shot learning by randomly selecting\n",
    "    a fixed number of samples per class.\n",
    "\n",
    "    Args:\n",
    "        dataset (ImageFolder): A PyTorch ImageFolder dataset (or any dataset with a `.samples` attribute \n",
    "                              containing (path, label) tuples).\n",
    "        shots_per_class (int, optional): Number of samples to select per class. Defaults to 5.\n",
    "\n",
    "    Returns:\n",
    "        List[int]: A list of selected indices, ensuring `shots_per_class` samples per class.\n",
    "\n",
    "    Example:\n",
    "        >>> target_set = ImageFolder(root='data/target', transform=transforms.ToTensor())\n",
    "        >>> few_shot_indices = get_few_shot_indices(target_set, shots_per_class=3)\n",
    "        >>> few_shot_loader = DataLoader(Subset(target_set, few_shot_indices), batch_size=3)\n",
    "    \"\"\"\n",
    "    \n",
    "    class_indices = {}\n",
    "    for idx, (_, label) in enumerate(dataset.samples):\n",
    "        class_indices.setdefault(label, []).append(idx)\n",
    "    \n",
    "    selected_indices = []\n",
    "    for label, indices in class_indices.items():\n",
    "        selected_indices.extend(np.random.choice(indices, shots_per_class, replace=False))\n",
    "    return selected_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c296ef10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_contrastive = BaseFERModel_V2(params).to(device)\n",
    "model_contrastive = base_fer_model_2.to(device)\n",
    "model_contrastive.load_state_dict(torch.load('weights/base_model_with_fer2013_weights.pt', weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e7ff5443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model and losses\n",
    "params = {'num_classes': 7, 'dropout_rate': 0.2}  # Example for FER2013\n",
    "cls_criterion = nn.CrossEntropyLoss()\n",
    "cont_criterion = ContrastiveLoss(temperature=0.2)\n",
    "optimizer = torch.optim.AdamW(model_contrastive.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "\n",
    "# Prepare few-shot target loader training set\n",
    "few_shot_indices = get_few_shot_indices(manga_faces_train_images, shots_per_class=15)\n",
    "few_shot_loader = DataLoader(\n",
    "    Subset(manga_faces_train_images, few_shot_indices),\n",
    "    batch_size=10,\n",
    "    shuffle=False,\n",
    "    drop_last=True  # Avoid partial batches\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdfa3a3",
   "metadata": {},
   "source": [
    "### Modified Training Loop for Contrastive Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699f9524",
   "metadata": {},
   "source": [
    "#### Using only CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f5beff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b38d4661",
   "metadata": {},
   "source": [
    "#### Using only ContrastiveLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885ddf3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4135265c",
   "metadata": {},
   "source": [
    "#### Using both CrossEntropyLoss and ContrastiveLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7aa0118e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop with domain adaptation\n",
    "def train_epoch(model, source_loader, target_loader, optimizer, epoch, epochs):\n",
    "    model.train()\n",
    "    target_iter = cycle(target_loader)  # Infinite iterator\n",
    "    \n",
    "    # Initialize metrics\n",
    "    total_cls_loss = 0.0\n",
    "    total_cont_loss = 0.0\n",
    "    running_total_loss = 0.0\n",
    "    source_correct = 0\n",
    "    target_correct = 0\n",
    "    total_source_samples = 0\n",
    "    total_target_samples = 0\n",
    "    \n",
    "    \n",
    "    tk = tqdm(source_loader, desc=\"EPOCH\" + \"[TRAIN]\" + str(epoch) + \"/\" + str(epochs))\n",
    "    \n",
    "    for batch_idx, (source_imgs, source_lbls) in enumerate(tk):\n",
    "        # Get target batch\n",
    "        target_imgs, target_lbls = next(target_iter)\n",
    "        \n",
    "        # Move to device\n",
    "        source_imgs = source_imgs.to(device)\n",
    "        source_lbls = source_lbls.to(device)\n",
    "        target_imgs = target_imgs.to(device)\n",
    "        target_lbls = target_lbls.to(device)\n",
    "        \n",
    "        # Forward pass with embeddings\n",
    "        source_logits, source_emb = model(source_imgs, return_embeddings=True)\n",
    "        target_logits, target_emb = model(target_imgs, return_embeddings=True)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        source_preds = source_logits.argmax(dim=1)\n",
    "        target_preds = target_logits.argmax(dim=1)\n",
    "        \n",
    "        # Update counters\n",
    "        batch_source_correct = (source_preds == source_lbls).sum().item()\n",
    "        batch_target_correct = (target_preds == target_lbls).sum().item()\n",
    "        \n",
    "        source_correct += batch_source_correct\n",
    "        target_correct += batch_target_correct\n",
    "        total_source_samples += source_lbls.size(0)\n",
    "        total_target_samples += target_lbls.size(0)\n",
    "        \n",
    "        # Loss calculation\n",
    "        cls_loss = cls_criterion(source_logits, source_lbls) + \\\n",
    "                cls_criterion(target_logits, target_lbls)\n",
    "        \n",
    "        cont_loss = cont_criterion(source_emb, source_lbls,\n",
    "                                 target_emb, target_lbls)\n",
    "        \n",
    "        current_loss = cls_loss + 0.9 * cont_loss # Adjusted weight\n",
    "        \n",
    "        # Update metrics\n",
    "        total_cls_loss += cls_loss.item()\n",
    "        total_cont_loss += cont_loss.item() * 0.9 # Adjusted weight\n",
    "        running_total_loss += current_loss.item()\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        current_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate batch-level accuracies\n",
    "        batch_source_acc = 100 * batch_source_correct / source_lbls.size(0)\n",
    "        batch_target_acc = 100 * batch_target_correct / target_lbls.size(0)\n",
    "        \n",
    "        # Update progress bar\n",
    "        tk.set_postfix({\n",
    "            'CLS Loss': f'{total_cls_loss / (batch_idx + 1):.4f}',\n",
    "            'CONT Loss': f'{total_cont_loss / (batch_idx + 1):.4f}',\n",
    "            'Total Loss': f'{running_total_loss / (batch_idx + 1):.4f}',\n",
    "            'Source Acc': f'{batch_source_acc:.2f}%',\n",
    "            'Target Acc': f'{batch_target_acc:.2f}%'\n",
    "        })\n",
    "            \n",
    "    # Calculate epoch-level metrics\n",
    "    epoch_cls_loss = total_cls_loss / len(source_loader)\n",
    "    epoch_cont_loss = total_cont_loss / len(source_loader)\n",
    "    epoch_total_loss = running_total_loss / len(source_loader)\n",
    "    \n",
    "    epoch_source_acc = 100 * source_correct / total_source_samples\n",
    "    epoch_target_acc = 100 * target_correct / total_target_samples\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch}/{epochs} Summary:\")\n",
    "    print(f\"CLS Loss: {epoch_cls_loss:.4f} | CONT Loss: {epoch_cont_loss:.4f} | Total Loss: {epoch_total_loss:.4f}\")\n",
    "    print(f\"Source Acc: {epoch_source_acc:.2f}% | Target Acc: {epoch_target_acc:.2f}%\")\n",
    "    \n",
    "    return epoch_cls_loss, epoch_cont_loss, epoch_total_loss, epoch_source_acc, epoch_target_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "99023746",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d5135f",
   "metadata": {},
   "source": [
    "### Run Contrastive Loss Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2bb61f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]1/50: 100%|██████████| 225/225 [01:25<00:00,  2.64it/s, CLS Loss=3.0016, CONT Loss=1.6332, Total Loss=4.6348, Source Acc=54.05%, Target Acc=40.00%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/50 Summary:\n",
      "CLS Loss: 3.0016 | CONT Loss: 1.6332 | Total Loss: 4.6348\n",
      "Source Acc: 62.27% | Target Acc: 33.02%\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/1: 100%|██████████| 5/5 [00:00<00:00, 20.40it/s, loss=1.770771, acc=0.387500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAVED-BEST-WEIGHTS!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]2/50: 100%|██████████| 225/225 [00:30<00:00,  7.26it/s, CLS Loss=2.7937, CONT Loss=1.6212, Total Loss=4.4150, Source Acc=56.76%, Target Acc=40.00%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/50 Summary:\n",
      "CLS Loss: 2.7937 | CONT Loss: 1.6212 | Total Loss: 4.4150\n",
      "Source Acc: 61.36% | Target Acc: 39.82%\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/1: 100%|██████████| 5/5 [00:00<00:00, 19.09it/s, loss=1.780400, acc=0.412500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAVED-BEST-WEIGHTS!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]3/50: 100%|██████████| 225/225 [00:31<00:00,  7.26it/s, CLS Loss=2.6375, CONT Loss=1.5791, Total Loss=4.2166, Source Acc=72.97%, Target Acc=40.00%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/50 Summary:\n",
      "CLS Loss: 2.6375 | CONT Loss: 1.5791 | Total Loss: 4.2166\n",
      "Source Acc: 60.42% | Target Acc: 45.91%\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/1: 100%|██████████| 5/5 [00:00<00:00, 24.92it/s, loss=1.792406, acc=0.412500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAVED-BEST-WEIGHTS!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]4/50: 100%|██████████| 225/225 [00:30<00:00,  7.48it/s, CLS Loss=2.5663, CONT Loss=1.5972, Total Loss=4.1634, Source Acc=48.65%, Target Acc=20.00%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/50 Summary:\n",
      "CLS Loss: 2.5663 | CONT Loss: 1.5972 | Total Loss: 4.1634\n",
      "Source Acc: 59.69% | Target Acc: 46.98%\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/1: 100%|██████████| 5/5 [00:00<00:00, 19.70it/s, loss=1.538352, acc=0.512500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAVED-BEST-WEIGHTS!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]5/50: 100%|██████████| 225/225 [00:31<00:00,  7.07it/s, CLS Loss=2.5085, CONT Loss=1.5714, Total Loss=4.0799, Source Acc=43.24%, Target Acc=50.00%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/50 Summary:\n",
      "CLS Loss: 2.5085 | CONT Loss: 1.5714 | Total Loss: 4.0799\n",
      "Source Acc: 60.14% | Target Acc: 50.27%\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/1: 100%|██████████| 5/5 [00:00<00:00, 21.65it/s, loss=2.151020, acc=0.393750]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAVED-BEST-WEIGHTS!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]6/50: 100%|██████████| 225/225 [00:30<00:00,  7.48it/s, CLS Loss=2.4899, CONT Loss=1.5941, Total Loss=4.0840, Source Acc=48.65%, Target Acc=50.00%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/50 Summary:\n",
      "CLS Loss: 2.4899 | CONT Loss: 1.5941 | Total Loss: 4.0840\n",
      "Source Acc: 59.77% | Target Acc: 47.38%\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/1: 100%|██████████| 5/5 [00:00<00:00, 25.11it/s, loss=1.496364, acc=0.493750]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]7/50: 100%|██████████| 225/225 [00:30<00:00,  7.41it/s, CLS Loss=2.4531, CONT Loss=1.5759, Total Loss=4.0290, Source Acc=56.76%, Target Acc=60.00%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/50 Summary:\n",
      "CLS Loss: 2.4531 | CONT Loss: 1.5759 | Total Loss: 4.0290\n",
      "Source Acc: 59.47% | Target Acc: 50.58%\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/1: 100%|██████████| 5/5 [00:00<00:00, 24.50it/s, loss=1.376477, acc=0.543750]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAVED-BEST-WEIGHTS!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]8/50: 100%|██████████| 225/225 [00:30<00:00,  7.31it/s, CLS Loss=2.4200, CONT Loss=1.5771, Total Loss=3.9971, Source Acc=56.76%, Target Acc=50.00%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/50 Summary:\n",
      "CLS Loss: 2.4200 | CONT Loss: 1.5771 | Total Loss: 3.9971\n",
      "Source Acc: 59.61% | Target Acc: 56.53%\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/1: 100%|██████████| 5/5 [00:00<00:00, 20.54it/s, loss=1.526329, acc=0.443750]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAVED-BEST-WEIGHTS!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]9/50: 100%|██████████| 225/225 [00:30<00:00,  7.39it/s, CLS Loss=2.3374, CONT Loss=1.5609, Total Loss=3.8983, Source Acc=64.86%, Target Acc=60.00%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9/50 Summary:\n",
      "CLS Loss: 2.3374 | CONT Loss: 1.5609 | Total Loss: 3.8983\n",
      "Source Acc: 59.89% | Target Acc: 55.64%\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/1: 100%|██████████| 5/5 [00:00<00:00, 20.53it/s, loss=1.693665, acc=0.450000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAVED-BEST-WEIGHTS!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]10/50: 100%|██████████| 225/225 [00:30<00:00,  7.44it/s, CLS Loss=2.3012, CONT Loss=1.5594, Total Loss=3.8606, Source Acc=45.95%, Target Acc=10.00%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/50 Summary:\n",
      "CLS Loss: 2.3012 | CONT Loss: 1.5594 | Total Loss: 3.8606\n",
      "Source Acc: 59.87% | Target Acc: 54.62%\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/1: 100%|██████████| 5/5 [00:00<00:00, 25.20it/s, loss=1.495873, acc=0.456250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAVED-BEST-WEIGHTS!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]11/50: 100%|██████████| 225/225 [00:30<00:00,  7.36it/s, CLS Loss=2.2555, CONT Loss=1.5676, Total Loss=3.8231, Source Acc=59.46%, Target Acc=70.00%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11/50 Summary:\n",
      "CLS Loss: 2.2555 | CONT Loss: 1.5676 | Total Loss: 3.8231\n",
      "Source Acc: 59.57% | Target Acc: 57.73%\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/1: 100%|██████████| 5/5 [00:00<00:00, 24.32it/s, loss=1.632192, acc=0.425000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAVED-BEST-WEIGHTS!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]12/50: 100%|██████████| 225/225 [00:29<00:00,  7.60it/s, CLS Loss=2.2520, CONT Loss=1.5281, Total Loss=3.7801, Source Acc=72.97%, Target Acc=70.00%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12/50 Summary:\n",
      "CLS Loss: 2.2520 | CONT Loss: 1.5281 | Total Loss: 3.7801\n",
      "Source Acc: 59.59% | Target Acc: 57.24%\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/1: 100%|██████████| 5/5 [00:00<00:00, 24.44it/s, loss=1.426100, acc=0.500000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAVED-BEST-WEIGHTS!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]13/50: 100%|██████████| 225/225 [00:30<00:00,  7.30it/s, CLS Loss=2.3063, CONT Loss=1.5422, Total Loss=3.8485, Source Acc=67.57%, Target Acc=70.00%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13/50 Summary:\n",
      "CLS Loss: 2.3063 | CONT Loss: 1.5422 | Total Loss: 3.8485\n",
      "Source Acc: 59.77% | Target Acc: 54.76%\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/1: 100%|██████████| 5/5 [00:00<00:00, 25.42it/s, loss=1.816779, acc=0.375000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]14/50: 100%|██████████| 225/225 [00:28<00:00,  7.79it/s, CLS Loss=2.2403, CONT Loss=1.5334, Total Loss=3.7738, Source Acc=59.46%, Target Acc=40.00%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14/50 Summary:\n",
      "CLS Loss: 2.2403 | CONT Loss: 1.5334 | Total Loss: 3.7738\n",
      "Source Acc: 60.25% | Target Acc: 56.80%\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/1: 100%|██████████| 5/5 [00:00<00:00, 21.44it/s, loss=1.410288, acc=0.487500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAVED-BEST-WEIGHTS!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]15/50: 100%|██████████| 225/225 [00:29<00:00,  7.73it/s, CLS Loss=2.1937, CONT Loss=1.5439, Total Loss=3.7376, Source Acc=48.65%, Target Acc=70.00%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15/50 Summary:\n",
      "CLS Loss: 2.1937 | CONT Loss: 1.5439 | Total Loss: 3.7376\n",
      "Source Acc: 60.29% | Target Acc: 62.36%\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/1: 100%|██████████| 5/5 [00:00<00:00, 24.85it/s, loss=1.371184, acc=0.493750]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAVED-BEST-WEIGHTS!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]16/50: 100%|██████████| 225/225 [00:29<00:00,  7.72it/s, CLS Loss=2.2051, CONT Loss=1.5219, Total Loss=3.7270, Source Acc=64.86%, Target Acc=50.00%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16/50 Summary:\n",
      "CLS Loss: 2.2051 | CONT Loss: 1.5219 | Total Loss: 3.7270\n",
      "Source Acc: 60.21% | Target Acc: 61.64%\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/1: 100%|██████████| 5/5 [00:00<00:00, 24.40it/s, loss=1.657290, acc=0.443750]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAVED-BEST-WEIGHTS!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]17/50: 100%|██████████| 225/225 [00:29<00:00,  7.76it/s, CLS Loss=2.2340, CONT Loss=1.5246, Total Loss=3.7586, Source Acc=67.57%, Target Acc=70.00%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17/50 Summary:\n",
      "CLS Loss: 2.2340 | CONT Loss: 1.5246 | Total Loss: 3.7586\n",
      "Source Acc: 60.01% | Target Acc: 61.11%\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/1: 100%|██████████| 5/5 [00:00<00:00, 22.16it/s, loss=1.585480, acc=0.462500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]18/50: 100%|██████████| 225/225 [00:29<00:00,  7.69it/s, CLS Loss=2.1423, CONT Loss=1.5310, Total Loss=3.6732, Source Acc=70.27%, Target Acc=70.00%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18/50 Summary:\n",
      "CLS Loss: 2.1423 | CONT Loss: 1.5310 | Total Loss: 3.6732\n",
      "Source Acc: 60.34% | Target Acc: 62.36%\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/1: 100%|██████████| 5/5 [00:00<00:00, 25.48it/s, loss=1.405279, acc=0.487500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAVED-BEST-WEIGHTS!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]19/50: 100%|██████████| 225/225 [00:29<00:00,  7.52it/s, CLS Loss=2.1394, CONT Loss=1.5165, Total Loss=3.6559, Source Acc=56.76%, Target Acc=50.00%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19/50 Summary:\n",
      "CLS Loss: 2.1394 | CONT Loss: 1.5165 | Total Loss: 3.6559\n",
      "Source Acc: 60.30% | Target Acc: 62.09%\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/1: 100%|██████████| 5/5 [00:00<00:00, 23.41it/s, loss=1.363287, acc=0.575000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAVED-BEST-WEIGHTS!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]20/50: 100%|██████████| 225/225 [00:29<00:00,  7.58it/s, CLS Loss=2.1329, CONT Loss=1.5161, Total Loss=3.6491, Source Acc=45.95%, Target Acc=50.00%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20/50 Summary:\n",
      "CLS Loss: 2.1329 | CONT Loss: 1.5161 | Total Loss: 3.6491\n",
      "Source Acc: 60.49% | Target Acc: 66.67%\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/1: 100%|██████████| 5/5 [00:00<00:00, 25.01it/s, loss=1.668858, acc=0.487500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAVED-BEST-WEIGHTS!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]21/50: 100%|██████████| 225/225 [00:30<00:00,  7.47it/s, CLS Loss=2.1713, CONT Loss=1.5363, Total Loss=3.7075, Source Acc=51.35%, Target Acc=70.00%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 21/50 Summary:\n",
      "CLS Loss: 2.1713 | CONT Loss: 1.5363 | Total Loss: 3.7075\n",
      "Source Acc: 60.45% | Target Acc: 61.11%\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/1: 100%|██████████| 5/5 [00:00<00:00, 24.79it/s, loss=1.650088, acc=0.400000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]22/50: 100%|██████████| 225/225 [00:29<00:00,  7.67it/s, CLS Loss=2.1338, CONT Loss=1.5002, Total Loss=3.6340, Source Acc=72.97%, Target Acc=90.00%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 22/50 Summary:\n",
      "CLS Loss: 2.1338 | CONT Loss: 1.5002 | Total Loss: 3.6340\n",
      "Source Acc: 60.11% | Target Acc: 62.27%\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/1: 100%|██████████| 5/5 [00:00<00:00, 25.39it/s, loss=1.487888, acc=0.543750]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAVED-BEST-WEIGHTS!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]23/50: 100%|██████████| 225/225 [00:29<00:00,  7.63it/s, CLS Loss=2.0625, CONT Loss=1.5015, Total Loss=3.5641, Source Acc=70.27%, Target Acc=80.00%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 23/50 Summary:\n",
      "CLS Loss: 2.0625 | CONT Loss: 1.5015 | Total Loss: 3.5641\n",
      "Source Acc: 60.75% | Target Acc: 66.36%\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/1: 100%|██████████| 5/5 [00:00<00:00, 22.30it/s, loss=1.627158, acc=0.437500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAVED-BEST-WEIGHTS!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]24/50: 100%|██████████| 225/225 [00:30<00:00,  7.46it/s, CLS Loss=2.1120, CONT Loss=1.5144, Total Loss=3.6264, Source Acc=64.86%, Target Acc=60.00%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 24/50 Summary:\n",
      "CLS Loss: 2.1120 | CONT Loss: 1.5144 | Total Loss: 3.6264\n",
      "Source Acc: 60.61% | Target Acc: 62.67%\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/1: 100%|██████████| 5/5 [00:00<00:00, 26.45it/s, loss=1.488162, acc=0.475000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]25/50: 100%|██████████| 225/225 [00:52<00:00,  4.32it/s, CLS Loss=2.1837, CONT Loss=1.5299, Total Loss=3.7136, Source Acc=54.05%, Target Acc=70.00%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 25/50 Summary:\n",
      "CLS Loss: 2.1837 | CONT Loss: 1.5299 | Total Loss: 3.7136\n",
      "Source Acc: 60.66% | Target Acc: 60.67%\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/1: 100%|██████████| 5/5 [00:00<00:00, 14.67it/s, loss=1.450806, acc=0.450000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]26/50: 100%|██████████| 225/225 [01:05<00:00,  3.45it/s, CLS Loss=2.0467, CONT Loss=1.5064, Total Loss=3.5531, Source Acc=54.05%, Target Acc=100.00%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 26/50 Summary:\n",
      "CLS Loss: 2.0467 | CONT Loss: 1.5064 | Total Loss: 3.5531\n",
      "Source Acc: 60.63% | Target Acc: 67.20%\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/1: 100%|██████████| 5/5 [00:00<00:00, 19.89it/s, loss=1.364113, acc=0.562500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAVED-BEST-WEIGHTS!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]27/50: 100%|██████████| 225/225 [01:45<00:00,  2.14it/s, CLS Loss=2.0289, CONT Loss=1.5128, Total Loss=3.5418, Source Acc=70.27%, Target Acc=70.00%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 27/50 Summary:\n",
      "CLS Loss: 2.0289 | CONT Loss: 1.5128 | Total Loss: 3.5418\n",
      "Source Acc: 60.19% | Target Acc: 67.24%\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/1: 100%|██████████| 5/5 [00:00<00:00, 18.24it/s, loss=1.446953, acc=0.500000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAVED-BEST-WEIGHTS!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]28/50: 100%|██████████| 225/225 [00:37<00:00,  6.04it/s, CLS Loss=2.1738, CONT Loss=1.5087, Total Loss=3.6825, Source Acc=64.86%, Target Acc=40.00%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 28/50 Summary:\n",
      "CLS Loss: 2.1738 | CONT Loss: 1.5087 | Total Loss: 3.6825\n",
      "Source Acc: 60.25% | Target Acc: 60.18%\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/1: 100%|██████████| 5/5 [00:00<00:00, 14.28it/s, loss=1.440465, acc=0.437500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]29/50: 100%|██████████| 225/225 [01:01<00:00,  3.66it/s, CLS Loss=2.1053, CONT Loss=1.5091, Total Loss=3.6144, Source Acc=51.35%, Target Acc=70.00%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 29/50 Summary:\n",
      "CLS Loss: 2.1053 | CONT Loss: 1.5091 | Total Loss: 3.6144\n",
      "Source Acc: 60.57% | Target Acc: 63.64%\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/1: 100%|██████████| 5/5 [00:00<00:00, 14.66it/s, loss=1.546764, acc=0.450000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]30/50: 100%|██████████| 225/225 [00:59<00:00,  3.81it/s, CLS Loss=2.1446, CONT Loss=1.5103, Total Loss=3.6550, Source Acc=56.76%, Target Acc=70.00%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 30/50 Summary:\n",
      "CLS Loss: 2.1446 | CONT Loss: 1.5103 | Total Loss: 3.6550\n",
      "Source Acc: 60.32% | Target Acc: 61.73%\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/1: 100%|██████████| 5/5 [00:00<00:00, 14.03it/s, loss=1.427198, acc=0.487500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No improvement in validation loss for 3 epoch(s).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]31/50: 100%|██████████| 225/225 [00:59<00:00,  3.80it/s, CLS Loss=2.0106, CONT Loss=1.4872, Total Loss=3.4979, Source Acc=67.57%, Target Acc=80.00%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 31/50 Summary:\n",
      "CLS Loss: 2.0106 | CONT Loss: 1.4872 | Total Loss: 3.4979\n",
      "Source Acc: 60.44% | Target Acc: 65.78%\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/1: 100%|██████████| 5/5 [00:00<00:00, 14.36it/s, loss=1.563166, acc=0.475000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAVED-BEST-WEIGHTS!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]32/50: 100%|██████████| 225/225 [01:02<00:00,  3.60it/s, CLS Loss=1.9847, CONT Loss=1.5029, Total Loss=3.4876, Source Acc=67.57%, Target Acc=90.00%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 32/50 Summary:\n",
      "CLS Loss: 1.9847 | CONT Loss: 1.5029 | Total Loss: 3.4876\n",
      "Source Acc: 60.59% | Target Acc: 69.87%\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/1: 100%|██████████| 5/5 [00:00<00:00, 14.25it/s, loss=1.286118, acc=0.593750]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAVED-BEST-WEIGHTS!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]33/50: 100%|██████████| 225/225 [01:01<00:00,  3.64it/s, CLS Loss=2.1017, CONT Loss=1.4857, Total Loss=3.5874, Source Acc=54.05%, Target Acc=60.00%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 33/50 Summary:\n",
      "CLS Loss: 2.1017 | CONT Loss: 1.4857 | Total Loss: 3.5874\n",
      "Source Acc: 60.54% | Target Acc: 64.31%\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/1: 100%|██████████| 5/5 [00:00<00:00, 14.92it/s, loss=1.397176, acc=0.512500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]34/50: 100%|██████████| 225/225 [01:00<00:00,  3.73it/s, CLS Loss=1.9498, CONT Loss=1.4862, Total Loss=3.4360, Source Acc=48.65%, Target Acc=100.00%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 34/50 Summary:\n",
      "CLS Loss: 1.9498 | CONT Loss: 1.4862 | Total Loss: 3.4360\n",
      "Source Acc: 60.76% | Target Acc: 74.00%\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/1: 100%|██████████| 5/5 [00:00<00:00, 13.76it/s, loss=1.450337, acc=0.481250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAVED-BEST-WEIGHTS!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]35/50: 100%|██████████| 225/225 [00:59<00:00,  3.75it/s, CLS Loss=2.0397, CONT Loss=1.4770, Total Loss=3.5167, Source Acc=67.57%, Target Acc=70.00%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 35/50 Summary:\n",
      "CLS Loss: 2.0397 | CONT Loss: 1.4770 | Total Loss: 3.5167\n",
      "Source Acc: 60.19% | Target Acc: 68.98%\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/1: 100%|██████████| 5/5 [00:00<00:00, 14.52it/s, loss=1.496696, acc=0.456250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]36/50: 100%|██████████| 225/225 [01:01<00:00,  3.63it/s, CLS Loss=2.0215, CONT Loss=1.4740, Total Loss=3.4955, Source Acc=56.76%, Target Acc=70.00%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 36/50 Summary:\n",
      "CLS Loss: 2.0215 | CONT Loss: 1.4740 | Total Loss: 3.4955\n",
      "Source Acc: 60.62% | Target Acc: 66.44%\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/1: 100%|██████████| 5/5 [00:00<00:00, 14.99it/s, loss=1.362674, acc=0.537500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]37/50: 100%|██████████| 225/225 [01:02<00:00,  3.63it/s, CLS Loss=2.0012, CONT Loss=1.5008, Total Loss=3.5020, Source Acc=72.97%, Target Acc=90.00%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 37/50 Summary:\n",
      "CLS Loss: 2.0012 | CONT Loss: 1.5008 | Total Loss: 3.5020\n",
      "Source Acc: 60.62% | Target Acc: 68.40%\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/1: 100%|██████████| 5/5 [00:00<00:00, 14.60it/s, loss=1.386590, acc=0.493750]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No improvement in validation loss for 3 epoch(s).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]38/50: 100%|██████████| 225/225 [01:00<00:00,  3.69it/s, CLS Loss=1.9211, CONT Loss=1.4542, Total Loss=3.3754, Source Acc=59.46%, Target Acc=80.00%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 38/50 Summary:\n",
      "CLS Loss: 1.9211 | CONT Loss: 1.4542 | Total Loss: 3.3754\n",
      "Source Acc: 60.58% | Target Acc: 72.13%\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/1: 100%|██████████| 5/5 [00:00<00:00, 14.00it/s, loss=1.406615, acc=0.475000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAVED-BEST-WEIGHTS!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]39/50: 100%|██████████| 225/225 [01:01<00:00,  3.66it/s, CLS Loss=2.0078, CONT Loss=1.4740, Total Loss=3.4818, Source Acc=59.46%, Target Acc=90.00%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 39/50 Summary:\n",
      "CLS Loss: 2.0078 | CONT Loss: 1.4740 | Total Loss: 3.4818\n",
      "Source Acc: 60.67% | Target Acc: 67.42%\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/1: 100%|██████████| 5/5 [00:00<00:00, 14.35it/s, loss=1.367625, acc=0.468750]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]40/50: 100%|██████████| 225/225 [01:01<00:00,  3.64it/s, CLS Loss=1.9506, CONT Loss=1.4685, Total Loss=3.4192, Source Acc=67.57%, Target Acc=60.00%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 40/50 Summary:\n",
      "CLS Loss: 1.9506 | CONT Loss: 1.4685 | Total Loss: 3.4192\n",
      "Source Acc: 60.63% | Target Acc: 68.84%\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/1: 100%|██████████| 5/5 [00:00<00:00, 14.11it/s, loss=1.409916, acc=0.406250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]41/50: 100%|██████████| 225/225 [01:00<00:00,  3.71it/s, CLS Loss=1.9469, CONT Loss=1.4955, Total Loss=3.4424, Source Acc=59.46%, Target Acc=100.00%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 41/50 Summary:\n",
      "CLS Loss: 1.9469 | CONT Loss: 1.4955 | Total Loss: 3.4424\n",
      "Source Acc: 60.71% | Target Acc: 72.36%\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/1: 100%|██████████| 5/5 [00:00<00:00, 13.75it/s, loss=1.376671, acc=0.512500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No improvement in validation loss for 3 epoch(s).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]42/50: 100%|██████████| 225/225 [01:02<00:00,  3.63it/s, CLS Loss=1.9787, CONT Loss=1.4793, Total Loss=3.4580, Source Acc=64.86%, Target Acc=100.00%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 42/50 Summary:\n",
      "CLS Loss: 1.9787 | CONT Loss: 1.4793 | Total Loss: 3.4580\n",
      "Source Acc: 60.99% | Target Acc: 68.80%\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/1: 100%|██████████| 5/5 [00:00<00:00, 15.26it/s, loss=1.496328, acc=0.475000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No improvement in validation loss for 4 epoch(s).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]43/50: 100%|██████████| 225/225 [01:01<00:00,  3.69it/s, CLS Loss=1.8828, CONT Loss=1.4742, Total Loss=3.3570, Source Acc=67.57%, Target Acc=90.00%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 43/50 Summary:\n",
      "CLS Loss: 1.8828 | CONT Loss: 1.4742 | Total Loss: 3.3570\n",
      "Source Acc: 60.78% | Target Acc: 74.53%\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/1: 100%|██████████| 5/5 [00:00<00:00, 14.63it/s, loss=1.632458, acc=0.468750]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAVED-BEST-WEIGHTS!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]44/50: 100%|██████████| 225/225 [01:01<00:00,  3.69it/s, CLS Loss=1.9595, CONT Loss=1.4900, Total Loss=3.4495, Source Acc=64.86%, Target Acc=80.00%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 44/50 Summary:\n",
      "CLS Loss: 1.9595 | CONT Loss: 1.4900 | Total Loss: 3.4495\n",
      "Source Acc: 60.38% | Target Acc: 71.91%\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/1: 100%|██████████| 5/5 [00:00<00:00, 14.17it/s, loss=1.456745, acc=0.443750]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]45/50: 100%|██████████| 225/225 [01:01<00:00,  3.67it/s, CLS Loss=1.9521, CONT Loss=1.4651, Total Loss=3.4172, Source Acc=54.05%, Target Acc=80.00%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 45/50 Summary:\n",
      "CLS Loss: 1.9521 | CONT Loss: 1.4651 | Total Loss: 3.4172\n",
      "Source Acc: 61.07% | Target Acc: 71.56%\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/1: 100%|██████████| 5/5 [00:00<00:00, 14.94it/s, loss=1.643028, acc=0.437500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]46/50: 100%|██████████| 225/225 [01:02<00:00,  3.61it/s, CLS Loss=1.9189, CONT Loss=1.4532, Total Loss=3.3721, Source Acc=62.16%, Target Acc=90.00%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 46/50 Summary:\n",
      "CLS Loss: 1.9189 | CONT Loss: 1.4532 | Total Loss: 3.3721\n",
      "Source Acc: 60.88% | Target Acc: 71.96%\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/1: 100%|██████████| 5/5 [00:00<00:00, 14.13it/s, loss=1.631629, acc=0.487500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No improvement in validation loss for 3 epoch(s).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]47/50: 100%|██████████| 225/225 [01:01<00:00,  3.68it/s, CLS Loss=1.8195, CONT Loss=1.4690, Total Loss=3.2885, Source Acc=54.05%, Target Acc=80.00%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 47/50 Summary:\n",
      "CLS Loss: 1.8195 | CONT Loss: 1.4690 | Total Loss: 3.2885\n",
      "Source Acc: 61.17% | Target Acc: 77.60%\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/1: 100%|██████████| 5/5 [00:00<00:00, 13.48it/s, loss=1.398213, acc=0.531250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAVED-BEST-WEIGHTS!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]48/50: 100%|██████████| 225/225 [02:19<00:00,  1.62it/s, CLS Loss=1.9531, CONT Loss=1.4861, Total Loss=3.4392, Source Acc=72.97%, Target Acc=100.00%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 48/50 Summary:\n",
      "CLS Loss: 1.9531 | CONT Loss: 1.4861 | Total Loss: 3.4392\n",
      "Source Acc: 60.96% | Target Acc: 70.80%\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/1: 100%|██████████| 5/5 [00:00<00:00, 15.02it/s, loss=1.429320, acc=0.418750]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]49/50: 100%|██████████| 225/225 [00:38<00:00,  5.89it/s, CLS Loss=1.8476, CONT Loss=1.4510, Total Loss=3.2986, Source Acc=67.57%, Target Acc=100.00%]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 49/50 Summary:\n",
      "CLS Loss: 1.8476 | CONT Loss: 1.4510 | Total Loss: 3.2986\n",
      "Source Acc: 60.81% | Target Acc: 76.89%\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/1: 100%|██████████| 5/5 [00:00<00:00, 20.78it/s, loss=1.502562, acc=0.481250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]50/50: 100%|██████████| 225/225 [00:29<00:00,  7.56it/s, CLS Loss=2.0265, CONT Loss=1.4676, Total Loss=3.4941, Source Acc=72.97%, Target Acc=80.00%] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 50/50 Summary:\n",
      "CLS Loss: 2.0265 | CONT Loss: 1.4676 | Total Loss: 3.4941\n",
      "Source Acc: 61.14% | Target Acc: 65.29%\n",
      "\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/1: 100%|██████████| 5/5 [00:00<00:00, 24.58it/s, loss=1.576431, acc=0.475000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No improvement in validation loss for 3 epoch(s).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "contrastive_loss_metrics = {\n",
    "    'cls_loss': [],\n",
    "    'cont_loss': [],\n",
    "    'total_loss': [],\n",
    "    'source_accuracy': [],\n",
    "    'target_accuracy': []\n",
    "}\n",
    "\n",
    "validation_loss_accuracy = {\n",
    "    'validation_loss': [],\n",
    "    'validation_accuracy': []\n",
    "}\n",
    "\n",
    "best_valid_loss = np.inf\n",
    "patience_counter = 0   # Tracks the number of epochs without improvement\n",
    "early_stop = False # Flag to indicate whether to stop training\n",
    "save_weights_patience = 5\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    if early_stop:\n",
    "        print(\"Early stopping triggered. Stopping training.\")\n",
    "        break\n",
    "        \n",
    "    cls_loss, cont_loss, total_loss, source_acc, target_acc = \\\n",
    "        train_epoch(model_contrastive, training_loader, few_shot_loader, optimizer, epoch, EPOCHS)\n",
    "    \n",
    "    contrastive_loss_metrics['cls_loss'].append(cls_loss)\n",
    "    contrastive_loss_metrics['cont_loss'].append(cont_loss)\n",
    "    contrastive_loss_metrics['total_loss'].append(total_loss)\n",
    "    contrastive_loss_metrics['source_accuracy'].append(source_acc)\n",
    "    contrastive_loss_metrics['target_accuracy'].append(target_acc)\n",
    "    \n",
    "    print()\n",
    "    current_val_loss_accuracy = test_out_of_distribution(model_contrastive, manga_faces_test_images_loader, epochs=1, device=device)\n",
    "    validation_loss_accuracy['validation_loss'].append(float(current_val_loss_accuracy['validation_loss'][0]))\n",
    "    validation_loss_accuracy['validation_accuracy'].append(float(current_val_loss_accuracy['validation_accuracy'][0]))\n",
    "    \n",
    "    \n",
    "    if total_loss < best_valid_loss:\n",
    "        torch.save(model_contrastive.state_dict(), 'weights/base_model_contrastive_learning_weights.pt')\n",
    "        print(\"SAVED-BEST-WEIGHTS!\")\n",
    "        best_valid_loss = total_loss\n",
    "        patience_counter = 0 # Reset early stopping\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"No improvement in validation loss for {patience_counter} epoch(s).\")\n",
    "\n",
    "    if patience_counter >= save_weights_patience:\n",
    "        print(\"Patience exceeded. Early stopping at epoch \" +str(epoch + 1))\n",
    "        early_stop = True\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98419f65",
   "metadata": {},
   "source": [
    "#### Store Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c67b5357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses and accuracy saved\n"
     ]
    }
   ],
   "source": [
    "# Store the metrics from when the model was tested on the out-of-distribution dataset\n",
    "data = {\n",
    "    \"Epoch\": list(range(1, len(contrastive_loss_metrics['cls_loss']) + 1)),\n",
    "    \"CLS_LOSS\": contrastive_loss_metrics['cls_loss'],\n",
    "    \"CONT_LOSS\": contrastive_loss_metrics['cont_loss'],\n",
    "    \"Total Loss\": contrastive_loss_metrics['total_loss'],\n",
    "    \"Source Accuracy\": contrastive_loss_metrics['source_accuracy'],\n",
    "    \"Target Accuracy\": contrastive_loss_metrics['target_accuracy']\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"stats/base_model_contrastive_learning_stats_training.csv\", index=False)\n",
    "print(\"Losses and accuracy saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906d57b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses and accuracy saved\n"
     ]
    }
   ],
   "source": [
    "# Store the metrics from when the model was tested on the out-of-distribution dataset\n",
    "data = {\n",
    "    \"Epoch\": list(range(1, len(validation_loss_accuracy['validation_loss']) + 1)),\n",
    "    \"Validation Loss\": validation_loss_accuracy['validation_loss'],\n",
    "    \"Validation Accuracy\": validation_loss_accuracy['validation_accuracy']\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"stats/base_model_contrastive_learning_TESTINGSET_stats_training.csv\", index=False)\n",
    "print(\"Losses and accuracy saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "95fd4686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/10: 100%|██████████| 5/5 [00:00<00:00, 15.84it/s, loss=1.654963, acc=0.475000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]2/10: 100%|██████████| 5/5 [00:00<00:00, 16.38it/s, loss=1.760662, acc=0.475000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]3/10: 100%|██████████| 5/5 [00:00<00:00, 16.51it/s, loss=1.555554, acc=0.475000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]4/10: 100%|██████████| 5/5 [00:00<00:00, 16.49it/s, loss=1.604056, acc=0.475000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]5/10: 100%|██████████| 5/5 [00:00<00:00, 15.37it/s, loss=1.491023, acc=0.475000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]6/10: 100%|██████████| 5/5 [00:00<00:00, 16.52it/s, loss=1.412548, acc=0.518750]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]7/10: 100%|██████████| 5/5 [00:00<00:00, 15.56it/s, loss=1.551669, acc=0.475000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]8/10: 100%|██████████| 5/5 [00:00<00:00, 15.27it/s, loss=1.735529, acc=0.475000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]9/10: 100%|██████████| 5/5 [00:00<00:00, 15.71it/s, loss=1.670435, acc=0.431250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]10/10: 100%|██████████| 5/5 [00:00<00:00, 16.71it/s, loss=1.543441, acc=0.475000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# tEST the model:\n",
    "cont_test_out_of_distribution_metrics = test_out_of_distribution(model_contrastive, manga_faces_test_images_loader, epochs=10, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3eea2477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, target=False):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for imgs, lbls in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            imgs = imgs.to(device)\n",
    "            lbls = lbls.to(device)\n",
    "            \n",
    "            logits, _ = model(imgs, return_embeddings=True)\n",
    "            preds = logits.argmax(dim=1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(lbls.cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = 100 * (np.array(all_preds) == np.array(all_labels)).mean()\n",
    "    class_report = classification_report(all_labels, all_preds, zero_division=0)\n",
    "    \n",
    "    print(f\"{'Target' if target else 'Source'} Test Accuracy: {accuracy:.2f}%\")\n",
    "    print(\"\\nClassification Report:\\n\", class_report)\n",
    "    \n",
    "    return accuracy, class_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d90fce5",
   "metadata": {},
   "source": [
    "#### Test on Source Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7714becb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 57/57 [00:48<00:00,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Test Accuracy: 60.76%\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.64      0.54       958\n",
      "           1       0.66      0.30      0.41       111\n",
      "           2       0.57      0.20      0.30      1024\n",
      "           3       0.79      0.86      0.82      1774\n",
      "           4       0.54      0.64      0.58      1233\n",
      "           5       0.51      0.43      0.46      1247\n",
      "           6       0.67      0.82      0.73       831\n",
      "\n",
      "    accuracy                           0.61      7178\n",
      "   macro avg       0.60      0.55      0.55      7178\n",
      "weighted avg       0.61      0.61      0.59      7178\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "source_test_accuracy, source_report = evaluate_model(model_contrastive, test_loader)\n",
    "# Contrastive learning model does not forget the source domain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d965a2",
   "metadata": {},
   "source": [
    "#### Test on Target Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "46a78bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 5/5 [00:00<00:00, 11.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Test Accuracy: 46.97%\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.62      0.51        21\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.80      0.67      0.73        49\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.52      0.50      0.51        22\n",
      "           6       0.50      0.12      0.20        40\n",
      "\n",
      "    accuracy                           0.47       132\n",
      "   macro avg       0.38      0.32      0.33       132\n",
      "weighted avg       0.61      0.47      0.50       132\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "target_test_accuracy, target_report = evaluate_model(model_contrastive, manga_faces_test_images_loader, target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c5fba147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'angry': 0,\n",
       " 'disgust': 1,\n",
       " 'fear': 2,\n",
       " 'happy': 3,\n",
       " 'neutral': 4,\n",
       " 'sad': 5,\n",
       " 'surprise': 6}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.class_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2513c430",
   "metadata": {},
   "source": [
    "- Align labels in source and target (limitation)\n",
    "- Split Manga dataset into train and test set  (limitation of small data set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe02458",
   "metadata": {},
   "source": [
    "The initial labels that were similar across both data sets include Angry, Happy, and Sad.\n",
    "\n",
    "The remaining labels in the Manga faces data set include Crying, Embarrassd, Pleased, and Shock\n",
    "The remaining labels in the FER 2013 data set include Disgust, Fear, Neutral, and Surprise\n",
    "\n",
    "\n",
    "I will rename the 'Shock' label in Manga to Surprise. \\\n",
    "I will combine the Pleased label with the Happy label of the Manga faces dataset \\\n",
    "Also, I will rename the Embarrassed label in Manga faces to \n",
    "\n",
    "After this, the new labels in the Manga faces become: Angry, Happy (+Pleased), Sad, and Surprise (Shock)\n",
    "\n",
    "The new data set will then be split into 60% for training and 40% for validation\n",
    "\n",
    "Small testing Manga faces data set is a limitation\n",
    "\n",
    "FUTURE WORK: More experiments with temperature and contrastive loss weighting.\n",
    "experiment on loss functions and hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4359449",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
