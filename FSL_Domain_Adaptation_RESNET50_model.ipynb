{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73db0601",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10b8bb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchinfo import summary\n",
    "from tqdm import tqdm\n",
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a374da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb69d7f8",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d415bfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f070573d",
   "metadata": {},
   "source": [
    "## Data Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5689ad0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transforms = T.Compose([\n",
    "    T.Resize((48, 48)),\n",
    "    T.ToTensor(),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    T.Normalize(mean, std),\n",
    "    T.RandomAffine(degrees=0, shear=0.2, scale=(0.8, 1.2))\n",
    "])\n",
    "\n",
    "val_transforms = T.Compose([\n",
    "    T.Resize((48, 48)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean, std)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369f49a1",
   "metadata": {},
   "source": [
    "## DataSet and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "04df5c89",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "fer_2013_dir = Path(os.getcwd(), 'datasets', 'fer2013')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97db57d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = ImageFolder(root=fer_2013_dir / 'train', transform=train_transforms)\n",
    "training_loader = DataLoader(training_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_set = ImageFolder(root=fer_2013_dir / 'test', transform=val_transforms)\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "40020c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 28709 images\n",
      "Testing set: 7178 images\n",
      "One image batch shape : torch.Size([128, 3, 48, 48])\n",
      "One label batch shape : torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "# Print shape of training and testing images\n",
    "print(f\"Training set: {len(training_set)} images\")\n",
    "print(f\"Testing set: {len(test_set)} images\")\n",
    "\n",
    "for images, labels in training_loader:\n",
    "  break\n",
    "\n",
    "print(f\"One image batch shape : {images.shape}\")\n",
    "print(f\"One label batch shape : {labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "17391128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'angry': 0, 'disgust': 1, 'fear': 2, 'happy': 3, 'neutral': 4, 'sad': 5, 'surprise': 6}\n"
     ]
    }
   ],
   "source": [
    "print(training_set.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c08b7dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    0: 'angry', 1: 'disgust', 2: 'fear', 3: 'happy', \n",
    "    4: 'neutral', 5: 'sad', 6: 'surprise'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3867fc1",
   "metadata": {},
   "source": [
    "#### Show sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bc0b98a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get a batch\n",
    "images, labels = next(iter(training_loader))\n",
    "\n",
    "# Unnormalize a few images from the batch\n",
    "def unnormalize(img):\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    return img * std + mean\n",
    "\n",
    "# Display first 4 images\n",
    "fig, axes = plt.subplots(1, 4, figsize=(12, 4))\n",
    "\n",
    "for i in range(4):\n",
    "    img = unnormalize(images[i])\n",
    "    img = img.permute(1, 2, 0)  # (C, H, W) -> (H, W, C)\n",
    "    axes[i].imshow(img)\n",
    "    axes[i].set_title(f\"Label: {label_map[int(labels[i])]}\")\n",
    "    axes[i].axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e253eda5",
   "metadata": {},
   "source": [
    "# ResNet50 Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41261683",
   "metadata": {},
   "source": [
    "### Define Class & Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0a2f5287",
   "metadata": {},
   "outputs": [],
   "source": [
    "params={          \n",
    "        \"dropout_rate\": 0.2,\n",
    "        \"num_classes\": 7,\n",
    "}\n",
    "\n",
    "resnet50_fer_model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "resnet50_fer_model.fc = nn.Sequential(\n",
    "    nn.Dropout(params[\"dropout_rate\"]),\n",
    "    nn.Linear(resnet50_fer_model.fc.in_features, params[\"num_classes\"])\n",
    ")\n",
    "resnet50_fer_model = resnet50_fer_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "21b95d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "ResNet                                   [128, 7]                  --\n",
      "├─Conv2d: 1-1                            [128, 64, 24, 24]         9,408\n",
      "├─BatchNorm2d: 1-2                       [128, 64, 24, 24]         128\n",
      "├─ReLU: 1-3                              [128, 64, 24, 24]         --\n",
      "├─MaxPool2d: 1-4                         [128, 64, 12, 12]         --\n",
      "├─Sequential: 1-5                        [128, 256, 12, 12]        --\n",
      "│    └─Bottleneck: 2-1                   [128, 256, 12, 12]        --\n",
      "│    │    └─Conv2d: 3-1                  [128, 64, 12, 12]         4,096\n",
      "│    │    └─BatchNorm2d: 3-2             [128, 64, 12, 12]         128\n",
      "│    │    └─ReLU: 3-3                    [128, 64, 12, 12]         --\n",
      "│    │    └─Conv2d: 3-4                  [128, 64, 12, 12]         36,864\n",
      "│    │    └─BatchNorm2d: 3-5             [128, 64, 12, 12]         128\n",
      "│    │    └─ReLU: 3-6                    [128, 64, 12, 12]         --\n",
      "│    │    └─Conv2d: 3-7                  [128, 256, 12, 12]        16,384\n",
      "│    │    └─BatchNorm2d: 3-8             [128, 256, 12, 12]        512\n",
      "│    │    └─Sequential: 3-9              [128, 256, 12, 12]        16,896\n",
      "│    │    └─ReLU: 3-10                   [128, 256, 12, 12]        --\n",
      "│    └─Bottleneck: 2-2                   [128, 256, 12, 12]        --\n",
      "│    │    └─Conv2d: 3-11                 [128, 64, 12, 12]         16,384\n",
      "│    │    └─BatchNorm2d: 3-12            [128, 64, 12, 12]         128\n",
      "│    │    └─ReLU: 3-13                   [128, 64, 12, 12]         --\n",
      "│    │    └─Conv2d: 3-14                 [128, 64, 12, 12]         36,864\n",
      "│    │    └─BatchNorm2d: 3-15            [128, 64, 12, 12]         128\n",
      "│    │    └─ReLU: 3-16                   [128, 64, 12, 12]         --\n",
      "│    │    └─Conv2d: 3-17                 [128, 256, 12, 12]        16,384\n",
      "│    │    └─BatchNorm2d: 3-18            [128, 256, 12, 12]        512\n",
      "│    │    └─ReLU: 3-19                   [128, 256, 12, 12]        --\n",
      "│    └─Bottleneck: 2-3                   [128, 256, 12, 12]        --\n",
      "│    │    └─Conv2d: 3-20                 [128, 64, 12, 12]         16,384\n",
      "│    │    └─BatchNorm2d: 3-21            [128, 64, 12, 12]         128\n",
      "│    │    └─ReLU: 3-22                   [128, 64, 12, 12]         --\n",
      "│    │    └─Conv2d: 3-23                 [128, 64, 12, 12]         36,864\n",
      "│    │    └─BatchNorm2d: 3-24            [128, 64, 12, 12]         128\n",
      "│    │    └─ReLU: 3-25                   [128, 64, 12, 12]         --\n",
      "│    │    └─Conv2d: 3-26                 [128, 256, 12, 12]        16,384\n",
      "│    │    └─BatchNorm2d: 3-27            [128, 256, 12, 12]        512\n",
      "│    │    └─ReLU: 3-28                   [128, 256, 12, 12]        --\n",
      "├─Sequential: 1-6                        [128, 512, 6, 6]          --\n",
      "│    └─Bottleneck: 2-4                   [128, 512, 6, 6]          --\n",
      "│    │    └─Conv2d: 3-29                 [128, 128, 12, 12]        32,768\n",
      "│    │    └─BatchNorm2d: 3-30            [128, 128, 12, 12]        256\n",
      "│    │    └─ReLU: 3-31                   [128, 128, 12, 12]        --\n",
      "│    │    └─Conv2d: 3-32                 [128, 128, 6, 6]          147,456\n",
      "│    │    └─BatchNorm2d: 3-33            [128, 128, 6, 6]          256\n",
      "│    │    └─ReLU: 3-34                   [128, 128, 6, 6]          --\n",
      "│    │    └─Conv2d: 3-35                 [128, 512, 6, 6]          65,536\n",
      "│    │    └─BatchNorm2d: 3-36            [128, 512, 6, 6]          1,024\n",
      "│    │    └─Sequential: 3-37             [128, 512, 6, 6]          132,096\n",
      "│    │    └─ReLU: 3-38                   [128, 512, 6, 6]          --\n",
      "│    └─Bottleneck: 2-5                   [128, 512, 6, 6]          --\n",
      "│    │    └─Conv2d: 3-39                 [128, 128, 6, 6]          65,536\n",
      "│    │    └─BatchNorm2d: 3-40            [128, 128, 6, 6]          256\n",
      "│    │    └─ReLU: 3-41                   [128, 128, 6, 6]          --\n",
      "│    │    └─Conv2d: 3-42                 [128, 128, 6, 6]          147,456\n",
      "│    │    └─BatchNorm2d: 3-43            [128, 128, 6, 6]          256\n",
      "│    │    └─ReLU: 3-44                   [128, 128, 6, 6]          --\n",
      "│    │    └─Conv2d: 3-45                 [128, 512, 6, 6]          65,536\n",
      "│    │    └─BatchNorm2d: 3-46            [128, 512, 6, 6]          1,024\n",
      "│    │    └─ReLU: 3-47                   [128, 512, 6, 6]          --\n",
      "│    └─Bottleneck: 2-6                   [128, 512, 6, 6]          --\n",
      "│    │    └─Conv2d: 3-48                 [128, 128, 6, 6]          65,536\n",
      "│    │    └─BatchNorm2d: 3-49            [128, 128, 6, 6]          256\n",
      "│    │    └─ReLU: 3-50                   [128, 128, 6, 6]          --\n",
      "│    │    └─Conv2d: 3-51                 [128, 128, 6, 6]          147,456\n",
      "│    │    └─BatchNorm2d: 3-52            [128, 128, 6, 6]          256\n",
      "│    │    └─ReLU: 3-53                   [128, 128, 6, 6]          --\n",
      "│    │    └─Conv2d: 3-54                 [128, 512, 6, 6]          65,536\n",
      "│    │    └─BatchNorm2d: 3-55            [128, 512, 6, 6]          1,024\n",
      "│    │    └─ReLU: 3-56                   [128, 512, 6, 6]          --\n",
      "│    └─Bottleneck: 2-7                   [128, 512, 6, 6]          --\n",
      "│    │    └─Conv2d: 3-57                 [128, 128, 6, 6]          65,536\n",
      "│    │    └─BatchNorm2d: 3-58            [128, 128, 6, 6]          256\n",
      "│    │    └─ReLU: 3-59                   [128, 128, 6, 6]          --\n",
      "│    │    └─Conv2d: 3-60                 [128, 128, 6, 6]          147,456\n",
      "│    │    └─BatchNorm2d: 3-61            [128, 128, 6, 6]          256\n",
      "│    │    └─ReLU: 3-62                   [128, 128, 6, 6]          --\n",
      "│    │    └─Conv2d: 3-63                 [128, 512, 6, 6]          65,536\n",
      "│    │    └─BatchNorm2d: 3-64            [128, 512, 6, 6]          1,024\n",
      "│    │    └─ReLU: 3-65                   [128, 512, 6, 6]          --\n",
      "├─Sequential: 1-7                        [128, 1024, 3, 3]         --\n",
      "│    └─Bottleneck: 2-8                   [128, 1024, 3, 3]         --\n",
      "│    │    └─Conv2d: 3-66                 [128, 256, 6, 6]          131,072\n",
      "│    │    └─BatchNorm2d: 3-67            [128, 256, 6, 6]          512\n",
      "│    │    └─ReLU: 3-68                   [128, 256, 6, 6]          --\n",
      "│    │    └─Conv2d: 3-69                 [128, 256, 3, 3]          589,824\n",
      "│    │    └─BatchNorm2d: 3-70            [128, 256, 3, 3]          512\n",
      "│    │    └─ReLU: 3-71                   [128, 256, 3, 3]          --\n",
      "│    │    └─Conv2d: 3-72                 [128, 1024, 3, 3]         262,144\n",
      "│    │    └─BatchNorm2d: 3-73            [128, 1024, 3, 3]         2,048\n",
      "│    │    └─Sequential: 3-74             [128, 1024, 3, 3]         526,336\n",
      "│    │    └─ReLU: 3-75                   [128, 1024, 3, 3]         --\n",
      "│    └─Bottleneck: 2-9                   [128, 1024, 3, 3]         --\n",
      "│    │    └─Conv2d: 3-76                 [128, 256, 3, 3]          262,144\n",
      "│    │    └─BatchNorm2d: 3-77            [128, 256, 3, 3]          512\n",
      "│    │    └─ReLU: 3-78                   [128, 256, 3, 3]          --\n",
      "│    │    └─Conv2d: 3-79                 [128, 256, 3, 3]          589,824\n",
      "│    │    └─BatchNorm2d: 3-80            [128, 256, 3, 3]          512\n",
      "│    │    └─ReLU: 3-81                   [128, 256, 3, 3]          --\n",
      "│    │    └─Conv2d: 3-82                 [128, 1024, 3, 3]         262,144\n",
      "│    │    └─BatchNorm2d: 3-83            [128, 1024, 3, 3]         2,048\n",
      "│    │    └─ReLU: 3-84                   [128, 1024, 3, 3]         --\n",
      "│    └─Bottleneck: 2-10                  [128, 1024, 3, 3]         --\n",
      "│    │    └─Conv2d: 3-85                 [128, 256, 3, 3]          262,144\n",
      "│    │    └─BatchNorm2d: 3-86            [128, 256, 3, 3]          512\n",
      "│    │    └─ReLU: 3-87                   [128, 256, 3, 3]          --\n",
      "│    │    └─Conv2d: 3-88                 [128, 256, 3, 3]          589,824\n",
      "│    │    └─BatchNorm2d: 3-89            [128, 256, 3, 3]          512\n",
      "│    │    └─ReLU: 3-90                   [128, 256, 3, 3]          --\n",
      "│    │    └─Conv2d: 3-91                 [128, 1024, 3, 3]         262,144\n",
      "│    │    └─BatchNorm2d: 3-92            [128, 1024, 3, 3]         2,048\n",
      "│    │    └─ReLU: 3-93                   [128, 1024, 3, 3]         --\n",
      "│    └─Bottleneck: 2-11                  [128, 1024, 3, 3]         --\n",
      "│    │    └─Conv2d: 3-94                 [128, 256, 3, 3]          262,144\n",
      "│    │    └─BatchNorm2d: 3-95            [128, 256, 3, 3]          512\n",
      "│    │    └─ReLU: 3-96                   [128, 256, 3, 3]          --\n",
      "│    │    └─Conv2d: 3-97                 [128, 256, 3, 3]          589,824\n",
      "│    │    └─BatchNorm2d: 3-98            [128, 256, 3, 3]          512\n",
      "│    │    └─ReLU: 3-99                   [128, 256, 3, 3]          --\n",
      "│    │    └─Conv2d: 3-100                [128, 1024, 3, 3]         262,144\n",
      "│    │    └─BatchNorm2d: 3-101           [128, 1024, 3, 3]         2,048\n",
      "│    │    └─ReLU: 3-102                  [128, 1024, 3, 3]         --\n",
      "│    └─Bottleneck: 2-12                  [128, 1024, 3, 3]         --\n",
      "│    │    └─Conv2d: 3-103                [128, 256, 3, 3]          262,144\n",
      "│    │    └─BatchNorm2d: 3-104           [128, 256, 3, 3]          512\n",
      "│    │    └─ReLU: 3-105                  [128, 256, 3, 3]          --\n",
      "│    │    └─Conv2d: 3-106                [128, 256, 3, 3]          589,824\n",
      "│    │    └─BatchNorm2d: 3-107           [128, 256, 3, 3]          512\n",
      "│    │    └─ReLU: 3-108                  [128, 256, 3, 3]          --\n",
      "│    │    └─Conv2d: 3-109                [128, 1024, 3, 3]         262,144\n",
      "│    │    └─BatchNorm2d: 3-110           [128, 1024, 3, 3]         2,048\n",
      "│    │    └─ReLU: 3-111                  [128, 1024, 3, 3]         --\n",
      "│    └─Bottleneck: 2-13                  [128, 1024, 3, 3]         --\n",
      "│    │    └─Conv2d: 3-112                [128, 256, 3, 3]          262,144\n",
      "│    │    └─BatchNorm2d: 3-113           [128, 256, 3, 3]          512\n",
      "│    │    └─ReLU: 3-114                  [128, 256, 3, 3]          --\n",
      "│    │    └─Conv2d: 3-115                [128, 256, 3, 3]          589,824\n",
      "│    │    └─BatchNorm2d: 3-116           [128, 256, 3, 3]          512\n",
      "│    │    └─ReLU: 3-117                  [128, 256, 3, 3]          --\n",
      "│    │    └─Conv2d: 3-118                [128, 1024, 3, 3]         262,144\n",
      "│    │    └─BatchNorm2d: 3-119           [128, 1024, 3, 3]         2,048\n",
      "│    │    └─ReLU: 3-120                  [128, 1024, 3, 3]         --\n",
      "├─Sequential: 1-8                        [128, 2048, 2, 2]         --\n",
      "│    └─Bottleneck: 2-14                  [128, 2048, 2, 2]         --\n",
      "│    │    └─Conv2d: 3-121                [128, 512, 3, 3]          524,288\n",
      "│    │    └─BatchNorm2d: 3-122           [128, 512, 3, 3]          1,024\n",
      "│    │    └─ReLU: 3-123                  [128, 512, 3, 3]          --\n",
      "│    │    └─Conv2d: 3-124                [128, 512, 2, 2]          2,359,296\n",
      "│    │    └─BatchNorm2d: 3-125           [128, 512, 2, 2]          1,024\n",
      "│    │    └─ReLU: 3-126                  [128, 512, 2, 2]          --\n",
      "│    │    └─Conv2d: 3-127                [128, 2048, 2, 2]         1,048,576\n",
      "│    │    └─BatchNorm2d: 3-128           [128, 2048, 2, 2]         4,096\n",
      "│    │    └─Sequential: 3-129            [128, 2048, 2, 2]         2,101,248\n",
      "│    │    └─ReLU: 3-130                  [128, 2048, 2, 2]         --\n",
      "│    └─Bottleneck: 2-15                  [128, 2048, 2, 2]         --\n",
      "│    │    └─Conv2d: 3-131                [128, 512, 2, 2]          1,048,576\n",
      "│    │    └─BatchNorm2d: 3-132           [128, 512, 2, 2]          1,024\n",
      "│    │    └─ReLU: 3-133                  [128, 512, 2, 2]          --\n",
      "│    │    └─Conv2d: 3-134                [128, 512, 2, 2]          2,359,296\n",
      "│    │    └─BatchNorm2d: 3-135           [128, 512, 2, 2]          1,024\n",
      "│    │    └─ReLU: 3-136                  [128, 512, 2, 2]          --\n",
      "│    │    └─Conv2d: 3-137                [128, 2048, 2, 2]         1,048,576\n",
      "│    │    └─BatchNorm2d: 3-138           [128, 2048, 2, 2]         4,096\n",
      "│    │    └─ReLU: 3-139                  [128, 2048, 2, 2]         --\n",
      "│    └─Bottleneck: 2-16                  [128, 2048, 2, 2]         --\n",
      "│    │    └─Conv2d: 3-140                [128, 512, 2, 2]          1,048,576\n",
      "│    │    └─BatchNorm2d: 3-141           [128, 512, 2, 2]          1,024\n",
      "│    │    └─ReLU: 3-142                  [128, 512, 2, 2]          --\n",
      "│    │    └─Conv2d: 3-143                [128, 512, 2, 2]          2,359,296\n",
      "│    │    └─BatchNorm2d: 3-144           [128, 512, 2, 2]          1,024\n",
      "│    │    └─ReLU: 3-145                  [128, 512, 2, 2]          --\n",
      "│    │    └─Conv2d: 3-146                [128, 2048, 2, 2]         1,048,576\n",
      "│    │    └─BatchNorm2d: 3-147           [128, 2048, 2, 2]         4,096\n",
      "│    │    └─ReLU: 3-148                  [128, 2048, 2, 2]         --\n",
      "├─AdaptiveAvgPool2d: 1-9                 [128, 2048, 1, 1]         --\n",
      "├─Sequential: 1-10                       [128, 7]                  --\n",
      "│    └─Dropout: 2-17                     [128, 2048]               --\n",
      "│    └─Linear: 2-18                      [128, 7]                  14,343\n",
      "==========================================================================================\n",
      "Total params: 23,522,375\n",
      "Trainable params: 23,522,375\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 27.26\n",
      "==========================================================================================\n",
      "Input size (MB): 3.54\n",
      "Forward/backward pass size (MB): 1083.71\n",
      "Params size (MB): 94.09\n",
      "Estimated Total Size (MB): 1181.34\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(summary(resnet50_fer_model, input_size=(BATCH_SIZE, 3, 48, 48), device=device.type))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dc8a14",
   "metadata": {},
   "source": [
    "# Create Train and Test functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf63633",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2cee4304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_pred,y_true):\n",
    "    top_p,top_class = y_pred.topk(1, dim = 1)\n",
    "    equals = top_class == y_true.view(*top_class.shape)\n",
    "    return torch.mean(equals.type(torch.cuda.FloatTensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4e3b04bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, criterion, optimizer, device, current_epoch, epochs):\n",
    "    \"\"\"\n",
    "    Train one epoch of the model.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The  model.\n",
    "        dataloader (DataLoader): DataLoader for training data.\n",
    "        device (torch.device): Device to train the model on (CPU/GPU).\n",
    "\n",
    "    Returns:\n",
    "        training_loss (float): Returns epoch_loss / len(dataloader)\n",
    "    \"\"\"\n",
    "    model.train()  # Set model to training mode\n",
    "    epoch_loss = 0.0\n",
    "    epoch_accuracy = 0.0\n",
    "    tk = tqdm(dataloader, desc=\"EPOCH\" + \"[TRAIN]\" + str(current_epoch + 1) + \"/\" + str(epochs))\n",
    "\n",
    "    for t, data in enumerate(tk):\n",
    "        images, labels = data\n",
    "\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Compute log probabilities from model\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "\n",
    "        # Update model parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate loss for logging; Total loss\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        epoch_accuracy += calculate_accuracy(logits, labels)\n",
    "\n",
    "        # Print/log training loss and accuracy for this epoch\n",
    "        tk.set_postfix({\n",
    "            'loss': '%6f' % float(epoch_loss / (t + 1)), \n",
    "            'acc': '%6f' % float(epoch_accuracy / (t + 1))\n",
    "        })\n",
    "\n",
    "    return epoch_loss / len(dataloader), epoch_accuracy / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7824849d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_one_epoch(model, dataloader, criterion, device, current_epoch, epochs):\n",
    "    \"\"\"\n",
    "    Test one epoch of the model\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model.\n",
    "        dataloader (DataLoader): DataLoader for training data.\n",
    "        learning_rate (float): Learning rate for optimizer.\n",
    "        device (torch.device): Device to train the model on (CPU/GPU).\n",
    "\n",
    "    Returns:\n",
    "        training_loss (float): Returns epoch_loss / len(dataloader)\n",
    "        \n",
    "        running_acc (float): Returns epoch accuracy\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    epoch_loss = 0.0\n",
    "    epoch_accuracy = 0.0\n",
    "    tk = tqdm(dataloader, desc=\"EPOCH\" + \"[VALID]\" + str(current_epoch + 1) + \"/\" + str(epochs))\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():  # Disable gradient calculation for testing\n",
    "        for t, data in enumerate(tk):          \n",
    "            images, labels = data\n",
    "\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Compute log probabilities from model\n",
    "            logits = model(images)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += images.size(0)            \n",
    "\n",
    "            # Compute CTC loss\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            # Accumulate loss for logging; Total loss\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            epoch_accuracy += calculate_accuracy(logits, labels)\n",
    "            \n",
    "\n",
    "            tk.set_postfix({\n",
    "                'loss': '%6f' % float(epoch_loss / (t + 1)), \n",
    "                'acc': '%6f' % float(epoch_accuracy / (t + 1))\n",
    "            })\n",
    "\n",
    "    return epoch_loss / len(dataloader), epoch_accuracy / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "81b39d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate_model(model, training_dataloader, testing_dataloader, epochs, learning_rate, device):\n",
    "    \"\"\"\n",
    "    Train and Test the speech recognition model using CTC loss.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model.\n",
    "        training_dataloader (DataLoader): DataLoader for training data.\n",
    "        testing_dataloader (DataLoader): DataLoader for testing data.\n",
    "        epochs (int): Number of training epochs.\n",
    "        learning_rate (float): Learning rate for optimizer.\n",
    "        device (torch.device): Device to train the model on (CPU/GPU).\n",
    "    \"\"\"\n",
    "    # Define Loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.1)\n",
    "\n",
    "    # Move model to device\n",
    "    model.to(device)\n",
    "\n",
    "    best_valid_loss = np.inf\n",
    "    patience_counter = 0   # Tracks the number of epochs without improvement\n",
    "    early_stop = False # Flag to indicate whether to stop training\n",
    "    save_weights_patience = 3\n",
    "\n",
    "    # Dictionary to store loss and accuracy values over epochs\n",
    "    history_metrics = {\n",
    "        'training_loss': [],\n",
    "        'training_accuracy': [],\n",
    "        'validation_loss': [],\n",
    "        'validation_accuracy': []\n",
    "    }\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        if early_stop:\n",
    "            print(\"Early stopping triggered. Stopping training.\")\n",
    "            break\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}, LR: {scheduler.optimizer.param_groups[0]['lr']}\")\n",
    "\n",
    "        # Training step\n",
    "        train_loss, train_accuracy = train_one_epoch(model, training_dataloader, criterion, optimizer, device, epoch, epochs)\n",
    "        \n",
    "        # Testing step\n",
    "        valid_loss, valid_accuracy = test_one_epoch(model, testing_dataloader, criterion, device, epoch, epochs) \n",
    "\n",
    "        history_metrics['training_loss'].append(train_loss)\n",
    "        history_metrics['validation_loss'].append(valid_loss)\n",
    "        history_metrics['training_accuracy'].append(train_accuracy)\n",
    "        history_metrics['validation_accuracy'].append(valid_accuracy)\n",
    "\n",
    "        # Update the learning rate based on validation loss and print\n",
    "        scheduler.step(valid_loss)\n",
    "\n",
    "        if valid_loss < best_valid_loss:\n",
    "            torch.save(model.state_dict(), 'weights/RESNET50_model_with_fer2013_weights.pt')\n",
    "            print(\"SAVED-BEST-WEIGHTS!\")\n",
    "            best_valid_loss = valid_loss\n",
    "            patience_counter = 0 # Reset early stopping\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"No improvement in validation loss for {patience_counter} epoch(s).\")\n",
    "\n",
    "        if patience_counter >= save_weights_patience:\n",
    "            print(\"Patience exceeded. Early stopping at epoch \" +str(epoch + 1))\n",
    "            early_stop = True\n",
    "            \n",
    "        \n",
    "    print(\"\")\n",
    "    return history_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cf1b19",
   "metadata": {},
   "source": [
    "### Run train functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f103698",
   "metadata": {},
   "outputs": [],
   "source": [
    "time1 = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e820802d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]1/100: 100%|██████████| 225/225 [03:40<00:00,  1.02it/s, loss=1.923978, acc=0.188164]\n",
      "EPOCH[VALID]1/100: 100%|██████████| 57/57 [00:19<00:00,  2.92it/s, loss=1.886772, acc=0.220477]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 2, LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]2/100: 100%|██████████| 225/225 [01:19<00:00,  2.84it/s, loss=1.868253, acc=0.224323]\n",
      "EPOCH[VALID]2/100: 100%|██████████| 57/57 [00:04<00:00, 11.87it/s, loss=1.832163, acc=0.245422]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 3, LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]3/100: 100%|██████████| 225/225 [01:18<00:00,  2.85it/s, loss=1.830810, acc=0.246639]\n",
      "EPOCH[VALID]3/100: 100%|██████████| 57/57 [00:04<00:00, 12.99it/s, loss=1.794433, acc=0.270504]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 4, LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]4/100: 100%|██████████| 225/225 [01:19<00:00,  2.84it/s, loss=1.800389, acc=0.258688]\n",
      "EPOCH[VALID]4/100: 100%|██████████| 57/57 [00:04<00:00, 12.64it/s, loss=1.770551, acc=0.284704]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 5, LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]5/100: 100%|██████████| 225/225 [01:24<00:00,  2.65it/s, loss=1.776322, acc=0.274756]\n",
      "EPOCH[VALID]5/100: 100%|██████████| 57/57 [00:04<00:00, 12.55it/s, loss=1.745412, acc=0.296135]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 6, LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]6/100: 100%|██████████| 225/225 [01:27<00:00,  2.58it/s, loss=1.753474, acc=0.290058]\n",
      "EPOCH[VALID]6/100: 100%|██████████| 57/57 [00:04<00:00, 12.24it/s, loss=1.721222, acc=0.306579]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 7, LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]7/100: 100%|██████████| 225/225 [01:14<00:00,  3.00it/s, loss=1.734470, acc=0.302278]\n",
      "EPOCH[VALID]7/100: 100%|██████████| 57/57 [00:04<00:00, 13.52it/s, loss=1.707858, acc=0.311075]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 8, LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]8/100: 100%|██████████| 225/225 [01:12<00:00,  3.09it/s, loss=1.717121, acc=0.309305]\n",
      "EPOCH[VALID]8/100: 100%|██████████| 57/57 [00:04<00:00, 13.54it/s, loss=1.675314, acc=0.336321]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 9, LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]9/100: 100%|██████████| 225/225 [01:11<00:00,  3.14it/s, loss=1.698920, acc=0.318434]\n",
      "EPOCH[VALID]9/100: 100%|██████████| 57/57 [00:04<00:00, 13.50it/s, loss=1.655551, acc=0.351288]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 10, LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]10/100: 100%|██████████| 225/225 [01:13<00:00,  3.05it/s, loss=1.677388, acc=0.337534]\n",
      "EPOCH[VALID]10/100: 100%|██████████| 57/57 [00:04<00:00, 13.55it/s, loss=1.636642, acc=0.363130]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 11, LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]11/100: 100%|██████████| 225/225 [01:13<00:00,  3.08it/s, loss=1.655947, acc=0.342619]\n",
      "EPOCH[VALID]11/100: 100%|██████████| 57/57 [00:04<00:00, 13.43it/s, loss=1.607104, acc=0.374342]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 12, LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]12/100: 100%|██████████| 225/225 [01:12<00:00,  3.11it/s, loss=1.635146, acc=0.357622]\n",
      "EPOCH[VALID]12/100: 100%|██████████| 57/57 [00:04<00:00, 13.37it/s, loss=1.589503, acc=0.381908]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 13, LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]13/100: 100%|██████████| 225/225 [01:11<00:00,  3.13it/s, loss=1.614221, acc=0.365128]\n",
      "EPOCH[VALID]13/100: 100%|██████████| 57/57 [00:04<00:00, 13.60it/s, loss=1.566680, acc=0.394901]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 14, LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]14/100: 100%|██████████| 225/225 [01:13<00:00,  3.05it/s, loss=1.596233, acc=0.376543]\n",
      "EPOCH[VALID]14/100: 100%|██████████| 57/57 [00:04<00:00, 13.53it/s, loss=1.557609, acc=0.399452]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 15, LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]15/100: 100%|██████████| 225/225 [01:11<00:00,  3.13it/s, loss=1.580886, acc=0.381449]\n",
      "EPOCH[VALID]15/100: 100%|██████████| 57/57 [00:04<00:00, 13.61it/s, loss=1.546404, acc=0.401645]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 16, LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]16/100: 100%|██████████| 225/225 [01:13<00:00,  3.08it/s, loss=1.559790, acc=0.393162]\n",
      "EPOCH[VALID]16/100: 100%|██████████| 57/57 [00:04<00:00, 13.49it/s, loss=1.515764, acc=0.423602]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 17, LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]17/100: 100%|██████████| 225/225 [01:12<00:00,  3.10it/s, loss=1.545215, acc=0.402203]\n",
      "EPOCH[VALID]17/100: 100%|██████████| 57/57 [00:04<00:00, 13.38it/s, loss=1.505586, acc=0.424287]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 18, LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]18/100: 100%|██████████| 225/225 [01:11<00:00,  3.16it/s, loss=1.529478, acc=0.408405]\n",
      "EPOCH[VALID]18/100: 100%|██████████| 57/57 [00:04<00:00, 13.73it/s, loss=1.489239, acc=0.433279]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 19, LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]19/100: 100%|██████████| 225/225 [01:11<00:00,  3.14it/s, loss=1.509172, acc=0.418626]\n",
      "EPOCH[VALID]19/100: 100%|██████████| 57/57 [00:04<00:00, 13.61it/s, loss=1.476228, acc=0.439748]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 20, LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]20/100: 100%|██████████| 225/225 [01:12<00:00,  3.11it/s, loss=1.491714, acc=0.423020]\n",
      "EPOCH[VALID]20/100: 100%|██████████| 57/57 [00:04<00:00, 13.58it/s, loss=1.462211, acc=0.438213]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 21, LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]21/100: 100%|██████████| 225/225 [01:12<00:00,  3.09it/s, loss=1.486654, acc=0.425328]\n",
      "EPOCH[VALID]21/100: 100%|██████████| 57/57 [00:04<00:00, 13.19it/s, loss=1.454485, acc=0.442078]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 22, LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]22/100: 100%|██████████| 225/225 [01:13<00:00,  3.07it/s, loss=1.468952, acc=0.434902]\n",
      "EPOCH[VALID]22/100: 100%|██████████| 57/57 [00:04<00:00, 13.64it/s, loss=1.435394, acc=0.452988]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 23, LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]23/100: 100%|██████████| 225/225 [01:12<00:00,  3.12it/s, loss=1.457264, acc=0.440653]\n",
      "EPOCH[VALID]23/100: 100%|██████████| 57/57 [00:04<00:00, 13.70it/s, loss=1.425801, acc=0.452577]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 24, LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]24/100: 100%|██████████| 225/225 [01:12<00:00,  3.09it/s, loss=1.448977, acc=0.441265]\n",
      "EPOCH[VALID]24/100: 100%|██████████| 57/57 [00:04<00:00, 13.51it/s, loss=1.416774, acc=0.454934]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 25, LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]25/100: 100%|██████████| 225/225 [01:13<00:00,  3.08it/s, loss=1.438874, acc=0.445413]\n",
      "EPOCH[VALID]25/100: 100%|██████████| 57/57 [00:04<00:00, 13.36it/s, loss=1.407709, acc=0.462034]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 26, LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]26/100: 100%|██████████| 225/225 [01:13<00:00,  3.07it/s, loss=1.428829, acc=0.450239]\n",
      "EPOCH[VALID]26/100: 100%|██████████| 57/57 [00:04<00:00, 13.61it/s, loss=1.397609, acc=0.467626]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 27, LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]27/100: 100%|██████████| 225/225 [01:11<00:00,  3.13it/s, loss=1.417579, acc=0.455236]\n",
      "EPOCH[VALID]27/100: 100%|██████████| 57/57 [00:04<00:00, 13.45it/s, loss=1.395955, acc=0.465351]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 28, LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]28/100: 100%|██████████| 225/225 [01:13<00:00,  3.08it/s, loss=1.404064, acc=0.462784]\n",
      "EPOCH[VALID]28/100: 100%|██████████| 57/57 [00:04<00:00, 13.50it/s, loss=1.379181, acc=0.475055]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 29, LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]29/100: 100%|██████████| 225/225 [01:12<00:00,  3.11it/s, loss=1.397033, acc=0.462923]\n",
      "EPOCH[VALID]29/100: 100%|██████████| 57/57 [00:04<00:00, 13.65it/s, loss=1.375033, acc=0.479715]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 30, LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]30/100: 100%|██████████| 225/225 [01:12<00:00,  3.10it/s, loss=1.392934, acc=0.463661]\n",
      "EPOCH[VALID]30/100: 100%|██████████| 57/57 [00:04<00:00, 13.44it/s, loss=1.375975, acc=0.476371]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in validation loss for 1 epoch(s).\n",
      "Epoch 31, LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]31/100: 100%|██████████| 225/225 [01:12<00:00,  3.10it/s, loss=1.380970, acc=0.473599]\n",
      "EPOCH[VALID]31/100: 100%|██████████| 57/57 [00:04<00:00, 13.62it/s, loss=1.361915, acc=0.482209]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 32, LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]32/100: 100%|██████████| 225/225 [01:11<00:00,  3.13it/s, loss=1.370806, acc=0.476171]\n",
      "EPOCH[VALID]32/100: 100%|██████████| 57/57 [00:04<00:00, 13.56it/s, loss=1.350625, acc=0.486568]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 33, LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]33/100: 100%|██████████| 225/225 [01:12<00:00,  3.09it/s, loss=1.366600, acc=0.473137]\n",
      "EPOCH[VALID]33/100: 100%|██████████| 57/57 [00:04<00:00, 13.45it/s, loss=1.350597, acc=0.486486]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 34, LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]34/100: 100%|██████████| 225/225 [01:13<00:00,  3.08it/s, loss=1.355062, acc=0.481262]\n",
      "EPOCH[VALID]34/100: 100%|██████████| 57/57 [00:04<00:00, 13.45it/s, loss=1.337584, acc=0.488925]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 35, LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]35/100: 100%|██████████| 225/225 [01:12<00:00,  3.09it/s, loss=1.347265, acc=0.484283]\n",
      "EPOCH[VALID]35/100: 100%|██████████| 57/57 [00:04<00:00, 13.55it/s, loss=1.343343, acc=0.487034]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in validation loss for 1 epoch(s).\n",
      "Epoch 36, LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]36/100: 100%|██████████| 225/225 [01:12<00:00,  3.12it/s, loss=1.342768, acc=0.487752]\n",
      "EPOCH[VALID]36/100: 100%|██████████| 57/57 [00:04<00:00, 13.35it/s, loss=1.325271, acc=0.491118]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 37, LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]37/100: 100%|██████████| 225/225 [01:12<00:00,  3.10it/s, loss=1.337728, acc=0.490859]\n",
      "EPOCH[VALID]37/100: 100%|██████████| 57/57 [00:04<00:00, 13.38it/s, loss=1.317374, acc=0.495203]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 38, LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]38/100: 100%|██████████| 225/225 [01:13<00:00,  3.08it/s, loss=1.328122, acc=0.488298]\n",
      "EPOCH[VALID]38/100: 100%|██████████| 57/57 [00:04<00:00, 13.44it/s, loss=1.319942, acc=0.498109]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in validation loss for 1 epoch(s).\n",
      "Epoch 39, LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]39/100: 100%|██████████| 225/225 [01:13<00:00,  3.07it/s, loss=1.322432, acc=0.493848]\n",
      "EPOCH[VALID]39/100: 100%|██████████| 57/57 [00:04<00:00, 13.27it/s, loss=1.300742, acc=0.501590]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 40, LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]40/100: 100%|██████████| 225/225 [01:12<00:00,  3.09it/s, loss=1.314999, acc=0.497841]\n",
      "EPOCH[VALID]40/100: 100%|██████████| 57/57 [00:04<00:00, 13.42it/s, loss=1.295347, acc=0.506414]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 41, LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]41/100: 100%|██████████| 225/225 [01:12<00:00,  3.10it/s, loss=1.303019, acc=0.501999]\n",
      "EPOCH[VALID]41/100: 100%|██████████| 57/57 [00:04<00:00, 13.52it/s, loss=1.285952, acc=0.515104]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 42, LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]42/100: 100%|██████████| 225/225 [01:13<00:00,  3.08it/s, loss=1.305789, acc=0.499993]\n",
      "EPOCH[VALID]42/100: 100%|██████████| 57/57 [00:04<00:00, 13.35it/s, loss=1.289204, acc=0.507812]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in validation loss for 1 epoch(s).\n",
      "Epoch 43, LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]43/100: 100%|██████████| 225/225 [01:12<00:00,  3.10it/s, loss=1.302999, acc=0.503490]\n",
      "EPOCH[VALID]43/100: 100%|██████████| 57/57 [00:04<00:00, 13.52it/s, loss=1.287339, acc=0.511650]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in validation loss for 2 epoch(s).\n",
      "Epoch 44, LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]44/100: 100%|██████████| 225/225 [01:12<00:00,  3.11it/s, loss=1.294224, acc=0.503757]\n",
      "EPOCH[VALID]44/100: 100%|██████████| 57/57 [00:04<00:00, 13.52it/s, loss=1.281681, acc=0.512610]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 45, LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]45/100: 100%|██████████| 225/225 [01:14<00:00,  3.04it/s, loss=1.287481, acc=0.507077]\n",
      "EPOCH[VALID]45/100: 100%|██████████| 57/57 [00:04<00:00, 13.29it/s, loss=1.272552, acc=0.517133]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 46, LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]46/100: 100%|██████████| 225/225 [01:12<00:00,  3.10it/s, loss=1.281846, acc=0.509916]\n",
      "EPOCH[VALID]46/100: 100%|██████████| 57/57 [00:04<00:00, 13.40it/s, loss=1.272060, acc=0.515899]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 47, LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]47/100: 100%|██████████| 225/225 [01:13<00:00,  3.06it/s, loss=1.270116, acc=0.514256]\n",
      "EPOCH[VALID]47/100: 100%|██████████| 57/57 [00:04<00:00, 12.42it/s, loss=1.267634, acc=0.513761]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 48, LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]48/100: 100%|██████████| 225/225 [01:12<00:00,  3.11it/s, loss=1.270972, acc=0.514713]\n",
      "EPOCH[VALID]48/100: 100%|██████████| 57/57 [00:04<00:00, 12.99it/s, loss=1.255251, acc=0.524041]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAVED-BEST-WEIGHTS!\n",
      "Epoch 49, LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]49/100: 100%|██████████| 225/225 [01:13<00:00,  3.04it/s, loss=1.266361, acc=0.519309]\n",
      "EPOCH[VALID]49/100: 100%|██████████| 57/57 [00:04<00:00, 13.42it/s, loss=1.256858, acc=0.521382]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in validation loss for 1 epoch(s).\n",
      "Epoch 50, LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]50/100: 100%|██████████| 225/225 [01:13<00:00,  3.07it/s, loss=1.257823, acc=0.515231]\n",
      "EPOCH[VALID]50/100: 100%|██████████| 57/57 [00:04<00:00, 13.51it/s, loss=1.260105, acc=0.517873]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in validation loss for 2 epoch(s).\n",
      "Epoch 51, LR: 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[TRAIN]51/100: 100%|██████████| 225/225 [01:12<00:00,  3.11it/s, loss=1.256725, acc=0.520984]\n",
      "EPOCH[VALID]51/100: 100%|██████████| 57/57 [00:04<00:00, 13.40it/s, loss=1.257031, acc=0.520779]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement in validation loss for 3 epoch(s).\n",
      "Patience exceeded. Early stopping at epoch 51\n",
      "Early stopping triggered. Stopping training.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model:\n",
    "resnet_model_losses = train_and_validate_model(resnet50_fer_model, training_loader, test_loader, epochs=100, learning_rate=0.001, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496a7c3b",
   "metadata": {},
   "source": [
    "> TRained for about 50 + 14 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d7e622a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time:  1:09:02.470153\n"
     ]
    }
   ],
   "source": [
    "time2 = datetime.now()\n",
    "print(\"Training time: \", time2 - time1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6722ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses and accuracy saved\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data\n",
    "data = {\n",
    "    \"Epoch\": list(range(1, len(resnet_model_losses['training_loss']) + 1)),\n",
    "    \"Training Loss\": resnet_model_losses['training_loss'],\n",
    "    \"Validation Loss\": resnet_model_losses['validation_loss'],\n",
    "    \"Training Accuracy\": [acc.cpu().item() for acc in resnet_model_losses['training_accuracy']],\n",
    "    \"Validation Accuracy\": [acc.cpu().item() for acc in resnet_model_losses['validation_accuracy']]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"stats/resnet50_model_stats_001_100 epochs.csv\", index=False)\n",
    "print(\"Losses and accuracy saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e318b5b5",
   "metadata": {},
   "source": [
    "# Test Model Accuracy on Out of Distribution Data set (Manga Faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8d39f44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_out_of_distribution(model, testing_dataloader, epochs, device):\n",
    "    \"\"\"\n",
    "    Train and Test the speech recognition model using CTC loss.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The model.\n",
    "        training_dataloader (DataLoader): DataLoader for training data.\n",
    "        testing_dataloader (DataLoader): DataLoader for testing data.\n",
    "        epochs (int): Number of training epochs.\n",
    "        learning_rate (float): Learning rate for optimizer.\n",
    "        device (torch.device): Device to train the model on (CPU/GPU).\n",
    "    \"\"\"\n",
    "    # Define Loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Move model to device\n",
    "    model.to(device)\n",
    "\n",
    "    # Dictionary to store loss and accuracy values over epochs\n",
    "    history_metrics = {\n",
    "        'validation_loss': [],\n",
    "        'validation_accuracy': []\n",
    "    }\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch + 1}\")\n",
    "        \n",
    "        # Testing step\n",
    "        valid_loss, valid_accuracy = test_one_epoch(model, testing_dataloader, criterion, device, epoch, epochs) \n",
    "        \n",
    "        history_metrics['validation_loss'].append(valid_loss)\n",
    "        history_metrics['validation_accuracy'].append(valid_accuracy)\n",
    "                \n",
    "    print(\"\")\n",
    "    return history_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ca2450a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50_fer_model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "resnet50_fer_model.fc = nn.Sequential(\n",
    "    nn.Dropout(params[\"dropout_rate\"]),\n",
    "    nn.Linear(resnet50_fer_model.fc.in_features, params[\"num_classes\"])\n",
    ")\n",
    "resnet50_fer_model = resnet50_fer_model.to(device)\n",
    "resnet50_fer_model.load_state_dict(torch.load('weights/RESNET50_model_with_fer2013_weights.pt', weights_only=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5acd7e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "manga_faces_dir = Path(os.getcwd(), 'datasets', 'manga')\n",
    "manga_faces_images = ImageFolder(root=manga_faces_dir, transform=val_transforms)\n",
    "manga_faces_images_loader = DataLoader(manga_faces_images, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4d105e",
   "metadata": {},
   "source": [
    "**Changes made to the data set folder**\n",
    "> Changed\n",
    "\n",
    " {'angry': 0, 'happy': 3, 'sad': 5,\n",
    " \n",
    " \n",
    " 'disgust': 1, 'fear': 2,  'neutral': 4,  'surprise': 6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "680836f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]1/5: 100%|██████████| 4/4 [00:07<00:00,  1.88s/it, loss=2.122886, acc=0.254016]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]2/5: 100%|██████████| 4/4 [00:01<00:00,  2.42it/s, loss=2.132977, acc=0.250495]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]3/5: 100%|██████████| 4/4 [00:01<00:00,  2.99it/s, loss=2.120428, acc=0.250495]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]4/5: 100%|██████████| 4/4 [00:01<00:00,  2.59it/s, loss=2.112646, acc=0.253631]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EPOCH[VALID]5/5: 100%|██████████| 4/4 [00:01<00:00,  2.77it/s, loss=2.122238, acc=0.250880]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model:\n",
    "test_out_of_distribution_losses = test_out_of_distribution(resnet50_fer_model, manga_faces_images_loader, epochs=5, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c183a06",
   "metadata": {},
   "source": [
    "# FSL DA Prototypical Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b40840d",
   "metadata": {},
   "source": [
    "### ResNet50 Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6559bff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50FeatureExtractor(nn.Module):\n",
    "    def __init__(self, base_model, embedding_dim=512):\n",
    "        super(ResNet50FeatureExtractor, self).__init__()\n",
    "        # Use the ResNet50 layers up to average pool.\n",
    "        # list(base_model.children())[:-1] ignores the last fc layer.\n",
    "        self.features = nn.Sequential(*list(base_model.children())[:-1])\n",
    "        # Optionally, add a projection layer to reduce dimensionality.\n",
    "        # ResNet50 outputs feature vectors of size 2048 after avgpool.\n",
    "        self.projection = nn.Linear(2048, embedding_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)             # shape: [B, 2048, 1, 1]\n",
    "        x = x.flatten(1)                 # shape: [B, 2048]\n",
    "        embeddings = self.projection(x)  # shape: [B, embedding_dim]\n",
    "        return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "56ef4039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=2048, out_features=7, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50_fer_model_2 = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "resnet50_fer_model_2.fc = nn.Sequential(\n",
    "    nn.Dropout(params[\"dropout_rate\"]),\n",
    "    nn.Linear(resnet50_fer_model_2.fc.in_features, params[\"num_classes\"])\n",
    ")\n",
    "resnet50_fer_model_2 = resnet50_fer_model_2.to(device)\n",
    "resnet50_fer_model_2.load_state_dict(torch.load('weights/RESNET50_model_with_fer2013_weights.pt', weights_only=True))\n",
    "resnet50_fer_model_2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bc2787f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming resnet50_fer_model is already defined and on device:\n",
    "feature_extractor = ResNet50FeatureExtractor(resnet50_fer_model_2).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a556c60f",
   "metadata": {},
   "source": [
    "### Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "15233c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FewShotFERDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for few-shot FER, where images are organized by class in folders.\n",
    "    This dataset generates episodes (tasks) on-the-fly.\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir, n_way=5, k_shot=1, k_query=5, transform=None):\n",
    "        \"\"\"\n",
    "        root_dir: Root folder containing one folder per class.\n",
    "        n_way: number of classes per episode.\n",
    "        k_shot: number of support (labeled) examples per class.\n",
    "        k_query: number of query (unlabeled) examples per class.\n",
    "        transform: transformation to apply to images.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.n_way = n_way\n",
    "        self.k_shot = k_shot\n",
    "        self.k_query = k_query\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Build a mapping: class -> list of image paths.\n",
    "        self.class_to_imgs = {}\n",
    "        for cls_name in os.listdir(root_dir):            \n",
    "            cls_folder = Path.joinpath(root_dir, cls_name)\n",
    "            if Path.is_dir(cls_folder):\n",
    "                self.class_to_imgs[cls_name] = [Path.joinpath(cls_folder, img)                                                 \n",
    "                                                 for img in Path(cls_folder).rglob('*')\n",
    "                                                 if str(img).endswith('.jpg') or str(img).endswith('.png')]        \n",
    "        self.classes = list(self.class_to_imgs.keys())\n",
    "    \n",
    "    def __len__(self):\n",
    "        # Define the number of episodes arbitrarily.\n",
    "        return 1000  # or any number representing episodes\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Randomly sample n_way classes for this episode.\n",
    "        sampled_classes = random.sample(self.classes, self.n_way)\n",
    "        support_imgs, support_labels = [], []\n",
    "        query_imgs, query_labels = [], []\n",
    "        \n",
    "        label_map = {cls_name: i for i, cls_name in enumerate(sampled_classes)}\n",
    "        \n",
    "        for cls_name in sampled_classes:\n",
    "            imgs = self.class_to_imgs[cls_name]\n",
    "            # Ensure there are enough examples in this class.\n",
    "            selected_imgs = random.sample(imgs, self.k_shot + self.k_query)\n",
    "            support_paths = selected_imgs[:self.k_shot]\n",
    "            query_paths = selected_imgs[self.k_shot:]\n",
    "            \n",
    "            for sp in support_paths:\n",
    "                img = Image.open(sp).convert('RGB')\n",
    "                if self.transform:\n",
    "                    img = self.transform(img)\n",
    "                support_imgs.append(img)\n",
    "                support_labels.append(label_map[cls_name])\n",
    "            \n",
    "            for qp in query_paths:\n",
    "                img = Image.open(qp).convert('RGB')\n",
    "                if self.transform:\n",
    "                    img = self.transform(img)\n",
    "                query_imgs.append(img)\n",
    "                query_labels.append(label_map[cls_name])\n",
    "        \n",
    "        # Convert lists to tensors.\n",
    "        support_imgs = torch.stack(support_imgs)  # shape: [n_way*k_shot, C, H, W]\n",
    "        support_labels = torch.tensor(support_labels, dtype=torch.long)\n",
    "        query_imgs = torch.stack(query_imgs)      # shape: [n_way*k_query, C, H, W]\n",
    "        query_labels = torch.tensor(query_labels, dtype=torch.long)\n",
    "        \n",
    "        return (support_imgs, support_labels), (query_imgs, query_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58adc3d5",
   "metadata": {},
   "source": [
    "### Instantiate Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6b699e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms (should match what the encoder expects)\n",
    "transform = T.Compose([\n",
    "    T.Resize((48, 48)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Root folder with classes as subfolders.\n",
    "few_shot_dataset = FewShotFERDataset(root_dir=manga_faces_dir, n_way=7, k_shot=15, k_query=20, transform=transform)\n",
    "few_shot_loader = DataLoader(few_shot_dataset, batch_size=1, shuffle=True, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc3e480",
   "metadata": {},
   "source": [
    "### Prototypical Network Inference function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "584fdf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_episode(feature_extractor, support_imgs, support_labels, query_imgs, query_labels, device):\n",
    "    \"\"\"\n",
    "    feature_extractor: model that outputs embeddings [B, embedding_dim]\n",
    "    support_imgs: tensor of shape [n_way * k_shot, C, H, W]\n",
    "    support_labels: tensor of shape [n_way * k_shot]\n",
    "    query_imgs: tensor of shape [n_way * k_query, C, H, W]\n",
    "    query_labels: tensor of shape [n_way * k_query]\n",
    "    \"\"\"\n",
    "    feature_extractor.eval()\n",
    "    with torch.no_grad():\n",
    "        # Move data to device.\n",
    "        support_imgs = support_imgs.to(device)\n",
    "        query_imgs = query_imgs.to(device)\n",
    "        \n",
    "        # Compute the embeddings.\n",
    "        support_embeddings = feature_extractor(support_imgs)  # [n_way*k_shot, D]\n",
    "        query_embeddings = feature_extractor(query_imgs)      # [n_way*k_query, D]\n",
    "    \n",
    "        # Compute prototypes: mean of support embeddings per class.\n",
    "        prototypes = []\n",
    "        unique_labels = torch.unique(support_labels)\n",
    "        for cls in unique_labels:\n",
    "            cls_indices = (support_labels == cls).nonzero(as_tuple=True)[0]\n",
    "            cls_embeddings = support_embeddings[cls_indices]\n",
    "            prototype = cls_embeddings.mean(dim=0)\n",
    "            prototypes.append(prototype)\n",
    "        prototypes = torch.stack(prototypes)  # shape: [n_way, D]\n",
    "        \n",
    "        # Compute distances between query embeddings and prototypes.\n",
    "        # We use Euclidean distance here.\n",
    "        # query_embeddings: [Q, D], prototypes: [n_way, D]\n",
    "        distances = torch.cdist(query_embeddings, prototypes, p=2)  # shape: [Q, n_way]\n",
    "        \n",
    "        # Convert distances to probabilities (smaller distance -> higher probability).\n",
    "        probs = F.softmax(-distances, dim=1)\n",
    "        preds = torch.argmax(probs, dim=1)\n",
    "        correct = (preds.cpu() == query_labels).sum().item()\n",
    "        total = query_labels.size(0)\n",
    "    \n",
    "    return correct, total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f71a500",
   "metadata": {},
   "source": [
    "### Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "242bc81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Few-Shot Episode Accuracy: 27.90%\n"
     ]
    }
   ],
   "source": [
    "total_correct = 0\n",
    "total_samples = 0\n",
    "num_episodes = 50  # Evaluate on 50 episodes.\n",
    "\n",
    "for i, episode in enumerate(few_shot_loader):\n",
    "    if i >= num_episodes:\n",
    "        break\n",
    "    # Remove the extra batch dimension since batch_size=1.\n",
    "    (support_imgs, support_labels), (query_imgs, query_labels) = episode\n",
    "    support_imgs = support_imgs.squeeze(0)\n",
    "    support_labels = support_labels.squeeze(0)\n",
    "    query_imgs = query_imgs.squeeze(0)\n",
    "    query_labels = query_labels.squeeze(0)\n",
    "    \n",
    "    correct, total = evaluate_episode(feature_extractor, support_imgs, support_labels, query_imgs, query_labels, device)\n",
    "    total_correct += correct\n",
    "    total_samples += total\n",
    "\n",
    "episode_accuracy = 100.0 * total_correct / total_samples\n",
    "print(\"Few-Shot Episode Accuracy: {:.2f}%\".format(episode_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d6cf20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
